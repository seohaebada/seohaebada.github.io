[{"id":0,"href":"/docs/algorithm/","title":"Algorithm","section":"Docs","content":" 000 Sample "},{"id":1,"href":"/docs/batch/","title":"Batch","section":"Docs","content":" 001 Performance Improved Batch "},{"id":2,"href":"/docs/data-structure/","title":"Data Structure","section":"Docs","content":" 000 Sample "},{"id":3,"href":"/docs/ddd/","title":"Ddd","section":"Docs","content":" 000 Sample "},{"id":4,"href":"/docs/docker/","title":"Docker","section":"Docs","content":" 000 Sample "},{"id":5,"href":"/docs/etc/","title":"Etc","section":"Docs","content":" 000 Sample "},{"id":6,"href":"/docs/java/","title":"Java","section":"Docs","content":" 001 Facade Pattern "},{"id":7,"href":"/docs/jenkins/","title":"Jenkins","section":"Docs","content":" 000 Sample "},{"id":8,"href":"/docs/jpa/","title":"Jpa","section":"Docs","content":" 000 Sample "},{"id":9,"href":"/docs/kafka/","title":"Kafka","section":"Docs","content":" 001 Kafka Cdc "},{"id":10,"href":"/docs/kotlin/","title":"Kotlin","section":"Docs","content":" 005 Kotlin Extract List Method 004 Kotlin Scoping Functions 003 Kotlin Basic 002 Functional Programming Example 001 Functional Programming "},{"id":11,"href":"/docs/linux/","title":"Linux","section":"Docs","content":" 000 Sample "},{"id":12,"href":"/docs/mongodb/","title":"Mongodb","section":"Docs","content":" 003 Spring Data Mongodb 004 Object Mapping 005 Mongo Operations 006 Reactive Mongo Repository 007 Query Method 001 Reactive Mongodb 002 Mongodb Document "},{"id":13,"href":"/docs/msa/","title":"Msa","section":"Docs","content":" 000 Sample "},{"id":14,"href":"/docs/mvc/","title":"Mvc","section":"Docs","content":" 000 Sample "},{"id":15,"href":"/docs/mysql/","title":"Mysql","section":"Docs","content":" 000 Sample "},{"id":16,"href":"/docs/network/","title":"Network","section":"Docs","content":" 000 Sample "},{"id":17,"href":"/docs/operating-system/","title":"Operating System","section":"Docs","content":" 000 Sample "},{"id":18,"href":"/docs/oracle/","title":"Oracle","section":"Docs","content":" 000 Sample "},{"id":19,"href":"/docs/r2dbc/","title":"R2dbc","section":"Docs","content":" 005 R2dbc Metadata Mapping 006 R2dbc Entity Operations 007 R2dbc Repository 008 R2dbc Query Method 003 R2dbc Entity Template 004 R2dbc Object Mapping 002 R2dbc Mysql 001 R2dbc Intro "},{"id":20,"href":"/docs/reactive-streams/","title":"Reactive Streams","section":"Docs","content":" 002 Impl1 Reactor 003 Impl2 Rxjava 004 Impl3 Munity 001 Reactive Streams Component "},{"id":21,"href":"/docs/redis/","title":"Redis","section":"Docs","content":" 003 Reactive Redis Intro 004 Lettuce 005 Reactive Redis Template 006 Reactive Operations 001 Redis Datastructure 002 Redis Cache "},{"id":22,"href":"/docs/security/","title":"Security","section":"Docs","content":" 000 Sample "},{"id":23,"href":"/docs/servlet/","title":"Servlet","section":"Docs","content":" 000 Sample "},{"id":24,"href":"/docs/spring/","title":"Spring","section":"Docs","content":" 000 Sample "},{"id":25,"href":"/docs/webflux/","title":"Webflux","section":"Docs","content":" 000 Sample "},{"id":26,"href":"/docs/redis/003_reactive_redis_intro/","title":"003 Reactive Redis Intro","section":"Redis","content":" 1. Redis 소개 # Redis instance # 여러 client가 하나의 redis 서버로 요청 전달 단일 redis 서버에 문제가 발생하면 장애 -\u0026gt; 모든 client에서 접속 불가 Redis replication # master와 replica로 구성 master에 데이터가 업데이트 -\u0026gt; replica 동기화 replica : 읽기만 가능 replica에 문제 발생 -\u0026gt; 여러 node에 data가 복제되었기 때문에 복구 가능 master에 문제 발생 -\u0026gt; 개발자가 직접 replica 중 하나를 master로 변경 Redis sentinel # master에 문제 발생 -\u0026gt; replica들이 master를 선출 이전 master가 복구 된 경우, replica로 전환되어 새로운 master를 바라보게된다. Automatic Failover 기능을 제공 자동 장애 조치 고가용성을 제공 Redis cluster # Redis sentinel 보다 조금 더 강력한 기능들을 제공 데이터를 자동으로 파티셔닝하고 client의 요청을 필요한 master 혹은 replica에게 전달 고가용성, 데이터 분산, 자동 파티셔닝 각각의 master에 문제가 생기면 replica가 마스터 역할을 수행 Redis connector # Spring에서는 redis connector로 jedis와 lettuce를 지원 현재는 기본으로 rettuce 사용 별도의 설정을 통해서 jedis를 설정 가능 Redis connector 차이 # Spring data redis reactive 스택 # Redis reposito # 동기 blocking 방식에서 redis repository를 지원 reactive 환경에서는 reactive redis repository 미지원 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":27,"href":"/docs/redis/004_Lettuce/","title":"004 Lettuce","section":"Redis","content":" 2. Lettuce # 구조 # Reactor 기반으로 Reactive API 지원 Reactive streams API 지원 동기 API, 비동기 API 모두 지원 Netty 기반으로 높은 성능과 확장성 제공 일반 TCP 통신 뿐만 아니라 epoll, kqueue 기반의 multiplexing I/O 지원 주요 컴포넌트 # RedisClient : Redis의 연결 정보를 포함하는 객체 Netty의 Channel, EventLoopGroup 등을 포함하기 때문에 가능한한 재사용 RedisConnecction 생성 StatefulRedisConnection : Redis 서버 Connection 여러 쓰레드가 동시에 접근해도 안전 동기, 비동기, Reactive command를 제공 RedisReactiveCommand : Redis API와 관련된 reactive command 제공 RedisReactiveCommand 획득 # RedisClient.create : Redis Client를 생성 RedisURI builder를 통해서 host, port 주입 연결 정보를 String으로 전달하여 생성 가능 RedisCleint의 connect를 통해서 StatefulRedisConnetion 획득 StatefulRedisConnection의 reactive를 통해서 reactiveCommand 획득 RedisReactiveCommand 실행 # StatefulRedisConnection과 ReactiveCommand는 key-value로 String 지원 set command를 실행한 후, then으로 get command 실행 StatefulRedisConnection # sync, async, reactive command 지원 addListener를 통해서 RedisPubSubListener나 RedisConnectionStateListener 등을 등록, 삭제 가능 Redis(Async)Commands # RedisCommands는 모든 commands를 동기 방식으로 수행 RedisAsyncCommands는 모든 commands를 RedisFuture 형태로 반환 RedisFuture # CompletableFuture와 비슷하게 CompletionStage와 Future를 구현 추가로 에러를 조회할 수 있는 getError와 특정 시간동안 응답을 기다리는 await 제공 RedisReactiveCommands # RedisReactiveCommands는 여러 타입의 Commands를 상속 각각의 Redis가 지원하는 데이터 타입과 맵핑 String List Set Hash SortedSet Stream HLL (HyperLogLog) String # set을 통해서 person:1:name, pserson:1:age를 설정 setnx를 통해서 값을 바꾸려고 하지만, 이미 key에 value가 존재하면 반영X get, mget을 통해서 value에 접근 mget은 KeyValue를 반환 incrby를 톨해서 key의 값을 증가 List - queue # lpush를 통해서 값들을 추가 llen을 이용해서 길이를 파악 rpop을 하면 가장 처음에 들어간 item이 pop되기 때문에 queue를 구현 가능 List - stack # lpush를 통해서 값들을 추가 llen을 이용해서 길이를 파악 lpop을 하면 가장 마지막에 들어간 item이 pop되기 때문에 stack을 구현 가능 Set # sadd를 통해서 추가, 결과로 추가된 갯수 반환 set은 값이 unique하기 때문에 이미 존재하는 item에 대해서는 무시 scard : set의 cardinality 반환 smembers : 모든 item 조회 sismember : redis에 item이 포함되는지 확인 srem으로 item 삭제 Hash # hest에 map을 제공하여 여러 field를 한번에 추가 hgetall : 모든 필드에 접근하여 flux로 반환 hlen : hahs의 크기 조회 hincrby : age 필드의 크기를 10만큼 증가 hmget : 여러 필드에 대한 값 조회 hdel : age 필드 제거 SortedSet # zadd : score와 value 추가 zrem : value를 삭제 zcard : sortedSet의 cardinality 조회 zrangeWithScores : 특정 범위의 값들을 score와 함께 조회 zrank : 특정 value의 rank를 조회 TTL # expire : key에 ttl을 부여 ttl command : key에 남은 ttl 확인 ttl이 지난 후 key에 조회시 empty key가 존재하지 않기 때문에 -2를 반환 TTL - persist # expire : key에 ttl을 부여 후 persist : key를 영구 보관 가능 key에 ttl이 없는 경우 -1을 반환 PubSub # StatefulRedisPubSubConnection과 RedisPubSubReactiveCommand를 이용 channel을 subscribe하고 observe 가능 다른 StatefulRedisConnection을 만들어서 channel에 publish Stream # 특정 stream의 최신 메세지를 읽기 위해 대기\nxread : count만큼의 stream을 받은 후 complete\n지속적으로 listen하기 위해서는 repeat 등을 활용 가능\ncomplete 이후 다시 subscribe xread : block 인자로 받은 시간만큼 connection을 blocking 두 번째 connection을 만들고 redis transaction을 이용해서 여러 stream을 xadd로 추가 HyperLogLog # pfadd : key에 value들을 추가 pfcount : key의 크기를 추정 hyperloglog는 적은 메모리로 집합의 원소 개수를 추정 가능 key를 아티클의 id, value를 유저의 id로 둔다면 매우 적은 메모리로 unique view count를 구할 수 있다. References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":28,"href":"/docs/redis/005_ReactiveRedisTemplate/","title":"005 Reactive Redis Template","section":"Redis","content":" 3. ReactiveRedisTemplate # ReactiveRedisTemplate # ReactiveRedisTemplate은 Spring data redis reactive의 추상화 클래스 ReactiveRedisConnectionFactory를 통해서 RedisConnection을 주입 ReactiveRedisConnectionFactory # ReactiveRedisConnectionFactory는 RedisConnection을 제공 LettuceConnectionFactory와 JedisConnectionFactory 구현체 RedisTemplate bean # RedisReactiveAutoConfiguration를 통해서 자동으로 ReactiveRedisTemplate bean 생성 JdkSerializationRedisSerializer는 ObjectOutputStream을 이용하여 key와 value로 주어지는 object를 binary로 변환 key, value에 대해서 String만 지원하는 ReactiveStringRedisTemplate bean도 등록 ReactiveRedisOperations # ReactiveRedisConnection에 직접 접근할 수 있는 execute, executeInSession 메소드 pub/sub 메소드 key와 관련된 메소드 스크립트 메소드 operations 접근 메소드 pub/sub # convertAndSend: destination 채널로 message를 전달하고 메시지를 받은 클라이언트의 숫자를 반환 listenToChannel: channels에 주어진 채널들을 listen하고 메시지를 Flux 형태로 전달 key 관련 # hasKey: EXISTS. key가 존재하는지 확인 scan: SCAN. key들을 non-blocking으로 분할해서 순회 delete: DELETE. key들을 삭제 expire: EXPIRE. key에 TTL 부여 expireAt: EXPIREAT. unix time을 기반으로 key에 TTL을 부여 persist: PERSIST. key에 TTL 제거 getExpire: PTTL. key의 TTL을 milliseconds로 반환 Operations # opsForValue: value opsForList: list opsForSet: set opsForHash: hash opsForZSet: sorted set opsForStream: stream opsForHyperLogLog: hyperLogLog References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":29,"href":"/docs/redis/006_ReactiveOperations/","title":"006 Reactive Operations","section":"Redis","content":" 4. ReactiveOperations # ReactiveValueOperations 실행 # set으로 특정 key에 value를 추가 setIfAbsent로 key에 값이 없을때만 설정 get으로 key의 value를 조회 multiGet으로 여러 key에 접근 increment로 특정 key의 value를 증가 ReactiveListOperations # size: LLEN. list의 크기를 반환 leftPush: LPUSH. list의 head에 값을 추가 rightPush: RPUSH. list의 tail에 값을 추가 set: LSET. 특정한 index에 값을 설정 remove: LREM. list에서 value를 count 숫자만큼 제거 leftPop: LPOP. list의 head에서 값을 제거하고 반환 rightPop: RPOP. list의 tail에서 값을 제거하고 반환 delete: DEL. key에 설정된 list를 제거 ReactiveListOperations - Queue # leftPush를 통해서 100, 200 값을 추가 size를 통해서 list의 크기를 출력 rightPop을 통해서 처음에 추가한 값들을 제거 이를 통해서 queue를 구현 ReactiveListOperations - Stack # leftPush를 통해서 100, 200 값을 추가 size를 통해서 list의 크기를 출력 leftPop을 통해서 처음에 추가한 값들을 제거 이를 통해서 stack을 구현 ReactiveSetOperations # add: SADD. value들을 set에 추가. 결과로 추가된 개수 반환 remove: SREM: set에서 item들 제거 size: SCARD. set의 cardinality 반환 isMember: SISMEMBER. set에 item이 포함되는지 확인 members: SMEMBERS. set의 모든 item 조회 delete: DEL. key에 설정된 set을 제거 ReactiveSetOperations 실행 # add를 통해서 set에 값을 추가 size를 통해서 set의 cardinality를 출력 members로 모든 item 조회 isMember로 item이 set에 존재하는지 확인 remove로 set에서 item 제거 ReactiveHashOperations # remove: HDEL. hash에서 주어진 field key를 갖는 field들을 제거 get: HGET. hash에서 주어진 field의 value 조회 multiGet: HMGET. 여러 field의 value 조회 increment: HINCRBY. 특정 field의 value를 주어진 값만큼 증가 size: HLEN. hash의 field 크기 반환 putAll: HSET. 여러 field들을 한번에 추가 values: HGETALL. 모든 field들을 조회 delete: DEL. key에 설정된 hash를 제거 ReactiveHashOperations 실행 # putAll로 여러 field를 한번에 추가 values로 모든 필드에 접근하여 flux로 반환 size으로 hash의 크기 조회 increment로 age 필드의 크기를 10만큼 증가 multiGet으로 여러 필드에 대한 값 조회 remove로 age 필드 제거 ReactiveZSetOperations # addAll: ZADD. sorted set에 value와 score들을 추가 remove: ZREM. set에서 value들을 제거 rank: ZRANK. 주어진 value의 순위를 반환 rangeWithScores: ZRANGE. 특정 범위 안의 value와 score를 조회 size: ZCARD. sorted set의 cardinality 반환 delete: DEL. key에 설정된 sorted set을 제거 ReactiveZSetOperations 실행 # addAll로 여러 value를 한번에 추가 remove로 특정 value 제거 size으로 set의 크기 조회 rangeWithScores로 모든 value와 score 조회 rank로 특정 value의 순위 출력 ReactiveStreamOperations # add: XADD. streams에 record를 추가 createGroup: XGROUP. streams에 consumer group을 생성. group 이름 반환 range: XRANGE. 주어진 범위의 record를 반환 read: XREAD. 특정 offset 이후 혹은 최신 record를 count만큼 읽음. 최대 count개만큼 가져온 후 complete 이벤트 발생 consumer 제공 가능 ReactiveStreamOperations 실행 # 10초동안 block되고 최대 2개를 받을 수 있는 option 생성 10초가 지나면 next 이벤트 없이 complete 이벤트 latest를 통해서 최신 record 반환 ReactiveHyperLogLogOperations # add: PFADD. hyperloglog에 item을 추가 size: PFCOUNT. hyperloglog의 item 개수를 추정 delete: DEL. hyperloglog를 제거 ReactiveHyperLogLogOperations 실행 # add로 여러 value를 한번에 추가 size로 hyperloglog의 크기를 추정 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":30,"href":"/docs/java/001_facade_pattern/","title":"001 Facade Pattern","section":"Java","content":" 퍼사드 (Facade) 패턴 # 복잡한 서브 시스템 의존성을 최소화하는 방법. 클라이언트가 사용해야 하는 복잡한 서브 시스템 의존성을 간단한 인터페이스로 추상화 할 수 있다. 복잡한 디테일을 퍼사드 뒤로 숨긴다. 복잡한 서브 클래스들의 공통적인 기능을 정의하는 상위 수준의 인터페이스를 제공하는 패턴이다. 서브 클래스의 코드에 의존하는 일을 감소시켜 주고, 복잡한 소프트웨어를 간단히 사용 할 수 있게 간단한 인터페이스를 제공해준다. 서브 시스템(SubSystem)들 간의 종속성을 줄여줄 수 있으며, 퍼사드 객체를 사용하는 곳(Client)에서는 여러 서브 클래스들을 호출할 필요 없이 편리하게 사용할 수 있다. Facade Object(WashingMachine)만을 호출하여 \u0026lsquo;어떤 동작\u0026rsquo;을 수행할 수 있으며, 메서드의 의미 또한 명확하게 알 수 있다. 장점 # 서브 시스템에 대한 의존성을 한곳으로 모을 수 있다. (결합도 감소, 응집도 증가) 단점 # 퍼사드 클래스가 서브 시스템에 대한 모든 의존성을 가지게된다. (EmailSender) 적용 전 # package com.designpattern.report._10_facade.step1_before; import javax.mail.Message; import javax.mail.MessagingException; import javax.mail.Session; import javax.mail.Transport; import javax.mail.internet.InternetAddress; import javax.mail.internet.MimeMessage; import java.util.Properties; public class Client { public static void main(String[] args) { String to = \u0026#34;keesun@whiteship.me\u0026#34;; String from = \u0026#34;whiteship@whiteship.me\u0026#34;; String host = \u0026#34;127.0.0.1\u0026#34;; // Properties 로 서버 정보 셋팅 Properties properties = System.getProperties(); properties.setProperty(\u0026#34;mail.smtp.host\u0026#34;, host); Session session = Session.getDefaultInstance(properties); /** * SOLID 객체 지향 원칙 */ try { MimeMessage message = new MimeMessage(session); // 메시지 정보 설정 message.setFrom(new InternetAddress(from)); message.addRecipient(Message.RecipientType.TO, new InternetAddress(to)); message.setSubject(\u0026#34;Test Mail from Java Program\u0026#34;); message.setText(\u0026#34;message\u0026#34;); // send Transport.send(message); } catch (MessagingException e) { e.printStackTrace(); } } } 적용 후 # EmailMessage\npackage com.designpattern.report._10_facade.step2_after; import lombok.Getter; import lombok.Setter; @Getter @Setter public class EmailMessage { private String from; private String to; private String cc; private String bcc; private String subject; private String text; } EmailSettings\npackage com.designpattern.report._10_facade.step2_after; import lombok.Getter; import lombok.Setter; @Getter @Setter public class EmailSettings { private String host; } EmailSender\npackage com.designpattern.report._10_facade.step2_after; import javax.mail.Message; import javax.mail.MessagingException; import javax.mail.Session; import javax.mail.Transport; import javax.mail.internet.InternetAddress; import javax.mail.internet.MimeMessage; import java.util.Properties; /** * 인터페이스로 만들고 * 각 구현클래스로 확장해갈 수도 있다. */ public class EmailSender { private EmailSettings emailSettings; public EmailSender(EmailSettings emailSettings) { this.emailSettings = emailSettings; } /** * 이메일 보내는 메소드 * @param emailMessage */ public void sendEmail(EmailMessage emailMessage) { Properties properties = System.getProperties(); properties.setProperty(\u0026#34;mail.smtp.host\u0026#34;, emailSettings.getHost()); Session session = Session.getDefaultInstance(properties); try { MimeMessage message = new MimeMessage(session); message.setFrom(new InternetAddress(emailMessage.getFrom())); message.addRecipient(Message.RecipientType.TO, new InternetAddress(emailMessage.getTo())); message.addRecipient(Message.RecipientType.CC, new InternetAddress(emailMessage.getCc())); message.setSubject(emailMessage.getSubject()); message.setText(emailMessage.getText()); Transport.send(message); } catch (MessagingException e) { e.printStackTrace(); } } } Client\npublic class Client { public static void main(String[] args) { /* Email Setting */ EmailSettings emailSettings = new EmailSettings(); emailSettings.setHost(\u0026#34;127.0.0.1\u0026#34;); /* Email Sender */ EmailSender emailSender = new EmailSender(emailSettings); /* Email 내용 */ EmailMessage emailMessage = new EmailMessage(); emailMessage.setFrom(\u0026#34;keesun\u0026#34;); emailMessage.setTo(\u0026#34;whiteship\u0026#34;); emailMessage.setCc(\u0026#34;일남\u0026#34;); emailMessage.setSubject(\u0026#34;오징어게임\u0026#34;); emailMessage.setText(\u0026#34;밖은 더 지옥이더라고..\u0026#34;); emailSender.sendEmail(emailMessage); } } 적용 후 모습 # References _1) 강의 : https://www.inflearn.com/course/%EB%94%94%EC%9E%90%EC%9D%B8-%ED%8C%A8%ED%84%B4 _2) 블로그 : https://velog.io/@bagt/Design-Pattern-Facade-Pattern-%ED%8D%BC%EC%82%AC%EB%93%9C-%ED%8C%A8%ED%84%B4 "},{"id":31,"href":"/docs/kafka/001_kafka_cdc/","title":"001 Kafka Cdc","section":"Kafka","content":" [tech blog 읽기] CDC 너두 할 수 있어(feat. B2B 알림 서비스에 Kafka CDC 적용하기) # B2B 알림 서비스에 CDC를 도입을 하게 되었다.\nB2B 알림 서비스 # B2B 알림 서비스 프로젝트가 무엇일까? 배민 B2C 고객 서비스에서는 알림센터라는 시스템을 통해 고객에 알림을 발송한다. 하지만, 사장님에게 발송되는 알림은 플랫폼이 부재한 관계로 카카오 알림톡으로 발송하고 있었다. 개선을 위해 알림센터를 활용해 사장님에게 전달되는 메시지를 내부 서비스를 통해 전달함으로써, 내부 서비스 활용도와 사용자 편의성을 향상시키고자 진행한 프로젝트가 \u0026lsquo;B2B 알림서비스\u0026rsquo;다. 여기서, 세일즈 매니저에 대한 알림톡을 알림센터 내 웹 푸시 알림으로 전환 하는 과정에서 CDC를 도입하게되었다. B2B 알림서비스에 CDC를 도입하게 된 이유 # 세일즈 매니저에게 알림이 발송되는 경우\n세일즈 매니저 본인이 만든 업무 요청 건의 상태가 변경되는 경우 세일즈 매니저 본인이 해당 가게의 세일즈 매니저로 설정되어있는 업무 요청 건의 상태가 변경될 경우 기존에 알림 발송은 프론트 코드에 있던 상태였지만, 아래와 같은 문제 존재\n네트워크 문제로 알림 발송 누락 알림 발송 이후 요청 건의 상태 변경에 실패하면 실제 데이터와 맞지 않음 위와 같은 사유로 백엔드에서 처리를 해야했다. 그래서 요청 건의 상태가 변경되면 DB에 반영되는 것에 착안하여 변경된 데이터를 감지하는 CDC를 선택하게되었다. CDC (Change Data Capture) # 소스 시스템에서 데이터가 변경된 것을 감지하여, 타깃 시스템이 변경 작업에 대응하는 작업을 수행하도록 하는 프로세스\n소스 시스템 : DB 타깃 시스템 : B2B 알림 서비스 CDC를 활용하면 데이터를 사용하는 모든 시스템에서 일관성을 유지할 수 있다는 장점이 있다. pull 방식 타깃 시스템의 주기적인 풀링으로 변경 사항이 있는지 확인 실시간성이 떨어진다. 구현은 쉽다.\npush 방식 소스 시스템이 변경될때마다 타깃 시스템에 알려준다. pull 방식에 비해 소스 시스템이 많은 작업을 해야하고, 타깃 시스템에 문제가 발생하면 변경 이벤트에 누락이 발생할 수 있다. 실시간성이 뛰어나다.\nKafka CDC\n위 방식 중에 Push 방식에서 이벤트 누락의 단점을 메시지 큐인 Kafka를 통해 해결하여, CDC 시스템을 만드는 것 Debezium MySQL Connector\nDB로부터 데이터의 변경 이벤트를 감지해서 Kafka 이벤트를 발행해주는 것 Mysql의 binlog를 읽어 INSERT, UPDATE, DELETE 연산에 대한 변경 이벤트를 만들어 KAfka 토픽으로 이벤트를 전송 binlog를 기반으로 데이터를 수집하기 때문에, DB에서 수행된 모든 이벤트가 안정적으로 수집되고, 이벤트 발행시 정확한 순서 보장 Kafka CDC를 활용 방법 # 사전준비 Kafka Kafka Connect Debezium MySQL Connector Kafka CDC를 활용한 코드 작성하기 Kafka를 통해 넘어오는 이벤트 레코드를 변환해야 하는데, Debezium MySQL Connector는 Apache Avro를 지원한다. 이를 사용하려면 스키마 레지스트리를 사용해야한다. 스키마 레지스트리에 등록된 스키마를 받기 위해서, 프로젝트의 gradle에 설정을 추가해두면 편하다. val schemaRegistry = \u0026#34;http://localhost:8081\u0026#34; // 스키마 레지스트리 주소 val downloadInputs = listOf( \u0026#34;schema.data-key\u0026#34;, \u0026#34;schema.data-value\u0026#34; ) val avroDestination = \u0026#34;org/main/avro\u0026#34; //avro 스키마가 저장될 프로젝트상의 위치 schemaRegistry { url.set(schemaRegistry) download { // 패턴에 해당하는 서브젝트(스키마)를 다운로드 downloadInputs.forEach { subjectPattern( inputPattern = it, file = avroDestination ) } } } arvo 스키마 { \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Envelope\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;schema.data\u0026#34;, \u0026#34;fields\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;before\u0026#34;, \u0026#34;type\u0026#34;: [ \u0026#34;null\u0026#34;, { \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Value\u0026#34;, \u0026#34;fields\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; } // ... ], \u0026#34;connect.name\u0026#34;: \u0026#34;schema.data\u0026#34; } ], \u0026#34;default\u0026#34;: null }, { \u0026#34;name\u0026#34;: \u0026#34;after\u0026#34;, \u0026#34;type\u0026#34;: [ \u0026#34;null\u0026#34;, \u0026#34;Value\u0026#34; ], \u0026#34;default\u0026#34;: null }, { \u0026#34;name\u0026#34;: \u0026#34;source\u0026#34;, \u0026#34;type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;io.debezium.connector.mysql\u0026#34;, \u0026#34;fields\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;version\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } // ... ], \u0026#34;connect.name\u0026#34;: \u0026#34;io.debezium.connector.mysql.Source\u0026#34; } }, { \u0026#34;name\u0026#34;: \u0026#34;op\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;ts_ms\u0026#34;, \u0026#34;type\u0026#34;: [ \u0026#34;null\u0026#34;, \u0026#34;long\u0026#34; ], \u0026#34;default\u0026#34;: null }, { \u0026#34;name\u0026#34;: \u0026#34;transaction\u0026#34;, \u0026#34;type\u0026#34;: [ \u0026#34;null\u0026#34;, { \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;ConnectDefault\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;io.confluent.connect.avro\u0026#34;, \u0026#34;fields\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;total_order\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;data_collection_order\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; } ] } ], \u0026#34;default\u0026#34;: null } ], \u0026#34;connect.name\u0026#34;: \u0026#34;schema.Envelope\u0026#34; } 빌드 후 생성되는 클래스 fun Envelop.toBefore(): CdcRecord? { val before = this.getBefore() ?: return null return CdcRecord( //... ) } ConsumerConfig 설정 @Configuration class CdcConsumerConfig { @Bean(CDC_CONTAINER_FACTORY) fun cdcListenerContainerFactory( properties: CdcConsumerProperties, @Value(\u0026#34;\\${spring.kafka.bootstrap-servers}\u0026#34;) bootstrapServers: String ): KafkaListenerContainerFactory\u0026lt;ConcurrentMessageListenerContainer\u0026lt;String, Envelope\u0026gt;\u0026gt; { val factory = ConcurrentKafkaListenerContainerFactory\u0026lt;String, Envelope\u0026gt;() factory.consumerFactory = DefaultKafkaConsumerFactory( mapOf( ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to bootstrapServers, ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to properties.keyDeserializerClass, ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to properties.valueDeserializerClass, ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to properties.enableAutoCommit, ConsumerConfig.MAX_POLL_RECORDS_CONFIG to properties.maxPollRecords, ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to properties.autoOffsetReset, // Schema Registry, Avro 관련 설정 필수 KafkaAvroDeserializerConfig.SCHEMA_REGISTRY_URL_CONFIG to properties.schemaRegistryUrl, KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG to properties.specificAvroReader, ) ) // ... } } 이벤트 리스너 생성 class CdcEventListener( private val cdcEventProcessor: List\u0026lt;CdcEventProcessor\u0026gt;, ) { private val sinkQueue = Queues.get\u0026lt;List\u0026lt;Envelope\u0026gt;\u0026gt;(4096).get() private val sinks = Sinks.many() .unicast() .onBackpressureBuffer(sinkQueue) private lateinit var disposable: Disposable @KafkaListener( topics = [\u0026#34;\\${kafka.cdc.topic}\u0026#34;], groupId = \u0026#34;\\${kafka.cdc.groupId}\u0026#34;, containerFactory = CdcConsumerConfig.CDC_CONTAINER_FACTORY, ) fun listen( @Payload payloads: List\u0026lt;Envelope?\u0026gt;, @Header(KafkaHeaders.RECEIVED_PARTITION_ID) partition: Int, @Header(KafkaHeaders.RECEIVED_TOPIC) topic: String, @Header(KafkaHeaders.RECEIVED_TIMESTAMP) ts: Long, acknowledgment: Acknowledgment, ) { // ... } } 조건 : CDC 이벤트의 종류에 따라서 다른 알림을 보내야 한다. 서로 다른 이벤트의 종류를 받을 이벤트 프로세서 + 각 이벤트 내에서 어떤 알림을 보낼지 결정하는 이벤트 핸들러\n요청 건에 대한 어떤 이벤트인가? : 가게 로고 수정, 가게 소개 수정 등\n어떤 이벤트인가? : 요청이 승인됨, 요청이 반려됨 등 각 이벤트 프로세서에 이벤트를 전달하는 코드\nclass CdcEventListener( private val cdcEventProcessor: List\u0026lt;CdcEventProcessor\u0026gt;, ) { // ... @PostConstruct protected fun init() { disposable = sinks.asFlux() // ... // 이벤트를 처리 하는 과정에서 doAlarm으로 알림 발송 .doOnNext(::doAlarm) // ... } private fun doAlarm(CdcRecords: List\u0026lt;Envelope\u0026gt; = emptyList()) { Flux.fromIterable(CdcRecords) .flatMap { Mono.fromCallable { // 각각의 이벤트 프로세서에게 이벤트를 처리 하도록 지시 cdcEventProcessor.forEach { processor -\u0026gt; try { processor.process( before = it.toBefore(), after = it.toAfter(), ) } catch (e: Exception) { log.warn(\u0026#34;[CdcEventProcessor] occured exception\u0026#34;, e) } } }.subscribeOn(Schedulers.boundedElastic()) }.subscribe() } } 이벤트를 처리하는 이벤트 프로세서 @Service class NotificationCenterAlarmFacade( private val notificationHandlers: List\u0026lt;NotificationHandler\u0026gt; ) : CdcEventProcessor { override fun process(before: CdcRecord?, after: CdcRecord?) { log.debug(\u0026#34;[알림서비스] process 진입 before = `{}`, after = `{}`\u0026#34;, before, after) if (after == null) { log.info(\u0026#34;[알림서비스] 데이터 삭제건에 대해서는 알림서비스 발송처리를 하지 않습니다. before: `{}`\u0026#34;, before) return } notificationHandlers.find { it.accept(before = before, after = after) } ?.send(record = after) } } 이벤트 프로세서에서는 자신이 전달받은 이벤트에 대해서 처리할 수 있는 이벤트인지 확인한 후, 처리할 수 있는 이벤트의 종류라면 자신이 가지고 있는 이벤트 핸들러들에게 처리를 위임한다.\n핸들러는 본인이 처리할 수 있는 이벤트인지 확인하고 알림을 보낸다. -\u0026gt; B2B 알림 서비스 동작 @Component class CompleteHandler : NotificationHandler { override fun send(record: CdcRecord) { // 알림 발송 로직 } override fun accept(before: CdcRecord?, after: CdcRecord?): Boolean { // 완료 이벤트에 대한 알림을 발송하는 핸들러이기 때문에, 완료 이벤트인지 확인하는 조건 if (before == null || after == null || before.status == Complete || after.status != Complete ) { return false } log.info(\u0026#34;[알림서비스] 완료 이벤트 감지 `{}`\u0026#34;, after.id) return true } } 이제 특정 요청 건들의 상태가 변경되면 자동으로 알림을 받을 수 있다.\n주의할점 # AWS Aurora 환경에서 쓰기 부하가 많은 경우 Debezium MySQL Connector를 연동하면 binlog dump thread가 Aurora MySQL 클러스터 스토리지의 binlog를 읽는데, 이때 락을 건다. Aurora MySQL 2.10.2 미만의 버전에서는 쓰기 부하가 많은 경우 부하가 심해질 수 있다. binlog dump thread의 부하가 심해지는 경우 INSERT, UPDATE, DELETE, COMMIT 등 DML 관련 레이턴시가 증가하게 되고, 이에 따라 장애가 발생할 수 있다.\n중복 메시지 발생의 가능성 여러 가지 경우로 Kakfa 메시지는 중복될 수 있다.\n해결 방법 : Redis Cache\nclass CdcEventListener( private val cdcEventProcessor: List\u0026lt;CdcEventProcessor\u0026gt;, ) { // ... @PostConstruct protected fun init() { disposable = sinks.asFlux() // ... // 이벤트를 처리 하는 과정에서 doCheckDuplicationPrevent 으로 중복 확인 .flatMap(::doCheckDuplicationPrevent) // ... } private fun doCheckDuplicationPrevent(cdcRecords: List\u0026lt;Envelope\u0026gt;): Mono\u0026lt;List\u0026lt;Envelope\u0026gt;\u0026gt; { return Mono.fromCallable { cdcRecords.filter { // HashCode를 이용한 RedisKey 생성 val key = RedisCacheType.DUPLICATION_PREVENT.addPostfix(name = \u0026#34;${it.getAfter().getId()}:${it.hashCode()}\u0026#34;) // 해당 Key가 이미 존재하는지 확인 val existKey = redisTemplate.opsForValue().existKey( key = key ) log.debug( \u0026#34;[CDC][EventEmitterSinks] Check Duplication Prevent. Key = `{}`, Value = `{}`\u0026#34;, key, existKey ) (!existKey) } }.subscribeOn(Schedulers.boundedElastic()) } } 정리 # CDC 키워드로 보게된 기술 블로그 포스팅이였는데, CDC에 대한 감을 잡는데에 도움이 된것같다. CDC, Kafka CDC, Debezium MySQL Connector 키워드에 대해서 좀더 공부해야할 필요를 느꼈다.\nReferences _1) https://techblog.woowahan.com/10000/?ref=codenary "},{"id":32,"href":"/docs/mongodb/003_spring_data_mongodb/","title":"003 Spring Data Mongodb","section":"Mongodb","content":" Spring data mongodb reactive # Entity # 데이터베이스에서 하나의 Document와 매칭되는 클래스 ReactiveMongoEntityTemplate, ReactiveMongoRepository 등은 데이터베이스에 요청을 보내고 그 결과를 Entity 형태로 반환한다. Collection, Document에 필요한 데이터베이스 metadata를 어노테이션 등으로 제공 ReactiveMongoTemplate # ReactiveMongoTemplate은 Spring data mongodb reactive의 추상화 클래스 Mongo 쿼리들을 Bson 형태로 넘기거나 PojoCodec, Custom codec 등을 등록하지 않아도, 메소드 체이닝을 통해서 쿼리를 수행하고 결과를 entity 객체로 받을 수 있다 ReactiveMongoOperations를 구현 MongoTemplate 생성 # MongoClient와 databaseName을 전달하여 생성 가능 spring에서는 ReactiveMongoDatabaseFactory와 MongoConverter을 주입받아 생성 ReactiveMongoOperations # ReactiveMongoTemplate의 operations를 담당하는 interface ReactiveFluentMongoOperations를 상속하고 MongoConverter 제공 MongoConverter: 주어진 Document를 Entity로 만드는 converter ReactiveMongoDatabaseFactory # getMongoDatabase: MongoDatabase를 반환 getCodecRegistry: bson의 CodecRegistry를 반환 ReactiveMongoTemplate은 ReactiveMongoDatabaseFactory의 MongoDatabase를 통해서 MongoCollection에 접근 ReactiveMongoTemplate 구현 # ReactiveMongoTemplate은 createMono 혹은 createFlux를 이용하여 MongoCollection을 획득 ReactiveMongoTemplate 구현 # createFlux를 이용하여 collectionName과 callback을 전달 callback에서 Publisher를 반환 이런 방식으로 여러 operations를 구현 MongoConverter # MongoWriter(EntityWriter를 상속), EntityReader를 구현\n구현체로 MappingMongoConverter 다양한 전략을 통해서 Object \u0026lt;-\u0026gt; document 변환\ncustom converter로 mapping Spring data의 object mapping convention 기반의 mapping metadata 기반의 mapping Custom converter mapping # Configuration를 통해서 converter들을 등록 데이터베이스에 읽고 쓰기를 하기 위해 두개의 Converter가 필요 bson.Document -\u0026gt; Target 클래스로 변환하는 Converter Target -\u0026gt; bson.Document로 변환하는 Converter ReadConverter # Document -\u0026gt; source, Entity -\u0026gt; target으로 하는 Converter Document로부터 name으로 field에 접근할 수 있고, 변환하고나 type에 해당하는 메서드 호출 WriteConverter # Entity -\u0026gt; source, Document -\u0026gt; target으로 하는 Converter Document에 값을 추가 put을 통해서 field의 이름, value 순으로 전달 Document를 데이터베이스에 전달 위 CustomConverter 등록 # AbstractMongoClientConfiguration를 상속하는 Configuration 생성 AbstractR2dbcConfiguration의 configureConverters에 custom converter들을 register References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":33,"href":"/docs/mongodb/004_object_mapping/","title":"004 Object Mapping","section":"Mongodb","content":" Object mapping # Spring data의 object mapping # 만약 지원하는 converter가 없다면 MappingMongoConverter는 다음 과정을 거쳐서 Document를 entity로 변환 Object creation constructor, factory method 등을 이용해서 Document의 field들로 Object 생성 Property population setter, with.. 메소드 등을 이용해서 Document의 field를 Object에 주입 Object creation # 다음 순서로 체크하여 해당하는 알고리즘으로 Document를 Object로 변환 @PersistenceCreator 어노테이션을 갖는 constructor가 있다면 해당 constructor 사용 인자가 없는 constructor가 있다면 해당 constructor 사용 constructor가 정확히 하나 있다면 해당 constructor 사용 id mapping # mongodb에서 모든 document는 _id를 필요 MappingMongoConverter는 다음의 방법으로 _id를 감지 @Id가 붙어있는 필드 필드명이 id이고 @Field를 통해서 별도의 이름이 부여되지 않은 경우 id 필드가 제공되지 않는 경우, 자동으로 추가 Property population # r2dbc에서는 property가 mutable할때만 property population 적용이 가능했지만, mongodb에서는 with 메소드 지원 No-args constructor를 호출하여 텅 빈 객체를 만들고, gender를 제외한 나머지 필드는 reflection으로 진행 gender는 withGender 메소드 호출 Metadata Mapping # Entity 클래스에 annotation을 추가하여 데이터베이스와 관련된 설정들을 주입 @Id: _id에 해당하는 필드에 적용 @Document: entity class에 적용. Collection 이름을 변경 가능 @DBRef: mongodb의 DBRef 형태로 저장해야 하는 필드 @Indexed: 필드에 대해서 인덱스를 생성. 기본적으론 자동 생성이 비활성화이므로 별도로 설정 필요 @CompoundIndex: 클래스에 적용. 여러 필드로 구성된 복합 인덱스 제공 @TextIndexed: 필드에 text index를 적용 @HashIndexed: 필드에 hash index를 적용 @Transient: 기본적으로 모든 필드는 mapping 대상. @Transient가 붙은 필드는 mapping에서 제외. @Field: entity의 property 필드에 적용. @Field가 붙은 필드에 대해서는 convention 기반 대신 Field에 주어진 name으로 적용 @Version: 낙관적 잠금 (Optimistic Lock)에 이용. entity가 update 될때마다 자동으로 update @PersistenceConstructor: 특정 constructor에 대해서 Object creation할 때 사용하게끔 지정. constructor의 argument 이름에 따라서 mapping References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":34,"href":"/docs/mongodb/005_mongoOperations/","title":"005 Mongo Operations","section":"Mongodb","content":" ReactiveMongoOperations # ReactiveMongoOperations # ReactiveFluentMongoOperations를 상속 ReactiveFluentMongoOperations는 여러 Operations를 상속 ReactiveFindOperation: find query와 관련된 메서드 제공 ReactiveInsertOperation: insert query와 관련된 메서드 제공 ReactiveUpdateOperation: update query와 관련된 메서드 제공 ReactiveRemoveOperation: delete query와 관련된 메서드 제공 ReactiveAggregationOperation: aggregation query와 관련된 메서드 제공 ReactiveChangeStreamOperation: watch query와 관련된 메서드 제공 ReactiveFindOperation # ReactiveFindOperation의 query 부터 시작 TerminatingFind의 count, exists, first, one, all, tail 등으로 종료 query -\u0026gt; inCollection -\u0026gt; as -\u0026gt; matching -\u0026gt; 최종 query -\u0026gt; inCollection -\u0026gt; matching -\u0026gt; 최종 query -\u0026gt; as -\u0026gt; matching -\u0026gt; 최종 query -\u0026gt; matching -\u0026gt; 최종 query -\u0026gt; 최종 ReactiveFindOperation # inCollection query를 실행할 collection 이름을 전달 제공되지 않을 경우 domain Type의 class 이름 통해 collection 이름 획득 @Document 어노테이션 통해 collection 이름 획득 as Entity를 전부 mapping하지 않고 특정 필드만 mapping 하고 싶은 경우 Entity의 일부 property만 담고 있는 subclass 또는 interface를 넘겨서 projection projection이 제공되지 않는다면 Entity에 모든 필드를 mapping matching query의 filter에 해당 Query를 전달하여 filter에 들어갈 내용을 설정 matching을 생략하면 collection 전체에 대한 요청을 보내는 것과 동일 최종 마지막으로 count, exists, first, one, all, tail 등의 연산을 선택 count: 조건에 맞는 document의 개수 반환 exists: 조건에 맞는 document 존재 여부 반환 first: 조건에 맞는 첫 번째 document 반환 one: 조건에 맞는 하나의 document 반환. 하나가 넘으면 exception all: 조건에 맞는 모든 document 반환 tail: cursor를 이용하여 조건에 해당하는 document를 지속적으로 수신 ReactiveFindOperation 실행 # MongoClient를 이용하여 ReactiveMongoTemplate을 생성 Query와 Criteria를 이용해서 query 생성 PersonNameOnlyDocument class를 이용해서 id와 name만 projection ReactiveInsertOperation # ReactiveInsertOperation의 insert 부터 시작하여 TerminatingInsert의 one, all로 종료 insert -\u0026gt; into -\u0026gt; (one, all) insert -\u0026gt; (one, all) ReactiveInsertOperation # one insert query에 이용할 entity 하나를 전달 주어진 entity를 Document로 변환하고 insert 결과를 Mono로 반환 all bulk insert 지원 주어진 entity Collection -\u0026gt; Document Collection으로 변환하고 insert 결과를 flux로 반환 ReactiveInsertOperation 실행 # inCollection을 통해서 insert할 collection 명시 entity를 생성하여 all에 전달 ReactiveUpdateOperation # ReactiveUpdateOperation의 update 부터 시작 update, findAndModify, findAndReplace 지원 findAndReplace # Document를 찾고 다른 Document로 대체 쿼리를 실행하고 그 결과를 Mono로 반환 replaceWith : 대상을 찾게되었을때 대체할 객체를 제공 withOptions : findAndReplace에 대한 옵션 제공 returnNew : true -\u0026gt; 대체된 document를 반환, false(default) -\u0026gt; 기존 document를 반환 upsert : true -\u0026gt; 조건에 만족하는 document가 없는 경우 insert, false -\u0026gt; 존재하는 경우에만 as : 값을 대체한 후 그 결과를 전부 mapping하지 않고 특정 필드만 mapping 하고 싶은 경우 findAndModify # 값을 찾아서 update 하고 그 결과를 Mono로 변환 withOptions : findAndModify에 대한 옵션 제공 returnNew : true -\u0026gt; 대체된 document를 반환, false(default) -\u0026gt; 기존 document를 반환 upsert : true -\u0026gt; 조건에 만족하는 document가 없는 경우 insert, false -\u0026gt; 존재하는 경우에만 remove : true -\u0026gt; update 대신 delete 수행 update # apply : update를 수행 insert와 다르게 Entity가 아닌 Update 객체 전달 Update 객체의 update, fromDocument 등을 통해서 생성 set, unset, setOrInsert, inc, push, pop, pull, rename, currentDate, multiply 등의 연산 지원\\ all : 조건을 만족하는 모든 document에 대해 update first : 조건을 만족하는 첫 document에 대해서 update upsert: 조건을 만족하는 document가 있다면 update하고 없다면 새로 생성 findAndReplace 실행 # inCollection을 통해서 update할 collection 명시 matching으로 update 영향을 받는 document 제한 returnNew 옵션 제공 findAndModify 실행 # inCollection을 통해서 update할 collection 명시 matching으로 update 영향을 받는 document 제한 Update 객체로 여러 필드 수정 update 실행 # inCollection을 통해서 update할 collection 명시 조건을 만족하는 document가 없게 만듬 Update 객체로 여러 필드 수정 upsert로 새로 추가 upsert: 조건을 만족하는 document가 있다면 update하고 없다면 새로 생성 ReactiveRemoveOperation # ReactiveRemoveOperation의 remove 부터 시작하여 TerminatingRemove의 all, findAndRemove으로 종료 remove -\u0026gt; inCollection -\u0026gt; matching -\u0026gt; 실행 remove -\u0026gt; inCollection -\u0026gt; 실행 remove -\u0026gt; matching -\u0026gt; 실행 remove -\u0026gt; 실행 ReactiveAggregationOperation # ReactiveAggregationOperation의 aggregateAndReturn 부터 시작하여 TerminatingAggregationOperation의 all로 종료 aggregateAndReturn -\u0026gt; inCollection -\u0026gt; by -\u0026gt; all aggregateAndReturn -\u0026gt; by -\u0026gt; all ReactiveChangeStreamOperation # ReactiveChangeStreamOperation의 changeStream 부터 시작하여 TerminatingChangeStream의 listen로 종료 withOptions: changeStream과 관련된 옵션 제공 filter: stream을 listen하는 동안 filter할 대상 as: stream의 결과로 mapping할 Class 제공 resumeAt: 주어진 Token부터 listen 재개 resumeAfter: 주어진 Token 이후부터 listen 재개 startAfter: 주어진 Token부터 listen 새로 시작 mongoTemplate.changeStream(ChatDocument.class) .listen() .doOnNext(item -\u0026gt; { ChatDocument target = item.getBody(); OperationType operationType = item.getOperationType(); log.info(\u0026#34;target: {}\u0026#34;, target); log.info(\u0026#34;type: {}\u0026#34;, operationType); if (target != null \u0026amp;\u0026amp; operationType == OperationType.INSERT) { String from = target.getFrom(); String to = target.getTo(); String message = target.getMessage(); doSend(from, to, message); } }) .subscribe(); ReactiveMongoOperations # ReactiveFluentMongoOperations에서 제공하는 조합 방식 대신 다양한 쿼리를 수행하는 단축 메소드 제공 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":35,"href":"/docs/mongodb/006_reactiveMongoRepository/","title":"006 Reactive Mongo Repository","section":"Mongodb","content":" ReactiveMongoRepository # ReactiveMongoRepository # ReactiveSortingRepository, ReactiveQueryByExampleExecutor를 상속한 interface SimpleReactiveMongoRepository에서 구현 ReactiveMongoRepository 등록 # MongoReactiveRepositoriesAutoConfiguration가 활성화되어 있다면 SpringBootApplication 기준으로 자동으로 scan 혹은 EnableReactiveMongoRepositories를 통해서 repository scan SimpleReactiveMongoRepository # ReactiveMongoRepository를 구현 ReactiveMongoOperations를 기반으로 Mongo 쿼리를 실행하고 결과를 Entity로 mapping save # save mongoOperations의 insert 혹은 update를 이용 새로운 entity라면 insert, 아니라면 update, Id 필드가 null이라면 new saveAll concatMap을 이용하여 save를 순차적으로 실행 전부 new entity라면 bulkInsert, 아니라면 각각을 save @Transactional이 없는 점 find # findById, existsById, count 모두 ReactiveMongoOperations에서 제공하는 단축 메소드 (findById, exists, count) 사용 delete # ReactiveMongoOperations에서 제공하는 단축 메소드 (remove) 사용 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":36,"href":"/docs/mongodb/007_query_method/","title":"007 Query Method","section":"Mongodb","content":" Query method # 쿼리 메소드 (Query method) # ReactiveMongoRepository를 상속한 repository interface에 메소드를 추가 메소드의 이름을 기반으로 Query 생성 조회, 삭제 지원 @Query, @Update, @Aggregation 어노테이션을 사용해서 복잡한 쿼리 실행 가능 쿼리 메소드 - find # id 뿐만 아니라 다른 필드를 이용해서 조회 가능 first 등의 키워드를 사용해서 query에 limit 제공 가능 기존의 Entity 뿐만 아니라 Projection을 사용하여 일부 필드만 조회 가능 사용예제\nfindFirstByNameOrderByAgeDesc name이 “taewoo”인 row들을 찾고 age 내림차순으로 sort 하여 limit을 1로 모든 field를 조회하여 PersonDocument class로 mapping 쿼리 메소드 - delete # 다른 필드를 이용해서 삭제 가능 여러 반환 타입 지원 Long: 영향을 받은 row 수 반환 Flux: 삭제된 document 반환 사용예제\ndeleteByAgeGreaterThan age가 100 초과인 document를 찾고 삭제한 후 영향을 받은 document가 있다면 Flux 형태로 반환 쿼리 메소드 시작 키워드 # find, read, get, query, search, stream find 쿼리를 실행하고 결과를 Publisher으로 반환 exists find exists 쿼리를 실행하고 결과를 Publisher으로 반환 count find count 쿼리를 실행하고 결과를 Publisher으로 반환 delete, remove delete 쿼리를 실행하고 Publisher 혹은 publisher로 삭제된 개수 반환 First, Top 쿼리의 limit을 N으로 설정. find와 By 사이 어디에든 등장 가능 Distinct distinct 기능을 제공. find와 By 사이 어디에든 등장 가능 쿼리 메소드 지원 키워드 # And: $and Or: $or After: $gt Before: $lt Containing,:regex로 제공 (String), $in (Collection) Between, IsBetween: $gt, $lt EndingWith: regex로 제공 Exists: $exists False, IsFalse: false와 비교 GreaterThan: $gt GreaterThanEqual: $gte In: $in NotNull, IsNotNull: $ne:null Null, IsNull: null LessThan: $lt LessThanEqual: $lte Like: regex로 제공 Near: $near Not: $not NotIn: $nin NotLike, IsNotLike: $not Regex,: $regex StartingWith: regex로 제공 True, IsTrue: true와 비교 Within, IsWithin: $geoWithin OrderBy: 주어진 property path와 direction에 따라서 쿼리에 Sort 제공 쿼리 메소드 - @Query # query가 메소드 이름으로 전부 표현이 되지 않는 경우 쿼리 메소드 예약어에서 지원되지 않는 문법을 사용하는 경우 복잡한 query문을 사용하는 경우 @Update와 조합하여 update를 수행 쿼리 메소드 - @Aggregate # @Aggregate를 이용해서 mongo aggregate수행 pipeline들을 array 형태로 전달 각각의 pipeline이 순차적으로 수행되고 인자로 넘긴 값들이 사용 사용예제\naggregateGroupByName 2개의 aggregate pipeline 포함 name이 주어진 인자와 같은 document만 필터 name으로 group 하여 count @Transactional # @Transactional를 사용하여 여러 query를 묶어서 진행 새로운 Entity를 만들어서 save하고 update한 후 findAll을 통해서 모든 document 반환 TransactionalOperator # transactional 메소드를 통해서 주어진 Flux 혹은 Mono를 transaction 안에서 실행 flux를 바로 반환하지 않고 transactionalOperator의 transactional로 wrapping 하여 전달\n혹은 execute를 통해서 TransactionCallback 형태로 실행 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":37,"href":"/docs/mongodb/001_reactive_mongodb/","title":"001 Reactive Mongodb","section":"Mongodb","content":" Reactive MongoDB driver # MongoDB driver # MongoDB사에서 공식적인 2가지 java driver를 제공 Sync Driver Reactive Streams Driver Sync driver # 동기적으로 동작 클라이언트 요청을 보내면 응답이 돌아오기 전까지 쓰레드가 blocking 메서드가 응답 객체를 바로 반환 -\u0026gt; 직관적 쓰레드 동시성 문제 발생 가능성 Reactive Streams driver # 비동기적으로 동작 클라이언트가 요청을 보내면 쓰레드는 non-blocking 모든 응답이 publisher를 이용해서 전달되기 때문에 처리하기 어렵다. Spring reactive stack과 함께 사용되어 높은 성능, 안정성 제공 Spring Data MongoDB Reactive, REactive Streams MongoDB Driver # Mongo Reactive streams driver # MongoCollection 획득 # MongoDB의 MongoClient, MongoDatabase, MongoCollection MongoClient MongoDB 클러스터를 가리키는 객체 (MongoDatabase factory 역할) MongoDatabase Mongo의 Database를 가리킨다. Codec, WriteConcern, ReadPreference 등의 정보를 포함 collection 이름을 인자로 받고 MongoCollection 제공 MongoCollection MongoDB의 Collection mongodb commands를 실행 MongoCollection 획득 예제 # ConnectionString을 이용해서 MongoDB 연결 정보를 String 형태로 제공 MongoClientSettings builder에 Connection 정보를 전달 MongoClientSettings로 MongoClient 생성 MongoClient로 MongoDatabase 접근 MongoDatabase로 MongoCollection 접근 MongoCollection - count # ClientSession을 통해서 multi document transaction 제공 다양한 수행건들의 트랜잭션을 ClientSession을 사용해서 하나로 묶을 수 있음 Bson 구현체 (BsonDocument 등)로 filter 제공 CountOptions로 hint, limit, skip, maxTime, collation 등의 정보 제공 // CountOptions를 사용하여 옵션 설정 CountOptions countOptions = new CountOptions(); countOptions.skip(10); // 처음 10개 문서 제외하고 count countOptions.limit(20); // 최대 20개의 문서만 count countOptions.maxTime(5000); // 최대 수행 시간 (5초) // countDocuments 메서드에 CountOptions 적용 long documentCount = collection.countDocuments(countOptions); System.out.println(\u0026#34;Total documents in the collection: \u0026#34; + documentCount); MongoCollection - find # Filters helper 클래스를 통해서 filter 설정 가능 eq, ne, gt, gte, lt, lte, in, nin, and, or, not, nor, exists, type, mod, regex, text 등의 기본 연산자 제공 geoWithin, geoWithinBox 등의 geo 연산자도 제공 // Filters를 사용한 쿼리 조건 생성 // 예: age가 30 이상인 문서 검색 FindIterable\u0026lt;Document\u0026gt; result = collection.find(Filters.gte(\u0026#34;age\u0026#34;, 30)); // 결과 출력 for (Document document : result) { System.out.println(document.toJson()); } aggregate # pipeline을 생성하고 mongo shard 전체에 대해서 필터, 집계, 그룹 등의 연산을 수행 MongoCollection - aggregate # Aggregates helper 클래스를 통해서 aggregate pipeline 제공 addFields, set, bucket, bucketAuto count, match, project, sort, sortByCount skip, limit, lookup facet, graphLookup, group, unionWith, unwind, out, merge, replaceRoot, replaceWith, sample 등 AggregatePublisher를 반환 // MongoDB 연결 설정 AggregatePublisher\u0026lt;Document\u0026gt; publisher = MongoClients.create() .getDatabase(\u0026#34;your_database_name\u0026#34;) .getCollection(\u0026#34;your_collection_name\u0026#34;, Document.class) .aggregate(Arrays.asList( new Document(\u0026#34;$group\u0026#34;, new Document(\u0026#34;_id\u0026#34;, \u0026#34;$city\u0026#34;).append(\u0026#34;totalPopulation\u0026#34;, new Document(\u0026#34;$sum\u0026#34;, \u0026#34;$population\u0026#34;))), new Document(\u0026#34;$sort\u0026#34;, new Document(\u0026#34;totalPopulation\u0026#34;, -1)), new Document(\u0026#34;$limit\u0026#34;, 5) )); // 결과 처리 publisher.subscribe( document -\u0026gt; System.out.println(document.toJson()), throwable -\u0026gt; System.err.println(\u0026#34;Error: \u0026#34; + throwable.getMessage()), () -\u0026gt; System.out.println(\u0026#34;Aggregation completed\u0026#34;) ); MongoCollection - watch # Aggregates helper 클래스를 통해서 aggregate pipeline 제공 addFields, match, project, replaceRoot, replaceWith, redact, set, unset 지원 ChangeStreamPublisher를 반환하고 해당 Publisher를 subscribe ChangeStreamDocument를 onNext로 전달 resumeToken, 변경사항이 발생한 document 혹은 _id // ChangeStreamPublisher를 얻어옴 Publisher\u0026lt;ChangeStreamDocument\u0026lt;Document\u0026gt;\u0026gt; changeStreamPublisher = mongoCollection.watch(); // Publisher를 사용하여 Subscriber에게 변경 사항을 알림 changeStreamPublisher.subscribe(new ExampleSubscriber()); MongoCollection - bulkWrite # Delete, Insert, Replace, Update 등을 모아서 한번에 실행하는 operation WriteModel DeleteManyModel: 조건을 만족하는 document를 모두 삭제 DeleteOneModel: 조건을 만족하는 document를 최대 1개만 삭제 InsertOneModel: 하나의 document를 추가 ReplaceOneModel: 조건을 만족하는 document를 최대 1개만 대체 UpdateManyModel: 조건을 만족하는 document를 모두 수정 UpdateOneModel: 조건을 만족하는 document를 최대 1개만 수정 // BulkWrite 작업 생성 List\u0026lt;WriteModel\u0026lt;Document\u0026gt;\u0026gt; bulkOperations = new ArrayList\u0026lt;\u0026gt;(); // 삽입 작업 Document document1 = new Document(\u0026#34;_id\u0026#34;, 1).append(\u0026#34;name\u0026#34;, \u0026#34;John\u0026#34;); InsertOneModel\u0026lt;Document\u0026gt; insertOneModel1 = new InsertOneModel\u0026lt;\u0026gt;(document1); bulkOperations.add(insertOneModel1); // 업데이트 작업 Document filter = new Document(\u0026#34;_id\u0026#34;, 2); Document update = new Document(\u0026#34;$set\u0026#34;, new Document(\u0026#34;age\u0026#34;, 25)); UpdateOneModel\u0026lt;Document\u0026gt; updateOneModel = new UpdateOneModel\u0026lt;\u0026gt;(filter, update); bulkOperations.add(updateOneModel); // 삭제 작업 DeleteOneModel\u0026lt;Document\u0026gt; deleteOneModel = new DeleteOneModel\u0026lt;\u0026gt;(Filters.eq(\u0026#34;_id\u0026#34;, 3)); bulkOperations.add(deleteOneModel); // BulkWrite 수행 BulkWriteResult result = mongoCollection.bulkWrite(bulkOperations); MongoCollection - insert # 하나 혹은 여러 document를 추가하는 operation InsertOneOptions, InsertManyOptions validation 우회 여부를 결정 InsertManyOptions라면 insert의 순서를 보장할지 결정 InsertOneResult, InsertManyResult wasAcknowledged() : write 성공 여부 getInsertedIds() : write된 id들을 제공 // 삽입할 문서 생성 Document document = new Document(\u0026#34;_id\u0026#34;, 1) .append(\u0026#34;name\u0026#34;, \u0026#34;John\u0026#34;) .append(\u0026#34;age\u0026#34;, 30) .append(\u0026#34;city\u0026#34;, \u0026#34;New York\u0026#34;); // 검사 우회 옵션 추가 Document options = new Document(\u0026#34;bypassDocumentValidation\u0026#34;, true); // 컬렉션에 문서 삽입 (검사 우회) mongoCollection.insertOne(document, options); InsertOneOptions\n// InsertOneOptions를 사용한 단일 문서 삽입 옵션 설정 InsertOneOptions insertOneOptions = new InsertOneOptions(); insertOneOptions.bypassDocumentValidation(true); // 데이터 유효성 검사 우회 // 단일 문서 삽입 Document document = new Document(\u0026#34;_id\u0026#34;, 1) .append(\u0026#34;name\u0026#34;, \u0026#34;John\u0026#34;) .append(\u0026#34;age\u0026#34;, 30); mongoCollection.insertOne(document, insertOneOptions); InsertManyOptions\n// InsertManyOptions를 사용한 다수의 문서 삽입 옵션 설정 InsertManyOptions insertManyOptions = new InsertManyOptions(); insertManyOptions.ordered(false); // 순서 무시 // 다수의 문서 삽입 List\u0026lt;Document\u0026gt; documents = Arrays.asList( new Document(\u0026#34;_id\u0026#34;, 2).append(\u0026#34;name\u0026#34;, \u0026#34;Jane\u0026#34;).append(\u0026#34;age\u0026#34;, 25), new Document(\u0026#34;_id\u0026#34;, 3).append(\u0026#34;name\u0026#34;, \u0026#34;Bob\u0026#34;).append(\u0026#34;age\u0026#34;, 35) ); mongoCollection.insertMany(documents, insertManyOptions); MongoCollection - update # 하나 혹은 여러 document를 수정하는 operation Filters helper 클래스를 통해서 filter 설정 가능 Updates helper 클래스를 통해 update 설정 가능 UpdateOptions를 통해서 upsert, hint, collation, variables 등 제공 // 업데이트 옵션 설정 UpdateOptions options = new UpdateOptions(); options.upsert(true); // 일치하는 문서가 없을 경우 삽입 (upsert) // 업데이트 작업 수행 mongoCollection.updateOne(eq(\u0026#34;name\u0026#34;, \u0026#34;John\u0026#34;), set(\u0026#34;age\u0026#34;, 31), options); MongoCollection - atomic # findOneAndDelete, findOneAndReplace, findOneAndUpdate 등 find와 write를 묶어서 atomic한 operation 제공 트랜잭션 내에서 수행되는 각 작업은 clientSession을 통해 수행 MongoCollection - index # Collection에서 특정 필드들에 대한 index 생성, 조회, 삭제 가능\nIndexes helper 클래스를 통해서 다양한 index 제공 IndexModel과 IndexOptions를 통해서 어떤 필드들에 대해서 어떻게 Index를 적용할 것인지 설정 가능\nbackground: index의 생성을 background에서 진행할지 여부 unique: unique index를 생성할지 여부 name: index에 name 설정 partialFilterExpression: 특별한 조건을 충족한 경우에만 index를 걸고 싶은 경우 설정 // IndexModel을 사용하여 색인 정의 IndexModel indexModel = new IndexModel( new Document(\u0026#34;field1\u0026#34;, 1), // 1은 오름차순, -1은 내림차순 new Document(\u0026#34;field2\u0026#34;, -1) ); // IndexOptions를 사용하여 색인 옵션 설정 IndexOptions indexOptions = new IndexOptions(); indexOptions.name(\u0026#34;custom_index_name\u0026#34;); // 색인의 이름 설정 indexOptions.unique(true); // 고유 색인 설정 indexOptions.background(true); // 비동기적으로 색인 생성 // 색인 생성 mongoCollection.createIndex(indexModel, indexOptions); References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":38,"href":"/docs/mongodb/002_mongodb_document/","title":"002 Mongodb Document","section":"Mongodb","content":" Reactive MongoDB Document # Document # MongoCollection에 query를 실행하여 bson의 Document를 반환 bson의 Document : Map\u0026lt;String, Object\u0026gt;를 구현하고 내부에 LinkedHashMap을 저장하여 Map 메서드 override Document 예제 # collection에서 findAll query를 실행 결과를 subscribe하여 onNext로 출력 모든 결과를 찾은 후, onComplete 이벤트로 종료 MongoDB BSON 인코딩 # 첫 줄은 전체 document의 크기를 가리킨다 데이터타입, 필드명, 길이(데이터 타입에 따라 optional), 값으로 구성 BSON Codec # bson 라이브러리는 Codec을 제공 Codec을 통해서 특정 java type이 주어졌을때 어떻게 encode, docode 해야할지 지정 Default codec # MongoClientSettings에서 Default codec을 제공 Java 자체 클래스와 관련된 codec들 IterableCodecProvider: Iterable 클래스 지원 MapCodecProvider: Map 클래스 지원 ValueCodecProvider: Java에서 제공하는 클래스 지원 Jsr310CodecProvider: Instant, LocalDate, LocalDateTime 등 Date, Time 관련 클래스 지원 EnumCodecProvider: Enum 지원 Jep395RecordCodecProvider: Record 지원 Bson과 관련된 codec들 BsonValueCodecProvider: Bson 타입들을 java로 1대1 맵핑한 클래스 지원 DBRefCodecProvider: DBRef 지원 DBObjectCodecProvider: DBObject 지원 DocumentCodecProvider: Document 지원 GeoJsonCodecProvider: Geometry, LineString, MultiPoint, Point, Polygon 등의 geojson 지원 GridFSFileCodecProvider: GridFSFile 지원 JsonObjectCodecProvider: JsonObject 지원 BsonValueCodecProvider # Bson 타입들과 1 대 1 매칭 BsonNull, BsonUndefined BsonBinary BsonBoolean BsonDateTime, BsonTimestamp BsonDBPointer BsonDouble, BsonInt32, BsonInt64, BsonDecimal128 BsonMinKey, BsonMaxKey BsonJavaScript BsonObjectId BsonRegularExpression BsonString, BsonSymbol ValueCodecProvider # Java 타입들을 지원 Binary (byte[]), Byte, ByteArray (byte[]) Boolean, AtomicBoolean Date Short, Float, Double, Integer, Long, Decimal128, BigDecimal, AtomicInteger, AtomicLong MinKey, MaxKey Code (javascript code) ObjectId Pattern Character, String, Symbol Codec 예제 - StringCodec # String을 binary로 encode 만약 변환 대상이 Bson.STRING 라면 그대로 write 만약 변환 대상이 Bson.OBJECT_ID 라면 ObjectId로 변환해서 write binary를 String으로 decode 만약 Bson.STRING 에서 String 으로 변환하는 경우 readString 혹은 readSymbol 만약 Bson.OBJECT_ID 에서 String으로 변환하는 경우 readObjectId 후 hexString으로 변환 PojoCodec # 주어진 POJO (Plain old java object)를 bson으로 bson을 POJO로 자동 변환하는 Codec PojoCodec은 기본으로 추가되지 않으므로 별도로 추가 필요 PojoCodec 등록 # PojoCodecProvider builder를 이용하여 automatic을 true로 제공 automatic을 true로 제공해야만 pojo 변환을 지원 getCollection의 2번째 인자로 PersonDocument 제공 Document 대신 PersonDocument로 find Custom Codec # Codec 인터페이스를 직접 구현 reader의 readObjectId, readString 등을 사용하면 하나의 필드를 읽고 java 클래스로 mapping 만약 encode 되어있는 필드 순서와 read하는 순서가 다르면 exception 발생 가능 이를 위해 readName을 호출하여 필드 이름을 파악한 후 해당 필드 이름과 매칭되는 readXX 메소드 호출도 가능 Custom Codec 등록 # fromCodecs를 이용하여 custom codec을 CodecRegistry로 변형 해당 CodecRegistry를 fromRegistries로 settings에 등록 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":39,"href":"/docs/batch/001_performance_improved_batch/","title":"001 Performance Improved Batch","section":"Batch","content":" [tech blog 읽기] 누구나 할 수 있는 10배 더 빠른 배치 만들기 # 우아한형제들 셀러 시스템 배치 개선 이야기 # 우아한형제들 기술 블로그의 글을 읽으면서 정리해본다.\n최근 셀러시스템팀에서 하루 한 번 주기로 실행되는 배치를 최적화하는 과제를 진행한 내용에 대한 포스팅이다.\n비운영 시간 데이터 # 셀러시스템에서는 가게와 업주에 대한 다양한 데이터를 관리 사장님들의 관리 사항 \u0026lsquo;가게가 운영하는지 안하는지\u0026rsquo;에 대한 정보를 유관 부서에 전달한다. \u0026lsquo;비운영시간 데이터\u0026rsquo; 실시간으로 수정되는 정보를 반영 매일 새벽에 전체 데이터를 계산하고 그 결과를 미리 갱신해둔 후, 유관부서에 전파 다양한 채널에서 입력되는 각족 운영과 휴무 데이터를 취합해서 비운영시간 데이터를 계산 위 계산된 데이터가 클라이언트까지 잘 전달될 수 있도록 각 지면에 적절한 형태로 가공하여 제공 문제상황 # 새벽에 배치 작업을 할때, 수많은 가게의 데이터를 매일 갱신하므로 배치 수행시간이 오래걸린다. 배포 예정 시간과 배치 실행 시간이 겹칠 경우, 배포가 여러번 복잡한 절차를 밟아 진행해야한다. (잠재적인 리스크) 배치 성능 개선이 필요 I/O 최적화 # I/O 병목을 먼저 살펴본다. I/O (Input / Output) 병목이란? 컴퓨팅에서 부하를 설명할 때에는 크게 CPU 부하와 I/O 부하로 나뉩니다. 데이터를 계산하고 처리하는 과정인 CPU 부하와 달리, I/O 부하는 디스크에 파일을 읽고 쓰거나 DB 및 외부 컴포넌트와 통신하는 과정에서 발생합니다. I/O 병목은 이러한 I/O 부하가 시스템의 전체적인 효율성을 떨어뜨리는 부분을 말합니다.\n배치에서 사용하는 I/O 부하 중 가장 핵심은 DB 쿼리였다. 원인 : JPA 지연 로딩으로 설정된 연관 관계 엔티티를 가져오는 과정에서 N+1 문제가 발생 데이터가 모두 1:N 구조의 연관관계로 설정되어 있어서 관련 데이터를 가져오는데에 오랜 시간이 걸린다. 해결\n연관관계로 설정된 엔티티의 종류가 많고 실제 연관관계 데이터의 수정은 불필요하다는 점 등을 고려하여, 각 엔티티 정보를 연관관계를 통해 가져오는 것이 아닌 별도 쿼리 호출을 통해 명시적으로 한 번에 읽어오게끔 수정 Before\npublic List\u0026lt;LiveShopClose\u0026gt; generateLiveShopClose(Shop shop, LocalDate startDate, LocalDate endDate) { final List\u0026lt;ShopCalendar\u0026gt; shopCalendars = shopCalendarRepository.findAllByCalendarDateBetween(startDate, endDate); final List\u0026lt;ShopTemporaryClosed\u0026gt; shopTemporaryCloses = shop.getActiveShopTemporaryClosed(); final List\u0026lt;ShopClosed\u0026gt; shopCloses = shop.getActiveShopClosed(); final List\u0026lt;ShopOperationHour\u0026gt; operationHours = shop.getShopOperationHourIsType(OperationHourType.OPERATION); return /* LiveShopClose 데이터 생성 */ } After\nList\u0026lt;LiveShopClose\u0026gt; generateLiveShopCloses(List\u0026lt;Long\u0026gt; shopNos, LocalDate startDate, LocalDate endDate) { List\u0026lt;ShopNo\u0026gt; shopNoEntities = shopNos.stream().map(ShopNo::new).collect(Collectors.toList()); List\u0026lt;ShopCalendar\u0026gt; shopCalendars = shopCalendarRepository.findAllByCalendarDateBetween(startDate, endDate); Map\u0026lt;Long, List\u0026lt;ShopTemporaryClosed\u0026gt;\u0026gt; activeShopTemporaryClosedMap = shopTemporaryClosedRepository.findActiveByShopNos(shopNoEntities).stream() .collect(groupingBy(ShopTemporaryClosed::getShopNo, Collectors.toList())); Map\u0026lt;Long, List\u0026lt;ShopClosed\u0026gt;\u0026gt; activeShopClosedMap = shopClosedRepository.findActiveByShopNos(shopNoEntities).stream() .collect(groupingBy(ShopClosed::getShopNo, Collectors.toList())); Map\u0026lt;Long, List\u0026lt;ShopOperationHour\u0026gt;\u0026gt; operationHoursMap = shopOperationHoursRepository.findOperationHoursByShopNos(shopNoEntities).stream() .collect(groupingBy(ShopOperationHour::getShopNo, Collectors.toList())); return shopNos.stream() .flatMap(shopNo -\u0026gt; generateLiveShopClose( shopNo, shopCalendars, ListUtils.emptyIfNull(activeShopTemporaryClosedMap.get(shopNo)), ListUtils.emptyIfNull(activeShopClosedMap.get(shopNo)), ListUtils.emptyIfNull(operationHoursMap.get(shopNo)) ).stream()) .collect(Collectors.toList()); } List\u0026lt;LiveShopClose\u0026gt; generateLiveShopClose(Long shopNo, List\u0026lt;ShopCalendar\u0026gt; shopCalendars, List\u0026lt;ShopTemporaryClosed\u0026gt; activeShopTemporaryCloses, List\u0026lt;ShopClosed\u0026gt; activeShopCloses, List\u0026lt;ShopOperationHour\u0026gt; operationHours) { return /* LiveShopClose 데이터 생성 */ } 도메인 로직 및 기타 최적화 # 현재 가게의 비운영시간 데이터가 업데이트될 경우, 변경된 가게에 대한 이벤트를 발행 기존 로직에서는 실제 데이터의 변경 여부와는 관계없이 D-1~D+2 데이터를 무조건 재생성하기 때문에, 실제로는 데이터가 변경되지 않을 테지만 다시 데이터가 생성되어 변경 이벤트가 전송되는 케이스 존재 대응 : 이러한 케이스에 대응하여 데이터가 바뀌었는지 여부를 확인한 후 실제로 바뀐 경우에만 변경 사항을 적용 효과 : 변경 이벤트로 인한 간접적인 부하 개선 최적화 검토 # 성능 효율을 높이기 위해 컴퓨팅 업계에서는 많은 죄악이 저질러지는데(심지어 효율적이지조차 않을 때도 있다) 그 수는 그냥 멍청해서 저지르는 죄악보다 많다. William A. Wulf (1972) 우리는 세세한 성능 효율에 대해서는 무시할 필요가 있다. 말하자면 97%가 이 경우에 해당한다. 섣부른 최적화는 만악의 근원이다. Donald E. Knuth (1974) 우리는 최적화에 대해서 다음 두가지 규칙을 따른다. 첫째. 하지 마라. 둘째. (전문가 한정) 아직은 하지 마라. 최적화되지 않은 상태로도 완벽하게 깔끔한 해결책을 찾는 것이 먼저다. M. A. Jackson (1975) 효율만 쫒다가 득보다 실이 큰 경우를 경계하라는 뜻\n최적화를 하기 전에 항상 아래 두가지를 검토\n최적화 이전에 먼저 좋은 코드를 작성하기 코드를 작성하는 데 있어서 성능을 염두에 두는 것은 물론 중요합니다. 하지만 많은 경우 대부분의 코드는 성능상 영향이 크지 않고 실제로 병목이 되는 부분은 극히 일부분입니다. 좋은 코드를 최적화하기는 쉽지만, 섣부르게 최적화된 코드를 좋은 코드로 만드는 건 어렵습니다. 빠른 코드보다는 좋은 코드를 짜는 데에 먼저 집중하고 최적화는 그 다음에 생각해야 합니다.\n정량적으로 성능을 측정하면서 병목을 파악하기 정량화된 지표를 통해 실제로 병목이 되는 부분을 파악해야 합니다. 지엽적인 부분을 일일히 개선하는 마이크로 최적화는 많은 경우 100ms 를 99ms로 줄이는 것에 그칩니다. 마이크로 최적화 보다는 거시적인 관점에서 중요한 병목을 찾고 이를 구조적으로 해결하는 것이 중요합니다. 그리고 실질적으로 얼마나 빨라졌는지 정량적인 성과로 나타낼 수 있어야 합니다.\n검토해야할 부분 # 위 개선을 통해 배치 수행시간이 너무 빨라졌다. MSA 구조에서는 애플리케이션과 직접적으로 연동되는 DB와 로드밸런서 뿐만 아니라, 많은 모듈 및 유관부서들이 유기적으로 연결되어있기 때문에 영향 범위를 면밀히 검토해야한다. 데이터 변경이 발생하면 변경 사항이 큐를 통해서 유관 부서에 전달된다. 확인 지표\n개발 환경에서 테스트 당시 애플리케이션이 실행되는 서버의 CPU 및 I/O 지표 개발 환경에서 테스트 당시 DB CPU, 쿼리 지연 시간 등 지표 예상 트래픽을 산출, 현재 운영 환경에서의 피크 트래픽과 비교하여 문제가 없을지 검토 변경 사항을 전달하는 큐에서 지연이 발생해도 문제가 없을지 검토 너무 빨라도 문제 # 빠르게 동작하기 때문에, 유관 부서 트래픽 또한 예상 이상으로 인입되어 DB CPU가 높아짐 해결방안 : 의도적으로 지연 시간 설정\n@Bean(STEP_NAME) @JobScope public Step liveShopCloseCreateStep() { return stepBuilderFactory.get(STEP_NAME) .\u0026lt;Long, Long\u0026gt;chunk(CHUNK_SIZE) .reader(shopCloseScheduleReader(null)) .writer(liveShopCloseWriter(null, null, null)) .transactionManager(storeTransactionManager) .listener(new AfterChunkSleepListener(200)) .build(); } @Slf4j public class AfterChunkSleepListener implements ChunkListener { private final long sleepMillis; public AfterChunkSleepListener(long sleepMillis) { this.sleepMillis = sleepMillis; } @Override public void afterChunk(ChunkContext context) { try { log.info(\u0026#34;Chunk 실행 후 sleep {} millis. 현재 read Count : {}\u0026#34;, sleepMillis, context.getStepContext().getStepExecution().getReadCount()); TimeUnit.MILLISECONDS.sleep(sleepMillis); } catch (InterruptedException e) { log.error(\u0026#34;Thread sleep interrupted.\u0026#34;, e); } } @Override public void afterChunkError(ChunkContext context) { // 사용안함. } @Override public void beforeChunk(ChunkContext context) { // 사용안함. } } 지연 시간을 설정해도 배치는 390분 -\u0026gt; 30분 소요되는 결과를 얻음 최적화 작업 # 리스크를 확인하고 과제에 대한 우선순위를 조정하기 문제 상황을 분석하고 병목을 확인하기 I/O의 경우 최대한 한번에 여러건을 읽고 쓰도록 하여 효율성 높이기 도메인 로직을 검토하여 개선할 수 있는 부분이 있는지 살피기 유의미한 최적화인가? 정량적인 지표로 다시 검토하기 빨라도 문제일 수 있으니 최적화에 의한 영향 범위를 검토하고 운영 환경에서도 문제가 없을지 확인하기 참고 # 위 배치의 chunk size : 100으로 설정 References _1) https://techblog.woowahan.com/13569/?ref=codenary _2) https://www.codenary.co.kr/search?keyword=Java "},{"id":40,"href":"/docs/r2dbc/005_r2dbc_Metadata_mapping/","title":"005 R2dbc Metadata Mapping","section":"R2dbc","content":" 05. Metadata mapping # Entity 클래스에 어노테이션을 추가 # @Id: primary key에 해당하는 필드에 적용 @Table: entity class에 적용. Table 이름을 변경 가능 @Transient: 기본적으로 모든 필드는 mapping 대상. @Transient가 붙은 필드는 mapping 에서 제외 @Column: entity의 property 필드에 적용. @Column이 붙은 필드에 대해서는 convention 기반 대신 Column에 주어진 name으로 적용 @Version: 낙관적 잠금 (Optimistic Lock)에 이용. entity가 update 될때마다 자동으로 update @PersistenceConstructor: 특정 constructor에 대해서 Object creation할 때 사용하게끔 지정. constructor의 argument 이름에 따라서 mapping Metadata mapping 예제 # @Id : id 필드 지정 @Column(\u0026ldquo;name\u0026rdquo;) : fullName 필드에 row의 name 필드와 mapping @Transient : score 필드를 mapping 대상에서 제외 @PersistenceCreator : id, fullName, age, gender를 인자로 받는 생성자 설정 @Version : version 필드 설정 Metadata mapping 실행 # update 수행 후, version 1 증가 update된 결과에서 score를 20으로 변경 데이터베이스에는 반영되지 않지만 변경된 score를 두번째 update된 결과에 포함 Metadata mapping 실패 # version을 강제로 1 증가시킨다. (마치, 다른 쓰레드가 증가시킨것처럼) OptimisticLockingFailureException 발생 어떻게 property mapping에서 MySQL 타입을 java 타입으로 바꿀 수 있나? # property mapping 타입 변환 # Row로부터 get을 통해서 특정 Java 클래스로 변환 MySqlRow # Row의 구현체인 MySqlRow는 Codecs를 포함 해당 codecs를 이용하여 column의 정보, 값을 전달하고 type을 갖는 객체를 반환 FieldValue: column의 실제 값에 해당하는 ByteBuf 혹은 List 포함 MySqlColumnDescriptor: MySqlType, column name, nullable, size 등의 column meta 정보 포함 MySQL DefaultCodecs # MySQL defaultCodecs에는 기본적으로 codec들을 포함 각각의 codec은 canDecode, decode를 구현 canDecode : columnMetadata를 기반으로 target(특정 java 타입)으로 변경 가능한지 여부 반환 decode : 주어진 column의 value를 특정 타입의 객체로 반환 Codec 예제 - IntegerCodec # canPrimitiveDecode 메소드에서 주어진 column이 numeric 타입인지 체크 아래의 MySQL 타입인 경우 true DECIMAL TINYINT, TINYINT_UNSIGNED SMALLINT, SMALLINT_UNSIGNED INT, INT_UNSIGNED FLOAT DOUBLE BIGINT, BIGINT_UNSIGNED MEDIUMINT, MEDIUMINT_UNSIGNED YEAR decodeInt에서 MySQL 타입에 따라서 int로 변환 MySQL DefaultCodecs 지원 # 기본적으로 26개의 Codec 지원 Byte, Short, Integer, Long, BigInteger BigDecimal, Float, Double Boolean, BitSet ZonedDatetTime, LocalDateTime, Instant, OffsetDateTime LocalDate LocalTime, Duration, OffsetTime Year String Enum Set Clob, Blob ByteBuffer, ByteArray References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":41,"href":"/docs/r2dbc/006_r2dbcEntityOperations/","title":"006 R2dbc Entity Operations","section":"R2dbc","content":" 06. R2dbcEntityOperations # 구조 # R2dbcEntityTemplate가 R2dbcEntityOperations를 상속한다. R2dbcEntityOperations가 FluentR2dbcOperations를 상속한다. FluentR2dbcOperations는 여러 Operations를 상속한다. ReactiveSelectOperation : select query와 관련된 메서드 제공 ReactiveInsertOperation : insert query와 관련된 메서드 제공 ReactiveUpdateOperation : update query와 관련된 메서드 제공 ReactiveDeleteOperation : delete query와 관련된 메서드 제공 ReactiveSelectOperation # ReactiveSelectOperation의 select부터 시작 TerminatingSelect의 count, exists, first, one, all 등으로 종료 구조 select -\u0026gt; from -\u0026gt; as -\u0026gt; matching -\u0026gt; 실행 select -\u0026gt; from -\u0026gt; matching -\u0026gt; 실행 select -\u0026gt; as -\u0026gt; matching -\u0026gt; 실행 select -\u0026gt; matching -\u0026gt; 실행 select -\u0026gt; -\u0026gt; 실행 ReactiveSelectOperation 사용 # from : query를 실행할 table 이름을 전달 as : Entity를 전부 mapping 하지 않고 특정 필드만 mapping 하고 싶은 경우 Entity의 일부 프로퍼티만 담고 있는 subclass(혹은 인터페이스)를 넘겨서 projection projection이 제공되지 않는다면 Entity에 모든 필드를 mapping matching : query의 where문에 해당 matching을 생략하면 table 전체에 대한 요청을 보내는 것과 동일 실행 : 마지막으로 count, exists, first, one, all 등의 연산을 선택 count: 조건에 맞는 row의 개수 반환 exists: 조건에 맞는 row 존재 여부 반환 first: 조건에 맞는 첫 번째 row 반환 one: 조건에 맞는 하나의 row 반환. 하나가 넘으면 exception all: 조건에 맞는 모든 row 반환 ReactiveSelectOperation 실행 # ConnectionFactory를 이용하여 R2dbcEntityTemplate을 생성 Query와 Criteria를 이용해서 query 생성 PersonNameOnly class를 이용해서 name만 projection ReactiveInsertOperation # ReactiveInsertOperation의 insert 부터 시작하여 TerminatingInsert의 using으로 종료 구조 insert -\u0026gt; into -\u0026gt; using insert -\u0026gt; using ReactiveInsertOperation 사용 # into : query를 실행할 table 이름을 전달 using : insert query에 이용할 entity를 전달 주어진 entity를 OutboundRow로 변환 변환된 OutboundRow로 쿼리 실행 ReactiveInsertOperation 실행 # into를 통해서 insert할 table 명시 entity를 생성하여 using에 전달 ReactiveUpdateOperation # ReactiveUpdateOperation의 update부터 시작하여 TerminatingUpdate의 apply로 종료 구조 update -\u0026gt; inTable -\u0026gt; matching -\u0026gt; apply update -\u0026gt; inTable -\u0026gt; apply update -\u0026gt; matching -\u0026gt; apply update -\u0026gt; apply ReactiveUpdateOperation 사용 # inTable : query를 실행할 table 이름을 전달 matching : query의 where문에 해당 Query를 전달하여 query의 where에 들어갈 내용을 설정 matching을 생략하면 table 전체에 대한 요청을 보내는 것과 동일 apply : update를 수행 Entity가 아닌 Update 객체 전달 Update는 내부에 SqlIdentifier를 Key로 변경하려는 값을 Value로 갖는 Map 포함 from과 update static method로 Update 객체 생성 결과로 영향을 받은 row의 숫자 반환 ReactiveUpdateOperation 실행 # inTable을 통해서 update할 table 명시 matching으로 update 영향을 받는 row 제한 update를 생성하여 apply에 전달 ReactiveDeleteOperation # ReactiveDeleteOperation의 delete 부터 시작하여, TerminatingDelete의 all로 종료 구조 delete -\u0026gt; from -\u0026gt; matching -\u0026gt; all delete -\u0026gt; from -\u0026gt; all delete -\u0026gt; matching -\u0026gt; all delete -\u0026gt; all ReactiveDeleteOperation 사용 # all : delete를 수행 결과로 영향을 받은 row의 숫자 반환 ReactiveDeleteOperation 실행 # from을 통해서 delete할 table 명시 maching으로 delete 영향을 받는 row 제한 all을 실행하여 결과 출력 R2dbcEntityOperations # FluentR2dbcOperations에서 제공하는 조합 방식 대신 다양한 쿼리를 수행하는 단축 메소드 제공 Query 객체를 인자로 받는 경우 Entity를 직접 인자로 받는 경우\ninsert, update의 경우 주어진 entity로 값을 추가하거나 변경 delete는 id를 추출하여 해당 id를 갖는 row를 제거 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":42,"href":"/docs/r2dbc/007_r2dbcRepository/","title":"007 R2dbc Repository","section":"R2dbc","content":" 07. R2dbcRepository # R2dbcRepository 구조 # ReactiveSortingRepository와 ReactiveQueryByExampleExecutor를 상속한 interface인 SimpleR2dbcRepository에서 구현 R2dbcRepository 등록 # R2dbcRepositoriesAutoConfiguration가 활성화되어 있다면 SpringBootApplication 기준으로 자동으로 scan 혹은 EnableR2dbcRepositories를 통해서 repository scan 만약 여러 r2dbcEntityTemplate이 존재하거나 여러 데이터베이스를 사용하는 경우, basePackages, entityOperationRef 등을 통해서 다른 경로, 다른 entityTemplate 설정 가능 Repository # Spring data에서는 Repository interface를 제공 데이터에 접근하는 계층을 추상화하고 CRUD 작업, Entity mapping, SQL 쿼리 생성 등을 자동으로 수행 ReactiveCrudRepository # Spring data reactive에서는 CrudRepository의 Reactive 버전인 ReactiveCrudRepository 지원 entity의 CRUD에 집중 모든 결과값 그리고 일부 인자들이 Publisher 지원 ReactiveCrudRepository - save # saveAll은 @Transactional을 사용해서 각각의 save를 하나의 tx로 묶고 concatMap을 통해서 save를 순차적으로 수행 ReactiveCrudRepository - find # id 기반으로 하나 혹은 여러 개의 항목을 탐색하거나 존재 여부를 확인 모든 항목을 탐색하거나 모든 항목의 개수를 확인 ReactiveCrudRepository - delete # id 기반으로 하나 혹은 여러 개의 항목을 제거하거나 하나 혹은 여러 개의 entity를 기반으로 id를 추출하여 제거하거나, 모두 제거 ReactiveSortingRepository # ReactiveCrudRepository를 상속 spring data의 Sort를 기반으로 여러 항목 탐색 Sort 객체는 여러 Order 객체를 포함 이를 기반으로 query에 sort 옵션을 제공 SimpleR2dbcRepository # R2dbcRepository를 구현 R2dbcEntityOperations를 기반으로 SQL 쿼리를 실행하고 결과를 Entity로 mapping 기본적으로 모든 메소드에 @Transactional(readOnly = true) 적용 SimpleR2dbcRepository - save # new entity 확인 전략 @Id에 해당하는 필드를 확인. 만약 @Id 필드가 null이거나 0이라면 새로운 entity로 간주 SimpleR2dbcRepository - find # findById, existsById, count 모두 R2dbcEntityOperations에서 제공하는 단축 메소드 (selectOne, exists, count) 사용 SimpleR2dbcRepository - delete # R2dbcEntityOperations에서 제공하는 단축 메소드 (delete) 사용 R2dbcRepository의 한계 # R2dbcRepository는 기본적으로 CRUD를 수행할 수 있는 메소드를 제공 모두 혹은 id 기반으로 CRUD를 제공 특정 필드로 탐색을 하거나 상위 n개만 조회 등의 기능은 제공되지 않는다 join이나 집계와 관련된 함수들은 제공되지 않는다. 한계 해결 : query method 사용\nReferences 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":43,"href":"/docs/r2dbc/008_r2dbc_query_method/","title":"008 R2dbc Query Method","section":"R2dbc","content":" 08. R2dbc Query Method # 쿼리 메소드 (Query method) # R2dbcRepository를 상속한 repository interface에 메소드를 추가 메소드의 이름을 기반으로 Query 생성 조회, 삭제 지원 @Query 어노테이션을 사용해서 복잡한 쿼리나 update 문도 실행 가능 쿼리 메소드 - find # id 뿐만 아니라 다른 필드를 이용해서 조회 가능 first 등의 키워드를 사용해서 query에 limit 제공 가능 기존의 Entity 뿐만 아니라 Projection을 사용하여 일부 필드만 조회 가능 findFirstByNameOrderByAgeDesc name이 “taewoo”인 row들을 찾고 age 내림차순으로 sort 하여 limit을 1로 모든 field를 조회하여 PersonEntity class로 mapping 쿼리 메소드 - delete # 다른 필드를 이용해서 삭제 가능 여러 반환 타입 지원 Integer: 영향을 받은 row 수 반환 Boolean: 삭제되었는지 여부 반환 Void: 반환값보다는 completion이 중요한 경우 deleteByAgeGreaterThan age가 100 초과인 row를 찾고 삭제한 후 영향을 받은 row가 있다면 true를, 없다면 false를 반환 쿼리 메서드 시작 키워드 # find, read, get, query, search, stream find 쿼리를 실행하고 결과를 Publisher으로 반환 exists find exists 쿼리를 실행하고 결과를 Publisher으로 반환 count find count 쿼리를 실행하고 결과를 Publisher으로 반환 delete, remove delete 쿼리를 실행하고 Publisher 혹은 publisher로 삭제된 개수 반환 쿼리 메서드 제한 키워드 # First, Top 쿼리의 limit을 N으로 설정. find와 By 사이 어디에든 등장 가능 Distinct distinct 기능을 제공. find와 By 사이 어디에든 등장 가능 쿼리 메소드 predicate 키워드 # And: AND Or: OR After, IsAfter: AFTER Before, IsBefore: BEFORE Containing, IsContaining, Contains: CONTAINING Between, IsBetween: BETWEEN EndingWith, IsEndingWith, EndsWith: ENDING_WITH Exists: EXISTS False, IsFalse: FALSE GreaterThan, IsGreaterThan: GREATER_THAN GreaterThanEqual, IsGreaterThanEqual: GREATER_THAN_EQUALS In, IsIn: IN Is, Equals: IS IsEmpty, Empty: IS_EMPTY IsNotEmpty, NotEmpty: IS_NOT_EMPTY NotNull, IsNotNull: IS_NOT_NULL Null, IsNull: IS_NULL LessThan, IsLessThan: LESS_THAN LessThanEqual, IsLessThanEqual: LESS_THAN_EQUAL Like, IsLike: LIKE Near, IsNear: NEAR Not, IsNot: NOT NotIn, IsNotIn: NOT_IN NotLike, IsNotLike: NOT_LIKE Regex, MatchesRegex, Matches: REGEX StartingWith, IsStartingWith, StartsWith: STARTING_WITH True, IsTrue: TRUE Within, IsWithin: WITHIN IgnoreCase, IgnoringCase: 특정 필드에 적용. 비교하려는 대상 모두 UPPER로 만들어서 비교 AllIgnoreCase, AllIgnoringCase OrderBy: 주어진 property path와 direction에 따라서 쿼리에 Sort 제공 쿼리 메소드 반환 타입 # Mono Reactor에서 제공 0개 혹은 하나의 값을 반환하는 Publisher 만약 결과가 2개 이상이라면 IncorrectResultSizeDataAccessException 발생 Flux Reactor에서 제공 0개 이상의 값을 반환하는 Publisher 끝이 없는 수의 결과를 반환 가능 Single RxJava에서 제공 무조건 1개의 값을 반환하는 Publisher 만약 결과가 2개 이상이라면 IncorrectResultSizeDataAccessException 발생 만약 결과가 0개라면 NoSuchElementException 발생 Maybe RxJava에서 제공 0개 혹은 하나의 값을 반환하는 Publisher 만약 결과가 2개 이상이라면 IncorrectResultSizeDataAccessException 발생 Flowable RxJava에서 제공 0개 이상의 값을 반환하는 Publisher 끝이 없는 수의 결과를 반환 가능 쿼리 메소드 - @Query # query가 메소드 이름으로 전부 표현이 되지 않는 경우 쿼리 메소드 예약어에서 지원되지 않는 문법을 사용하는 경우 복잡한 query문을 사용하는 경우 쿼리 메소드 - @Query # inner join을 이용하여 person_role과 join하여 role이 특정값인 경우에만 조회 결과를 PersonEntity 형태로 반환 @Transactional # @Transactional를 사용하여 여러 query를 묶어서 진행 새로운 Entity를 만들어서 save하고 update 한 후, findAll을 통해서 모든 row 반환 로그 TransactionalOperator # transactional 메소드를 통해서 주어진 Flux 혹은 Mono를 transaction 안에서 실행 TransactionalOperator 사용 # flux를 바로 반환하지 않고 transactionalOperator의 transactional로 wrapping 하여 전달 혹은 execute를 통해서 TransactionCallback 형태로 실행 로그 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":44,"href":"/docs/kotlin/005_Kotlin_extractList_Method/","title":"005 Kotlin Extract List Method","section":"Kotlin","content":" Kotlin에서 리스트 추출하기 : subList, slice, take, drop # 리스트의 부분 리스트 구하기 : subList(), slice(), take() # Kotlin에서는 리스트의 부분 리스트를 구하는 메서드로 여러 메서드를 제공한다. 부분 리스트를 추출하는 기능을 하는 메서드에 대해 알아보자. 원본 리스트를 변경하지 않고 추출한 새로운 리스트를 반환하는 특징이 있다. 이 메서드들은 immutable한 리스트와 mutable한 리스트 모두에서 사용할 수 있다.\nsubList() # 리스트의 인덱스를 기반으로 리스트의 일부분을 추출하여, 새로운 리스트를 생성한다. Java의 subList와 유사하게 시작 인덱스부터 끝 인덱스까지 요소를 추출한다. 시작 인덱스는 포함, 끝 인덱스는 포함X val list = listOf(1, 2, 3, 4, 5) val sub = list.subList(1, 4) // [2, 3, 4] slice() # 리스트의 특정 범위를 추출하여 새로운 리스트를 생성한다. subList()와 다르게 IntRange를 받는다. IntRange에 해당하는 범위의 리스트를 추출하여 새로운 리스트로 생성한다. -\u0026gt; (1..4) 시작 인덱스, 끝 인덱스 모두 포함 val list = listOf(1, 2, 3, 4, 5) val sliced = list.slice(1..4) // [2, 3, 4, 5] subList() vs slice() # subList() : 추출된 부분 리스트는 원본 리스트의 View에 해당한다. 따라서 원본 리스트의 변경의 영향을 받는다. slice() : 추출된 부분 리스트는 원본 리스트와 완전히 독립된 리스트다. 따라서 영향을 받지 않는다. val mutableList = mutableListOf(1, 2, 3, 4, 5) val sub = mutableList.subList(1, 4) // [2, 3, 4] val sliced = mutableList.slice(1..3) // [2, 3, 4] // 원본 리스트 변경 mutableList[2] = 7 // subList() : 원본 리스트 변경 적용 println(sub) // [2, 7, 4] // slice() : 원본 리스트 변경 적용 X println(sliced) // [2, 3, 4] subList(), slice() 의 동작 방식 # val mutableList = mutableListOf(1, 2, 3, 4, 5) val sub = mutableList.subList(1, 4) // [2, 3, 4] val sliced = mutableList.slice(1..3) // [2, 3, 4] // mutableList[2] = 7 println(sub) // [2, 7, 4] println(sliced) // [2, 3, 4] mutableList, sub, sliced 각각 다른 해시코드를 가지고 있어, 다른 객체임을 확인할 수 있다. mutableList와 sliced는 ArrayList 클래스 타입이고, sub는 ArrayList 클래스의 내부 클래스인 SubList 클래스 타입이다. 각각의 리스트를 구성하는 요소들의 해시코드는 동일하다. 내부적으로 모두 동일한 객체를 가리킨다.\nval mutableList = mutableListOf(1, 2, 3, 4, 5) val sub = mutableList.subList(1, 4) // [2, 3, 4] val sliced = mutableList.slice(1..3) // [2, 3, 4] mutableList[2] = 7 println(sub) // [2, 7, 4] println(sliced) // [2, 3, 4] mutableList[2] = 7 코드를 수행시켜보자. mutablieList, sub : 7을 가리키는 새로운 객체(Integer@831)로 대체된다. sliced : 기존의 객체(Integer@837)로 유지된다. subList로 추출한 리스트는 원본 리스트의 참조를 따라가고, slice로 추출한 리스트의 경우 기존 참조를 유지한다. take(), drop() # take() : 리스트의 앞부분부터 지정한 개수만큼의 요소를 추출하여 새로운 리스트를 생성한다. drop() : 리스트의 앞부분부터 지정한 개수만큼의 요소를 뺀 새로운 리스트를 생성한다. take(), drop() 둘다 원본 리스트와 독립적으로 생성되며, 원본 리스트가 변경되어도 영향을 받지않는다. val list = listOf(1, 2, 3, 4, 5) val taken = list.take(3) // [1, 2, 3] val dropped = list.drop(3) // [4, 5] subList(slice) vs. take(drop) # subList와 slice : 리스트의 범위를 넘어가는 인덱스를 인자로 받을 경우 IndexOutOfBoundsException을 발생 take와 drop : 리스트의 범위를 넘어가는 인덱스를 인자로 받더라도 별도의 Exception을 발생X 리스트의 범위를 넘어가는 인덱스를 인자로 받을 경우 take : 원본 리스트를 그대로 가져온다. drop : 리스트의 모든 요소를 제외하여 부분 리스트를 생성한다. val list = listOf(1, 2, 3) // 길이가 3이고, maxIndex가 2인 list val sub = list.subList(0, 4) // IndexOutOfBoundsException val sliced = list.slice(0..3) // IndexOutOfBoundsException val taken = list.take(4) // [1, 2, 3] val dropped = list.drop(4) // [] 정리 # subList 원본 리스트와 부분 리스트 간의 관계를 유지하고자 할 때 0번 인덱스부터 자르는 것이 아닌 중간부터 자를 때 (끝까지 자르는 것이 아닌 도중에 자를 때) ex: subList(1, 4) slice 원본 리스트와 관계없는 독립적인 리스트를 생성해야 할 때 0번 인덱스부터 자르는 것이 아닌 중간부터 자를 때 (끝까지 자르는 것이 아닌 도중에 자를 때) ex: slice(1..4) take, drop slice를 대체할 수 있으면 사용하는 것이 좋음 slice(0, 3) 대신 take(3) 사용 → IndexOutOfBoundsException으로부터 안전 subList(0, 4) 대신 take(3)을 사용할 경우, 원본 리스트 간의 동기화 문제가 발생할 수 있으므로 이 점 참고하여 사용 IndexOutOfBoundsException을 발생시켜야 하는 상황에서는 다른 메서드 사용 References _1) https://medium.com/@limgyumin/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%9D%98-apply-with-let-also-run-%EC%9D%80-%EC%96%B8%EC%A0%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94%EA%B0%80-4a517292df29 "},{"id":45,"href":"/docs/r2dbc/003_r2dbcEntityTemplate/","title":"003 R2dbc Entity Template","section":"R2dbc","content":" 03. R2dbcEntityTemplate # Entity # 데이터베이스에서 하나의 Row와 매칭되는 클래스 R2dbcEntityTemplate, R2dbcRepository 등은 데이터베이스에 요청을 보내고 그 결과를 Entity 형태로 반환 Table, Row, Column에 필요한 데이터베이스 metadat를 어노테이션으로 제공 R2dbcEntityTemplate # Spring data r2dbc의 추상화 클래스 메서드 체이닝을 통해서 쿼리를 수행하고 결과를 entity 객체로 받을 수 있다. R2dbcEntityOperations를 구현 public class R2dbcEntityTemplate implements R2dbcEntityOperations, BeanFactoryAware, ApplicationContextAware { private final DatabaseClient databaseClient; ... } R2dbcEntityTemplate 생성 # ConnectionFactory를 제공하거나 R2dbcDialect, R2dbcConverter를 제공하여 constructor로 생성 가능 R2dbcDialect : R2dbc 버전의 Dialect 확장 R2dbcEntityTemplate 빈 등록 # R2dbcDataAutoConfiguration 위 클래스를 통해서 DatabaseClient, R2dbcDialect, MappingR2dbcConverter를 주입 @AutoConfiguration(after = R2dbcAutoConfiguration.class) @ConditionalOnClass({ DatabaseClient.class, R2dbcEntityTemplate.class }) @ConditionalOnSingleCandidate(DatabaseClient.class) public class R2dbcDataAutoConfiguration { private final DatabaseClient databaseClient; private final R2dbcDialect dialect; public R2dbcDataAutoConfiguration(DatabaseClient databaseClient) { this.databaseClient = databaseClient; this.dialect = DialectResolver.getDialect(this.databaseClient.getConnectionFactory()); } @Bean @ConditionalOnMissingBean public R2dbcEntityTemplate r2dbcEntityTemplate(R2dbcConverter r2dbcConverter) { return new R2dbcEntityTemplate(this.databaseClient, this.dialect, r2dbcConverter); } @Bean @ConditionalOnMissingBean public R2dbcMappingContext r2dbcMappingContext(ObjectProvider\u0026lt;NamingStrategy\u0026gt; namingStrategy, R2dbcCustomConversions r2dbcCustomConversions) { R2dbcMappingContext relationalMappingContext = new R2dbcMappingContext( namingStrategy.getIfAvailable(() -\u0026gt; NamingStrategy.INSTANCE)); relationalMappingContext.setSimpleTypeHolder(r2dbcCustomConversions.getSimpleTypeHolder()); return relationalMappingContext; } @Bean @ConditionalOnMissingBean public MappingR2dbcConverter r2dbcConverter(R2dbcMappingContext mappingContext, R2dbcCustomConversions r2dbcCustomConversions) { return new MappingR2dbcConverter(mappingContext, r2dbcCustomConversions); } ... } R2dbcEntityOperations # DatabaseClient와 R2dbcConverter를 제공 DatabaseClient ConnectionFactory를 wrapping하여 결과를 Map이나 Integer로 반환 R2dbcConverter 주어진 Row를 Entity로 만드는 converter R2dbcEntityTemplate에서는 이 DatabaseClient, R2dbcConverter로 쿼리를 실행하고 결과를 entity로 반환한다. public interface R2dbcEntityOperations extends FluentR2dbcOperations { DatabaseClient getDatabaseClient(); ... R2dbcConverter getConverter(); ... } DatabaseClient # 내부에 포함된 ConnectionFactory에 접근 가능 sql 메서드를 통해서 GenericExecuteSpec을 반환한다. bind를 통해서 parameter를 sql에 추가 fetch를 통해서 FetchSpec을 반환 public interface DatabaseClient extends ConnectionAccessor { ConnectionFactory getConnectionFactory(); GenericExecuteSpec sql(String sql); ... interface GenericExecuteSpec { GenericExecuteSpec bind(int index, Object value); GenericExecuteSpec bindNull(int index, Class\u0026lt;?\u0026gt; type); GenericExecuteSpec bind(String name, Object value); GenericExecuteSpec bindNull(String name, Class\u0026lt;?\u0026gt; type); default GenericExecuteSpec filter(Function\u0026lt;? super Statement, ? extends Statement\u0026gt; filterFunction) { Assert.notNull(filterFunction, \u0026#34;Filter function must not be null\u0026#34;); } GenericExecuteSpec filter(StatementFilterFunction filter); default \u0026lt;R\u0026gt; RowsFetchSpec\u0026lt;R\u0026gt; map(Function\u0026lt;Row, R\u0026gt; mappingFunction) { Assert.notNull(mappingFunction, \u0026#34;Mapping function must not be null\u0026#34;); return map((row, rowMetadata) -\u0026gt; mappingFunction.apply(row)); } \u0026lt;R\u0026gt; RowsFetchSpec\u0026lt;R\u0026gt; map(BiFunction\u0026lt;Row, RowMetadata, R\u0026gt; mappingFunction); FetchSpec\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; fetch(); Mono\u0026lt;Void\u0026gt; then(); } } FetchSpec # RowsFetchSpec, UpdatedRowFetchSpec을 상속 RowsFetchSpec : one, first, all 메서드 제공 one : 없거나 혹은 하나의 결과를 Mono로 제공 (그 이상일 경우 에러 반환) first : 첫번째 결과를 Mono로 제공 all : 모든 결과를 Flux로 제공 UpdatedRowFetchSpec : 쿼리의 영향을 받은 row 수를 Mono로 제공 DatabaseClient 실행 # sql을 실행하여 GenericExecuteSpec을 반환 fetch() : FetchSpec 반환 예제코드를 보니, 여전히 직접 mapping 을 해줘야한다는 단점이 존재한다. R2dbcConverter # EntityReader, EntityWriter를 상속 구현체로 MappingR2dbcConverter가 존재 public interface R2dbcConverter extends EntityReader\u0026lt;Object, Row\u0026gt;, EntityWriter\u0026lt;Object, OutboundRow\u0026gt;, RelationalConverter { ... } public class MappingR2dbcConverter extends BasicRelationalConverter implements R2dbcConverter { /** * Creates a new {@link MappingR2dbcConverter} given {@link MappingContext}. * * @param context must not be {@literal null}. */ public MappingR2dbcConverter( MappingContext\u0026lt;? extends RelationalPersistentEntity\u0026lt;?\u0026gt;, ? extends RelationalPersistentProperty\u0026gt; context) { super(context, new R2dbcCustomConversions(R2dbcCustomConversions.STORE_CONVERSIONS, Collections.emptyList())); } ... } 다양한 전략을 통해서 Object를 데이터베이스의 row로, 데이터베이스의 row를 Object로 변환 custom converter로 mapping Spring data의 object로 mapping convention 기반의 mapping metadata 기반의 mapping Custom Converter Mapping # Configuration을 통해서 converter들을 등록 read, write 각각의 Converter이 필요 (2개) ReadConverter # Row를 source로 Entity를 target으로 하는 converter WriteConverter # Entity를 source로 Row를 target으로 하는 converter key : column 이름 value : parameter.from을 이용해서 entity의 속성 전달 OutboudRow에 값을 추가하고, DefaultDatabaseClient에서 이를 이용해서 SQL 생성 CustomConverter 등록 # AbstractR2dbcConfiguration를 상속하는 Configuration 생성 AbstractR2dbcConfiguration의 getCustomCOnverters에 custom converter들을 List 형태로 제공 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":46,"href":"/docs/r2dbc/004_r2dbc_object_mapping/","title":"004 R2dbc Object Mapping","section":"R2dbc","content":" 04. Object mapping # Spring data의 object mapping # 만약 지원하는 converter이 없다면 MappingR2dbcConverter는 다음 과정을 거쳐서 Row를 Entity로 변환한다. Object cretion : Row의 column들로 Object 생성 Property population : direct set, setter, with..메서드 등을 이용해서 Row의 Column을 Objec에 주입 Object creation # Object creation 테스트 # R2dbcEntityTemplate의 select 호출시, R2dbcConverter를 사용하기 때문에 이를 이용해서 selet에 class를 넘기는 방식으로 테스트 PersistenceCreator constructor # @PersistenceCreator 을 갖는 constructor가 존재한다면 해당 constructor를 사용 여러개가 존재한다면 가장 마지막 @PersistenceCreator가 붙은 constructor를 사용 NoArgsConstructor, AllArgsConstructor 전부 패스 NoArgs constructor # @PersistenceCreator 을 갖는 constructor가 없는 경우 No-args constructor가 존재한다면 해당 constructor를 사용 다른 constructor 전부 패스 하나의 constructor # 오직 하나의 constructor이 존재한다면 해당 constructor 사용 2개 이상의 constructor가 있다면? # @PersistenceCreator를 갖는 constructor도 없고, No-args constructor도 없다면, Exception 발생 생성자에 전체 필드가 없었어도, 결과를 보면 필드에 값이 들어가있었다. -\u0026gt; Property popultaion 동작\nProperty population # r2dbc에서는 property가 mutable할때만 property population 적용 id, name 필드를 채움 property 순회하여 mutable한 경우에만 reflection을 사용해서 값 주입 (남은 필드들도 값이 생김) Object mapping 최적화 # 객체를 가능한한 Immutable하게 모든 property를 인자로 갖는 All-args 제공 property polulation이 발생하지 않게되어 성능 향상 코드 중복 방지를 위해 lombok 사용 Naming strategy # 별도의 @Table, @Column 어노테이션이 없다면, naming strategy에 맞춰서 클래스명, 변수명을 변경해서 table과 column에 mapping NamingStrategy interface를 구현하여 bean으로 등록하면 일괄 변경가능 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":47,"href":"/docs/r2dbc/002_r2dbc_mysql/","title":"002 R2dbc Mysql","section":"R2dbc","content":" 02. R2dbc MySQL # R2dbc MysqlConnection # Connection을 구현한 MysqlConnection ConnectionMetadata를 구현한 MysqlConnectionMetadata Statement를 구현한 MysqlStatement MysqlConnectionFactory # Mono 형태로 포함 MysqlConnectionConfiguration을 인자로 받아서 MysqlConnectionFactory를 생성 MysqlConnectionFactory로 MysqlConnection 생성 MysqlConnection으로 MysqlStatement를 생성 MysqlConnection으로 transaction을 start, rollback, commit MysqlConnectionConfiguration # MYSQL 연결의 설정을 포함하는 객체 Builder 패턴 host, port, database, username 등 기본 설정 제공 serverZoneId 설정 MysqlConnection 생성 # Sql 준비 # Sql 실행 # ConnectionFactory의 create()를 통해서 connection 접근 connection의 createStatement를 통해서 sql 준비 result의 map으로 row에 접근하고 Person으로 변환 thenMany() chaining : 순차적으로 실행 selectPeople 결과를 아래로 전달 result의 map으로 row에 접근하고 Person으로 변환 MysqlConnection의 한계 # SQL 쿼리를 명시적으로 전달 반환된 결과를 수동으로 파싱 별도의 mapper를 만들어야하고 확장성이 떨어짐 Transaction 실행 # connection의 beginTransaction과 commitTransaction으로 transaction 시작과 commit 수행 롤백 수행 : conn.rollbackTransaction() References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":48,"href":"/docs/kotlin/004_Kotlin_Scoping_Functions/","title":"004 Kotlin Scoping Functions","section":"Kotlin","content":" Kotlin Scoping Functions apply vs. with, let, also, and run # apply, with, let, also, run # Kotlin의 Receiver # 객체 외부의 람다 코드 블록을 마치 해당 객체 내부에서 사용하는 것 처럼 작성할 수 있게 해주는 장치\nblock : T.() -\u0026gt; R 위 람다 블록은 객체 T를 receiver로 이용하여 객체 R을 반환한다.\nreceiver : 객체 T receiver를 사용하는 람다 : lambda with receiver block : (T) -\u0026gt; R 위의 경우 객체 T를 리시버가 아니라 람다 파라미터로 받는다.\n범위 지정 함수란? # 수신객체 수신객체 지정 람다 (lambda with receiver) 람다 식 내에서 수신 객체의 멤버에 직접 접근할 수 있게 하는 기능 with # inline fun \u0026lt;T, R\u0026gt; with(receiver: T, block: T.() -\u0026gt; R): R { return receiver.block() } 수신객체 : receiver T 수신 객체 지정 람다 : block Before\nclass Person { var name: String? = null var age: Int? = null } val person: Person = getPerson() print(person.name) print(person.age) After\nval person: Person = getPerson() with(person) { print(name) print(age) } also # inline fun \u0026lt;T\u0026gt; T.also(block: (T) -\u0026gt; Unit): T { block(this) return this } T 의 확장함수로 수신 객체가 암시적으로 제공 수신 객체 지정 람다 : 매개변수 T 로 코드 블록 내에 명시적으로 전달 Before\nclass Person { var name: String? = null var age: Int? = null } val person: Person = getPerson() print(person.name) print(person.age) After\nval person: Person = getPerson().also { print(it.name) print(it.age) } with, also, apply, let, run 차이점 # 호출시에 수신 객체가 매개 변수로 명시적으로 전달되거나 수신 객체의 확장 함수로 암시적 수신 객체 로 전달 수신 객체 지정 람다 에 전달되는 수신 객체가 명시적 매개 변수 로 전달 되거나 수신 객체의 확장 함수로 암시적 수신 객체로 코드 블록 내부로 전달 범위 지정 함수의 결과로 수신 객체를 그대로 반환하거나 수신 객체 지정 람다 의 실행 결과를 반환 inline fun \u0026lt;T, R\u0026gt; with(receiver: T, block: T.() -\u0026gt; R): R { return receiver.block() } inline fun \u0026lt;T\u0026gt; T.also(block: (T) -\u0026gt; Unit): T { block(this) return this } inline fun \u0026lt;T\u0026gt; T.apply(block: T.() -\u0026gt; Unit): T { block() return this } inline fun \u0026lt;T, R\u0026gt; T.let(block: (T) -\u0026gt; R): R { return block(this) } inline fun \u0026lt;T, R\u0026gt; T.run(block: T.() -\u0026gt; R): R { return block() } apply 사용 규칙 # 수신 객체 람다 내부에서 수신 객체의 함수를 사용하지 않고 수신 객체 자신을 다시 반환 하려는 경우 Before\nval clark = Person() clark.name = \u0026#34;Clark\u0026#34; clark.age = 18 After\nval peter = Person().apply { // apply 의 블록 에서는 오직 프로퍼티 만 사용합니다! name = \u0026#34;Peter\u0026#34; age = 18 } also 사용 규칙 # 수신 객체 람다가 전달된 수신 객체를 전혀 사용 하지 않거나 수신 객체의 속성을 변경하지 않고 사용하는 경우 수신 객체를 반환 하므로 블록 함수가 다른 값을 반환 해야하는 경우 사용 불가능 inline fun \u0026lt;T\u0026gt; T.also(block: (T) -\u0026gt; Unit): T { block(this) return this } Before\nclass Book(val author: Person) { init { requireNotNull(author.age) print(author.name) } } After\nclass Book(author: Person) { val author = author.also { requireNotNull(it.age) print(it.name) } } apply 와 also : 리시버와 파라미터의 차이 # public inline fun \u0026lt;T\u0026gt; T.also(block: (T) -\u0026gt; Unit): T { block(this) return this } public inline fun \u0026lt;T\u0026gt; T.apply(block: T.() -\u0026gt; Unit): T { block() return this } also : 객체를 람다 파라미터로 받는다. apply : 객체를 리시버로 받는다. class person { var name = \u0026#34;kotlin\u0026#34; private val id = \u0026#34;1541\u0026#34; } person.also { println(\u0026#34;my name is ${it.name}\u0026#34;) } person.apply { println(\u0026#34;my name is $name\u0026#34;) } also : it을 사용한다. apply : this를 사용한다. it vs this # 내가 작성하고자 하는 코드의 의미(semantics) 에 따라 also를 쓸지 apply를 쓸지 결정하는 것이다.\nit also는 객체를 람다 아규먼트로 받기 때문에 객체에 접근할 때 it(혹은 내가 정의한 다른 이름)을 사용 이는 코드가 객체 외부에서 해당 객체에 접근한다는 인상을 강하게 준다. 객체를 외부에서 접근하는 느낌을 주기 때문에 해당 객체와 더불어(혹은 이용해서) 어떠한 행위를 수행하고자 할 때 쓰인다. person.also { println(\u0026#34;my name is ${it.steven}\u0026#34;) } this apply 는 객체를 람다 리시버로 받기 때문에 객체에 접근할 때 this(혹은 생략)을 사용 코드가 해당 객체의 외부가 아니라 객체 내부에 있는듯한 인상을 준다. apply코드 블록이 객체 내부에 있는 듯한 느낌을 주기 때문에 주로 객체를 초기화 하는 코드 혹은 객체의 상태를 변경하는 코드에 많이 사용된다. person.apply { name = \u0026#34;steven\u0026#34; age = 21 } let 사용 규칙 # 지정된 값이 null 이 아닌 경우에 코드를 실행해야 하는 경우 Nullable 객체를 다른 Nullable 객체로 변환하는 경우 단일 지역 변수의 범위를 제한 하는 경우 inline fun \u0026lt;T, R\u0026gt; T.let(block: (T) -\u0026gt; R): R { return block(this) } Before\nval person: Person? = getPromotablePerson() if (person != null) { promote(person) } val driver: Person? = getDriver() val driversLicence: Licence? = if (driver == null) null else licenceService.getDriversLicence(it) val person: Person = getPerson() val personDao: PersonDao = getPersonDao() personDao.insert(person) After\ngetNullablePerson()?.let { // null 이 아닐때만 실행됩니다. promote(it) } val driversLicence: Licence? = getNullablePerson()?.let { // nullable personal객체를 nullable driversLicence 객체로 변경합니다. licenceService.getDriversLicence(it) } val person: Person = getPerson() getPersonDao().let { dao -\u0026gt; // 변수 dao 의 범위는 이 블록 안 으로 제한 됩니다. dao.insert(person) } with 사용 규칙 # Non-nullable (Null 이 될수 없는) 수신 객체 이고 결과가 필요하지 않은 경우에만 with 를 사용 inline fun \u0026lt;T, R\u0026gt; with(receiver: T, block: T.() -\u0026gt; R): R { return receiver.block() } Before\nval person: Person = getPerson() print(person.name) print(person.age) After\nval person: Person = getPerson() with(person) { print(name) print(age) } run 사용 규칙 # 어떤 값을 계산할 필요가 있거나 여러개의 지역 변수의 범위를 제한하려면 run 을 사용 매개 변수로 전달된 명시적 수신객체 를 암시적 수신 객체로 변환 할때 run ()을 사용 inline fun \u0026lt;T, R\u0026gt; T.run(block: T.() -\u0026gt; R): R { return block() } Before\nval person: Person = getPerson() val personDao: PersonDao = getPersonDao() val inserted: Boolean = personDao.insert(person) fun printAge(person: Person) = { print(person.age) } After\nval inserted: Boolean = run { // person 과 personDao 의 범위를 제한 합니다. val person: Person = getPerson() val personDao: PersonDao = getPersonDao() // 수행 결과를 반환 합니다. personDao.insert(person) } fun printAge(person: Person) = person.run { // person 을 수신객체로 변환하여 age 값을 사용합니다. print(age) } 여러 범위 지정 함수 결합 # 하나의 코드 블록 내에서 여러 범위 지정 함수를 중첩하지 않는 것이 좋다. 수신객체 지정 람다 에 수신 객체가 암시적으로 전달되는 apply, run, with 는 중첩하지 말라. 이 함수들은 수신 객체를 this 또는 생략하여 사용하며, 수신객체의 이름을 다르게 지정할수 없기 때문에 중첩될 경우 혼동 하기 쉽다. also 와 let 을 중첩 해야만 할때는 암시적 수신 객체 를 가르키는 매개 변수 인 it 을 사용하지 말고, 명시적인 이름을 제공해서 코드상의 이름이 혼동되지 않도록 하자.\nprivate fun insert(user: User) = SqlBuilder().apply { append(\u0026#34;INSERT INTO user (email, name, age) VALUES \u0026#34;) append(\u0026#34;(?\u0026#34;, user.email) append(\u0026#34;,?\u0026#34;, user.name) append(\u0026#34;,?)\u0026#34;, user.age) }.also { print(\u0026#34;Executing SQL update: $it.\u0026#34;) }.run { jdbc.update(this) \u0026gt; 0 } References _1) https://medium.com/@limgyumin/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%9D%98-apply-with-let-also-run-%EC%9D%80-%EC%96%B8%EC%A0%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94%EA%B0%80-4a517292df29\n_2) https://jaeyeong951.medium.com/kotlin-lambda-with-receiver-5c2cccd8265a "},{"id":49,"href":"/docs/r2dbc/001_r2dbc_intro/","title":"001 R2dbc Intro","section":"R2dbc","content":" R2dbc 소개 # 왜 JDBC, JPA는 non-blocking을 지원할 수 없을까? # JDBC : 동기 blocking I/O 기반으로 설계 Socket에 대한 연결과 쿼리 실행 모두 동기 blocking으로 동작 JPA 또한 JDBC 기반 -\u0026gt; 비동기 non-blocking 지원 불가 그래서 결국, 비동기 non-blocing 기반의 API, 드라이버를 새로 만든다. R2dbc # Reactive Relational Database Connectivity 비동기 non-blocking 관계형 데이터베이스 드라이버 Reactive streams 스펙을 제공하며 Project reactor 기반으로 구현 R2dbc 지원 데이터베이스 # 공식지원 r2dbc-h2 r2dbc-mssql r2dbc-pool : Reactor pool로 커넥션 풀 제공 벤더 지원 oracle-r2dbc r2dbc-mariadb r2dbc-postgresql 커뮤니티 지원 r2dbc-mysql mirromutth 에서 2020년 5월부터 업데이트 X asyncer-io에서 RELEASE 지원 R2dbc MySQL 구조 # r2dbc-spi와 Reactor Netty 기반 Reactor Netty를 이용하여 r2dbc-spi 스펙을 구현 Reactor Netty client로 성능과 확장성 모두 제공 r2dbc-spi 스펙을 구현하여 여러 데이터베이스 시스템과 호환 R2dbc SPI # r2dbc Service Provider Interface SPI에서 제공하는 인터페이스를 구현해야한다. db connection 스펙, Exception 등의 스펙, Result, Row 등 result 스펙, Statement(요청) 스펙 R2dbc SPI Connection # 데이터베이스에 대한 연결을 가리킨다.\nClosable을 구현하여 close 메서드로 connection을 닫을 수 있다.\nConnectionMetadata를 제공\ndatabase의 version과 productName을 제공 createStatement를 통해서 sql을 넘기고 Statement를 생성한다. transaction 관련된 기능을 제공\ntransaction을 시작\nTransactionDefinition로 고립 수준, 읽기 전용 여부, 이름, lockWaitTime 등을 설정 transaction savepoint를 생성\ntransaction 중간에 savepoint를 만들고 rollback 가능 transaction을 commit하거나 rollback R2dbc SPI ConnectionFactory # connection을 생성하는 factory ConnectionFactoryMetadat를 통해서 ConnectionFactory의 정보를 제공 ConnectionFactoryMetadata는 name을 제공 R2dbc SPI Statement # Statement는 Connection으로부터 createStatement을 통해서 생성 bind : sql에 parameter를 bind add : 이전까지 진행한 binding을 저장하고 새로운 binding을 생성 execute : 생성된 binding 수만큼 쿼리를 실행하고 publisher로 반환 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지 "},{"id":50,"href":"/docs/kotlin/003_Kotlin_basic/","title":"003 Kotlin Basic","section":"Kotlin","content":" 코틀린 문법 한번에 정리하기 # 주석 정리 Variable # // top-level var x = 5 fun main() { x+= 1 println(x) val a : Int = 1 val b = 1 val c : Int c = 3 val d : Int d = 123 //val(value) : 불변(Immutable) //var(variable) : 가변(Mutable) var e : String = \u0026#34;Hello\u0026#34; e = \u0026#34;World\u0026#34; var f = 123 // f = \u0026#34;hi\u0026#34; // 컴파일 오류 타입은 변경이 불가 } Function # // 기본적인 함수 선언 스타일 fun sum(a: Int, b: Int) : Int { return a + b } // 표현식 스타일 fun sum2(a: Int, b: Int) : Int = a + b // 표현식 \u0026amp; 반환타입 생략 fun sum3(a: Int, b: Int) = a + b // 몸통이 있는 함수는 반환 타입을 제거하면 컴파일 오류 fun sum4(a: Int, b: Int) : Int { return a + b } // 반환타입이 없는 함수는 Unit을 반환한다 fun printSum(a: Int, b: Int) : Unit { println(\u0026#34;$a + $b = ${a + b}\u0026#34;) } // 디폴트 파라미터 fun greeting(message: String = \u0026#34;안녕하세요!!\u0026#34;) { println(message) } // //fun main( ) { // greeting() // greeting(\u0026#34;HI!!!\u0026#34;) //} fun log(level: String = \u0026#34;INFO\u0026#34;, message: String) { println(\u0026#34;[$level]$message\u0026#34;) } fun main( ) { log(message = \u0026#34;인포 로그\u0026#34;) log(level = \u0026#34;DEBUG\u0026#34;, \u0026#34;디버그 로그\u0026#34;) log(\u0026#34;WARN\u0026#34;, \u0026#34;워닝 로그\u0026#34;) log(level = \u0026#34;ERROR\u0026#34;, message = \u0026#34;에러 로그\u0026#34;) } For # fun main() { // 범위 연산자 .. 를 사용해 for loop 돌리기 for (i in 0..3) { println(i) } // until 을 사용해 반복한다 // 뒤에 온 숫자는 포함하지 않는다 for (i in 0 until 3) { println(i) } // step 에 들어온 값 만큼 증가시킨다 for ( i in 0..6 step 2) { println(i) } // downTo를 사용해 반복하면서 값을 감소시킨다 for (i in 3 downTo 1) { println(i) } // 전달받은 배열을 반복 val numbers = arrayOf(1,2,3) for (i in numbers) { println(i) } } If # fun main() { //if..else 사용 val job = \u0026#34;Software Developer\u0026#34; if (job == \u0026#34;Software Developer\u0026#34;) { println(\u0026#34;개발자\u0026#34;) } else { println(\u0026#34;개발자아님\u0026#34;) } //코틀린의 if...else는 표현식이다 val age : Int = 10 val str = if (age \u0026gt; 10) { \u0026#34;성인\u0026#34; } else { \u0026#34;아이\u0026#34; } //코틀린은 삼항 연산자가 없다. if..else가 표현식이므로 불필요하다 val a = 1 val b = 2 val c = if (b \u0026gt; a) b else a } When # fun main() { // 자바 코드를 코틀린의 when식으로 변환한 코드 val day = 2 val result = when (day) { 1 -\u0026gt; \u0026#34;월요일\u0026#34; 2 -\u0026gt; \u0026#34;화요일\u0026#34; 3 -\u0026gt; \u0026#34;수요일\u0026#34; 4 -\u0026gt; \u0026#34;목요일\u0026#34; else -\u0026gt; \u0026#34;기타\u0026#34; } println(result) // else를 생략할 수 있다 when(getColor()) { Color.RED -\u0026gt; print(\u0026#34;red\u0026#34;) Color.GREEN -\u0026gt; println(\u0026#34;green\u0026#34;) else -\u0026gt; println(\u0026#34;blue\u0026#34;) } // 여러개의 조건을 콤마로 구분해 한줄에서 정의할 수 있다 when (getNumber()) { 0, 1 -\u0026gt; print(\u0026#34;0 또는 1\u0026#34;) else -\u0026gt; print(\u0026#34;0 또는 1이 아님\u0026#34;) } } enum class Color { RED, GREEN, BLUE } fun getColor() = Color.RED fun getNumber() = 2 while # fun main() { // 자바의 while문과 동일 // 조건을 확인하고 참이면 코드 블록을 실행한 후 다시 조건을 확인 var x = 5 while (x \u0026gt; 0) { println(x) x-- } } Exception # fun main() { try { throw Exception() } catch (e: Exception) { println(\u0026#34;에러 발생!\u0026#34;) } finally { println(\u0026#34;finally 실행!\u0026#34;) } val a = try { \u0026#34;1234\u0026#34;.toInt() } catch (e: Exception) { println(\u0026#34;예외 발생 !\u0026#34;) } println(a) //throw Exception(\u0026#34;예외 발생!\u0026#34;) val b: String? = null val c: String = b ?: failFast(\u0026#34;a is null\u0026#34;) println(c.length) } fun failFast(message: String): Nothing { throw IllegalArgumentException(message) } Null Safety # fun getNullStr(): String? = null fun getLengthIfNotNull(str: String?) = str?.length ?: 0 fun main() { val nullableStr = getNullStr() val nullableStrLength = nullableStr?.length ?: \u0026#34;null인 경우 반환\u0026#34;.length println(nullableStrLength) val length = getLengthIfNotNull(null) println(length) //throw NullPointerException() // val c: String? = null // val d = c!!.length // println(Java_NullSafety.getNullStr()?.length ?: 0) } Class Property # class Coffee( var name: String = \u0026#34;\u0026#34;, var price: Int = 0, var iced: Boolean = false, ) { val brand: String get() { return \u0026#34;스타벅스\u0026#34; } var quantity : Int = 0 set(value) { if (value \u0026gt; 0) { // 수량이 0 이상인 경우에만 할당 field = value } } } class EmptyClass fun main() { val coffee = Coffee() coffee.name = \u0026#34;아이스 아메리카노\u0026#34; coffee.price = 2000 coffee.quantity = 1 coffee.iced = true if (coffee.iced) { println(\u0026#34;아이스 커피\u0026#34;) } println(\u0026#34;${coffee.brand} ${coffee.name} 가격은 ${coffee.price} 수량은 ${coffee.quantity}\u0026#34;) } Inheritance # open class Dog { open var age: Int = 0 open fun bark() { // 반드시 오버라이드해야하는건 아니다. open fun일 경우 반드시 body를 구현해야한다. println(\u0026#34;멍멍\u0026#34;) } } open class Bulldog(final override var age: Int = 0) : Dog() { final override fun bark() { super.bark() } } abstract class Developer { abstract var age: Int abstract fun code(language: String) } class BackendDeveloper(override var age : Int) : Developer() { override fun code(language: String) { println(\u0026#34;I code with $language\u0026#34;) } } fun main() { val backendDeveloper = BackendDeveloper(age = 20) println(backendDeveloper.age) backendDeveloper.code(\u0026#34;Kotlin\u0026#34;) val dog = Bulldog(age = 2) println(dog.age) dog.bark() } Interface # class Product(val name: String, val price: Int) interface Wheel { fun roll() } interface Cart : Wheel { var coin: Int val weight: String get() = \u0026#34;20KG\u0026#34; fun add(product: Product) fun rent() { if (coin \u0026gt; 0) { println(\u0026#34;카트를 대여합니다\u0026#34;) } } override fun roll() { println(\u0026#34;카트가 굴러갑니다\u0026#34;) } fun printId() = println(\u0026#34;1234\u0026#34;) } interface Order { fun add(product: Product) { println(\u0026#34;${product.name} 주문이 완료되었습니다\u0026#34;) } fun printId() = println(\u0026#34;5678\u0026#34;) } class MyCart(override var coin: Int) : Cart, Order { override fun add(product: Product) { if (coin \u0026lt;= 0) println(\u0026#34;코인을 넣어주세요\u0026#34;) else println(\u0026#34;${product.name}이(가) 카트에 추가됐습니다\u0026#34;) // 주문하기 super\u0026lt;Order\u0026gt;.add(product) } override fun printId() { super\u0026lt;Cart\u0026gt;.printId() super\u0026lt;Order\u0026gt;.printId() } } fun main() { val cart = MyCart(coin = 100) cart.rent() cart.roll() cart.add(Product(name = \u0026#34;장난감\u0026#34;, price = 1000)) cart.printId() } Collection # import java.util.* import java.util.stream.Collectors import kotlin.collections.ArrayList fun main() { // immutable val currencyList = listOf(\u0026#34;달러\u0026#34;, \u0026#34;유로\u0026#34;, \u0026#34;원\u0026#34;) // mutable val mutableCurrencyList: MutableList\u0026lt;String\u0026gt; = mutableListOf\u0026lt;String\u0026gt;().apply { add(\u0026#34;달러\u0026#34;) add(\u0026#34;유로\u0026#34;) add(\u0026#34;원\u0026#34;) } mutableCurrencyList.add(\u0026#34;파운드\u0026#34;) // immutable set val numberSet = setOf(1, 2, 3, 4) // mutable set val mutableSet = mutableSetOf\u0026lt;Int\u0026gt;().apply { add(1) add(2) add(3) add(4) } // immutable map val numberMap = mapOf(\u0026#34;one\u0026#34; to 1, \u0026#34;two\u0026#34; to 2) // mutable map val mutableNumberMap = mutableMapOf\u0026lt;String, Int\u0026gt;() mutableNumberMap[\u0026#34;one\u0026#34;] = 1 mutableNumberMap[\u0026#34;two\u0026#34;] = 2 mutableNumberMap[\u0026#34;three\u0026#34;] = 3 // 컬렉션 빌더는 내부에선 mutable 반환은 immutable val numberList: List\u0026lt;Int\u0026gt; = buildList{ add(1) add(2) add(3) add(4) } // linkedList val linkedList = LinkedList\u0026lt;Int\u0026gt;().apply { addFirst(3) add(2) addLast(1) } // arrayList val arrayList = ArrayList\u0026lt;Int\u0026gt;().apply { add(1) add(2) add(3) } // val iterator = currencyList.iterator() // while (iterator.hasNext()) { // println(iterator.next()) // } // // println(\u0026#34;===============\u0026#34;) // // for (currency in currencyList) { // println(currency) // } // // println(\u0026#34;===============\u0026#34;) // // currencyList.forEach { // println(it) // } // for loop -\u0026gt; map val lowerList = listOf(\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;) //val upperList = mutableListOf\u0026lt;String\u0026gt;() // for (lowerCase in lowerList) { // upperList.add(lowerCase.uppercase()) // } val upperList = lowerList.map { it.uppercase() } //val filteredList = mutableListOf\u0026lt;String\u0026gt;() // for (upperCase in upperList) { // if (upperCase == \u0026#34;A\u0026#34; || upperCase == \u0026#34;C\u0026#34; ) { // filteredList.add(upperCase) // } // } val filteredList = upperList .asSequence() // 대량데이터의 경우 이걸 사용하는게 좋다. .filter { it == \u0026#34;A\u0026#34; || it == \u0026#34;C\u0026#34; } .toList() println(filteredList) } Data Calss # data class Person(val name: String, val age: Int) { } fun main() { val person1 = Person(name = \u0026#34;tony\u0026#34;, age = 12) val (name, age) = person1 println(\u0026#34;이름=${name}, 나이=${age}\u0026#34;) // val set = hashSetOf(person1) // println(set.contains(person1)) } Singleton # import java.time.LocalDateTime //object Singleton { // // val a = 1234 // // fun printA() = println(a) //} // //fun main() { // println(Singleton.a) // Singleton.printA() //} //object DatetimeUtils { // // val now : LocalDateTime // get() = LocalDateTime.now() // // const val DEFAULT_FORMAT = \u0026#34;YYYY-MM-DD\u0026#34; // // fun same(a: LocalDateTime, b: LocalDateTime) : Boolean { // return a == b // } // //} // //fun main() { // println(DatetimeUtils.now) // println(DatetimeUtils.now) // println(DatetimeUtils.now) // // println(DatetimeUtils.DEFAULT_FORMAT) // // val now = LocalDateTime.now() // println(DatetimeUtils.same(now, now)) //} class MyClass { private constructor() companion object MyCompanion { val a = 1234 fun newInstance() = MyClass() } } fun main() { println(MyClass.a) println(MyClass.newInstance()) println(MyClass.a) println(MyClass.newInstance()) } Sealed Class # sealed class Developer { abstract val name: String abstract fun code(language: String) } data class BackendDeveloper(override val name: String) : Developer() { override fun code(language: String) { println(\u0026#34;저는 백엔드 개발자입니다 ${language}를 사용합니다\u0026#34;) } } data class FrontendDeveloper(override val name: String) : Developer() { override fun code(language: String) { println(\u0026#34;저는 프론트엔드 개발자입니다 ${language}를 사용합니다\u0026#34;) } } object OtherDeveloper : Developer() { override val name: String = \u0026#34;익명\u0026#34; override fun code(language: String) { TODO(\u0026#34;Not yet implemented\u0026#34;) } } data class AndroidDeveloper(override val name: String) : Developer() { override fun code(language: String) { println(\u0026#34;저는 안드로이드 개발자입니다 ${language}를 사용합니다\u0026#34;) } } data class IosDeveloper(override val name: String) : Developer() { override fun code(language: String) { println(\u0026#34;저는 Ios 개발자입니다 ${language}를 사용합니다\u0026#34;) } } object DeveloperPool { val pool = mutableMapOf\u0026lt;String, Developer\u0026gt;() // 컴파일러는 Developer 구현 클래스가 무엇인지를 모름 // else가 없으면 when절에 컴파일 오류남 // Developer 를 sealed Class로 정의하면 else문 생략가능 // 같은 패키지/하위 모듈에 있는 경우에만 sealed class의 하위클래스가 될 수 있다 // 컴파일러가 Developer 의 자식클래스를 알고있끼 때문이다. fun add(developer: Developer) = when(developer) { is BackendDeveloper -\u0026gt; pool[developer.name] = developer is FrontendDeveloper -\u0026gt; pool[developer.name] = developer is AndroidDeveloper -\u0026gt; pool[developer.name] = developer is IosDeveloper -\u0026gt; pool[developer.name] = developer is OtherDeveloper -\u0026gt; println(\u0026#34;지원하지않는 개발자종류입니다\u0026#34;) } fun get(name: String) = pool[name] } fun main() { val backendDeveloper = BackendDeveloper(name=\u0026#34;토니\u0026#34;) DeveloperPool.add(backendDeveloper) val frontendDeveloper = FrontendDeveloper(name=\u0026#34;카즈야\u0026#34;) DeveloperPool.add(frontendDeveloper) val androidDeveloper = AndroidDeveloper(name=\u0026#34;안드로\u0026#34;) DeveloperPool.add(androidDeveloper) println(DeveloperPool.get(\u0026#34;토니\u0026#34;)) println(DeveloperPool.get(\u0026#34;카즈야\u0026#34;)) println(DeveloperPool.get(\u0026#34;안드로\u0026#34;)) } Extension # /** * 문자열 첫번째 원소 리턴 */ fun String.first() : Char { return this[0] } fun String.addFirst(char: Char) : String { // this : 수신자 객체 return char + this.substring(0) } class MyExample { fun printMessage() = println(\u0026#34;클래스 출력\u0026#34;) } // MyExample의 확장함수 생성 // printMessage 멤버함수와 이름을 동일하게 했을때 멤버함수가 우선적으로 수행된다. // 확장함수의 멤버함수와 동일한 시그니처는 멤버함수가 실행됨 fun MyExample.printMessage() = println(\u0026#34;확장 출력\u0026#34;) // 시그니처가 다르면 확장함수 실행이 잘 됨 fun MyExample.printMessage(message:String) = println(message) // MyExample 이 null일 가능성이 존재 // null인 경우와 아닌 경우 분기처리 fun MyExample?.printNullOrNotNull() { if (this == null) println(\u0026#34;널인 경우에만 출력\u0026#34;) else println(\u0026#34;널이 아닌 경우에만 출력\u0026#34;) } fun main() { var myExample: MyExample? = null // 함수에서 null 체크를 하고있다는걸 컴파일러가 알고있어서 오류가 안난다. myExample.printNullOrNotNull() myExample = MyExample() myExample.printNullOrNotNull() //MyExample().printMessage(\u0026#34;확장 출력\u0026#34;) // println(\u0026#34;ABCD\u0026#34;.first()) // // println(\u0026#34;ABCD\u0026#34;.addFirst(\u0026#39;Z\u0026#39;)) } Generics # class MyGenerics\u0026lt;out T\u0026gt;(val t: T) { // 공변성은 자바 제네릭의 extends 코틀린에선 out } class Bag\u0026lt;T\u0026gt; { fun saveAll( to: MutableList\u0026lt;in T\u0026gt;, // 반공변성은 자바 제네릭의 super 코틀린에선 in from: MutableList\u0026lt;T\u0026gt;, ) { to.addAll(from) } } fun main() { val bag = Bag\u0026lt;String\u0026gt;() // String이 CharSequence의 하위타입인데, // 반공변성에서는 mutableListOf\u0026lt;CharSequence\u0026gt;가 mutableListOf\u0026lt;String\u0026gt;의 하위타입이 된다. bag.saveAll(mutableListOf\u0026lt;CharSequence\u0026gt;(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;), mutableListOf\u0026lt;String\u0026gt;(\u0026#34;3\u0026#34;, \u0026#34;4\u0026#34;)) // MyGenerics\u0026lt;CharSequence\u0026gt; 가 MyGenerics\u0026lt;String\u0026gt; 보다 상위타입 val generics = MyGenerics\u0026lt;String\u0026gt;(\u0026#34;테스트\u0026#34;) val charGenerics : MyGenerics\u0026lt;CharSequence\u0026gt; = generics // 제네릭을 사용한 클래스의 인스턴스를 만드려면 타입아규먼트를 제공 (컴파일러 타입 추론 가능) val generics2 = MyGenerics\u0026lt;String\u0026gt;(\u0026#34;테스트\u0026#34;) // 생략가능 val generics3 = MyGenerics(\u0026#34;테스트\u0026#34;) // 변수의 타입에 제네릭을 사용한 경우 val list1: MutableList\u0026lt;String\u0026gt; = mutableListOf() // 타입아규먼트를 생성자에서 추가 val list2 = mutableListOf\u0026lt;String\u0026gt;() val list3 : List\u0026lt;*\u0026gt; = listOf\u0026lt;String\u0026gt;(\u0026#34;테스트\u0026#34;) val list4: List\u0026lt;*\u0026gt; = listOf\u0026lt;Int\u0026gt;(1, 2, 3, 4) // PECS는 Producer-Extends, Consumer-Super // 공변성은 자바 제네릭의 extends 코틀린에선 out // -\u0026gt; 공변성 : T’가 T의 서브타입이면, C\u0026lt;T’\u0026gt;는 C\u0026lt;out T\u0026gt;의 서브타입이다. // 반공변성은 자바 제네릭의 super 코틀린에선 in // -\u0026gt; 반공변성 : T’가 T의 서브타입이면, C\u0026lt;T\u0026gt;는 C\u0026lt;in T’\u0026gt;의 서브타입이다. } Late init # class `7_LateInit` { // 가변 프로퍼티에 대한 지연 초기화 // nullable이 아님에도 초기호 안했어도 컴파일 오류가 발생하지 않는다. lateinit var text: String // var : 가변 val textInitialized: Boolean // isInitialized 는 클래스 내부에서만 사용 가능하다. (Main 등에서 사용 불가능) get() = this::text.isInitialized // 초기화 여부 fun printText() { println(text) } } fun a (str:String, block: (String) -\u0026gt; Unit) { block(str) } fun main() { \u0026#34;\u0026#34;.let { } a(\u0026#34;\u0026#34;) { it.length } val test = `7_LateInit`() if (!test.textInitialized) { test.text = \u0026#34;하이요\u0026#34; } test.printText() // 초기화 전에 출력 요청하면 오류 발생 } Lazy init # class HelloBot { // val 불변 // by lazy 사용 (멀티쓰레드 안전) // 기본 : LazyThreadSafetyMode.SYNCHRONIZED // LazyThreadSafetyMode.NONE 등 상태값을 설정하여 쓰레드 안전성 무시 가능 // 불변을 유지하면서 변수에 대한 초기화를 뒤로 미룰수 있다. // 변수가 처음으로 사용될 때까지 해당 변수의 초기화를 늦춘다. // -\u0026gt; 즉, 변수에 처음으로 접근하는 시점에서 초기화 코드가 실행 val greeting: String by lazy(LazyThreadSafetyMode.PUBLICATION) { // 멀티쓰레드 환경에서도 동기화가 필요하지 않을때 : LazyThreadSafetyMode.PUBLICATION // 한 번 초기화된 이후에는 모든 스레드가 같은 값을 공유 // 따라서 여러 스레드에서 동시에 초기화를 시도하더라도 최초 한 번만 초기화가 이루어지고 나면 이후에는 초기화 코드가 다시 실행되지않음 getHello() } fun sayHello() = println(greeting) } fun getHello() = \u0026#34;안녕하세요\u0026#34; fun main() { val helloBot = HelloBot() // 초기화 이후에는 더이상 by lazy {}을 수행하지 않음 // ... // ... for (i in 1..5) { Thread { // 쓰레드 생성하여 병렬로 수행해보자 helloBot.sayHello() // 변수 초기화 첫 실행 }.start() } } Pair Destructuring # // f((1, 3)) = 1 + 3 = 4 // f(1, 3) = 1 + 3 = 4 //data class Tuple(val a : Int, val b: Int) fun plus(pair: Pair\u0026lt;Int, Int\u0026gt;) = pair.first + pair.second fun main() { //println(plus(1,3)) val plus = plus(Pair(1, 3)) println(plus) val pair = Pair(\u0026#34;A\u0026#34;, 1) // 불변 val newPair = pair.copy(first = \u0026#34;B\u0026#34;) // 새로운 Pair을 생성 println(newPair) val second = newPair.component2() // second 값 가져오기 println(second) val list = newPair.toList() println(list) /* 3개 요소 (4개 이상부터는 지원하지 않음, Collection 사용하면 됨) */ val triple = Triple(\u0026#34;A\u0026#34;,\u0026#34;B\u0026#34;,\u0026#34;C\u0026#34;) println(triple) // 출력 triple.first triple.second val newTriple = triple.copy(third = \u0026#34;D\u0026#34;) // third 값 변경한 새로운 Triple 생성 println(newTriple) println(newTriple.component3()) /* 구조분해 할당 */ val (a: String, b: String, c: String) = newTriple println(\u0026#34;$a, $b, $c\u0026#34;) val list3: List\u0026lt;String\u0026gt; = newTriple.toList() val (a1, a2, a3) = list3 println(\u0026#34;$a1, $a2, $a3\u0026#34;) list3.component1() list3.component2() list3.component3() // list3.component4() // list3.component5() val map = mutableMapOf(Pair(\u0026#34;이상훈\u0026#34;, \u0026#34;개발자\u0026#34;)) for ( (key, value) in map ) { println(\u0026#34;${key}의 직업은 $value\u0026#34;) } } 범위 지정 함수 # (이미지 출처 : https://medium.com/@limgyumin/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%9D%98-apply-with-let-also-run-%EC%9D%80-%EC%96%B8%EC%A0%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94%EA%B0%80-4a517292df29)\nRun # run 정의 inline fun \u0026lt;T, R\u0026gt; T.run(block: T.() -\u0026gt; R): R { return block() } 예제코드 class DatabaseClient { var url: String? = null var username: String? = null var password: String? = null // DB에 접속하고 Boolean 결과를 반환 fun connect(): Boolean { println(\u0026#34;DB 접속 중 ...\u0026#34;) Thread.sleep(1000) println(\u0026#34;DB 접속 완료\u0026#34;) return true } } fun main() { // val config = DatabaseClient() // config.url = \u0026#34;localhost:3306\u0026#34; // config.username = \u0026#34;mysql\u0026#34; // config.password = \u0026#34;1234\u0026#34; // val connected = config.connect() // run 안에서 수신자 객체 참조는 this로 함 (생략도 가능) // 변수 중복 참조를 생략할 수 있다는 장점 (위에서 config.xx가 반복됨) val connected: Boolean = DatabaseClient().run { url = \u0026#34;localhost:3306\u0026#34; username = \u0026#34;mysql\u0026#34; this.password = \u0026#34;1234\u0026#34; connect() // 자동 return } println(connected) val result: Boolean = with(DatabaseClient()) { url = \u0026#34;localhost:3306\u0026#34; username = \u0026#34;mysql\u0026#34; password = \u0026#34;1234\u0026#34; connect() } println(result) } Also # also 정의 inline fun \u0026lt;T\u0026gt; T.also(block: (T) -\u0026gt; Unit): T { block(this) return this } 예제 class User(val name: String, val password: String) { fun validate() { if (name.isNotEmpty() \u0026amp;\u0026amp; password.isNotEmpty()) { println(\u0026#34;검증 성공!\u0026#34;) } else { println(\u0026#34;검증 실패!\u0026#34;) } } fun printName() = println(name) } fun main() { User(name = \u0026#34;tony\u0026#34;, password = \u0026#34;1234\u0026#34;).also { // it을 사용해서 간결하게 사용 가능 it.validate() it.printName() } } Apply # apply 정의 inline fun \u0026lt;T\u0026gt; T.apply(block: T.() -\u0026gt; Unit): T { block() return this } 예제코드 fun main() { // return 타입이 Context 객체에 대한 타입 그대로 (DatabaseClient) DatabaseClient().apply { url = \u0026#34;localhost:3306\u0026#34; username = \u0026#34;mysql\u0026#34; this.password = \u0026#34;1234\u0026#34; }.connect() .run { println(this) } // this : connect() 함수의 반환결과 } Let # let 정의 inline fun \u0026lt;T, R\u0026gt; T.let(block: (T) -\u0026gt; R): R { return block(this) } 예제코드 fun main() { val str: String? = \u0026#34;안녕\u0026#34; // str 이 null이 아닌 경우에 동작한다. val result: Int? = str?.let { println(it) // it = str val abc: String? = \u0026#34;abc\u0026#34; val def: String? = \u0026#34;def\u0026#34; if (!abc.isNullOrEmpty() \u0026amp;\u0026amp; !def.isNullOrEmpty()) { println(\u0026#34;abcdef가 null 아님\u0026#34;) } // return 키워드 없이도 return 값으로 셋팅된다. 1234 } println(result) // val this: String? = null // val it : String? = null val hello = \u0026#34;hello\u0026#34; val hi = \u0026#34;hi\u0026#34; hello.let { a : String -\u0026gt; //println(a.length) hi.let{ b -\u0026gt; println(a.length) println(b.length) } } } With # with 정의 inline fun \u0026lt;T, R\u0026gt; with(receiver: T, block: T.() -\u0026gt; R): R { return receiver.block() } 예제 fun main() { val str = \u0026#34;안녕하세요\u0026#34; // val length: Int = with(str) { length // return 생략 가능 } println(length) } "},{"id":51,"href":"/docs/reactive-streams/002_impl1_reactor/","title":"002 Impl1 Reactor","section":"Reactive Streams","content":" Reactive Streams 구현 라이브러리 (1) Reactor # Project reactor # Pivotal 사에서 개발 Spring reactor에서 사용 Mono와 Flux publisher 제공 Project reactor - Flux # 0..n개의 item을 전달 에러가 발생하면 error signal 전달하고 종료 모든 item을 전달했다면 complete signal 전달 하고 종료 backPressure 지원 Flux 예제 # SimpleSubscriber\nFluxIterable publisher Subscription : StrictSubscriber @Slf4j @RequiredArgsConstructor public class p181_SimpleSubscriber\u0026lt;T\u0026gt; implements Subscriber\u0026lt;T\u0026gt; { private final Integer count; /** * 지속적으로 요청을 하는게 아니라, 딱 한번 N개의 요청을 받고 그 이후로 값을 계속 받음 * @param s the {@link Subscription} that allows requesting data via {@link Subscription#request(long)} */ @Override public void onSubscribe(Subscription s) { log.info(\u0026#34;subscribe\u0026#34;); s.request(count); // count만큼 request log.info(\u0026#34;request: {}\u0026#34;, count); } @SneakyThrows @Override public void onNext(T t) { log.info(\u0026#34;item: {}\u0026#34;, t); Thread.sleep(100); } @Override public void onError(Throwable t) { log.error(\u0026#34;error: {}\u0026#34;, t.getMessage()); } @Override public void onComplete() { log.info(\u0026#34;complete\u0026#34;); } } FluxSimpleExample\n@Slf4j public class p181_FluxSimpleExample { @SneakyThrows public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); // main 쓰레드에서 수행 getItems() // 고정된 개수를 subscribe .subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); Thread.sleep(1000); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.fromIterable(List.of(1, 2, 3, 4, 5)); } } 실행결과\n13:18:58.672 [main] INFO com.example06.reactor.p181_FluxSimpleExample - start main 13:18:58.733 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 13:18:58.736 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 13:18:58.736 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 13:18:58.737 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 1 13:18:58.904 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 2 13:18:59.049 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 3 13:18:59.233 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 4 13:18:59.399 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 5 13:18:59.578 [main] INFO com.example06.reactor.p181_SimpleSubscriber - complete 13:18:59.578 [main] INFO com.example06.reactor.p181_FluxSimpleExample - end main Flux - subscribeOn 예제 # FluxSimpleSubscribeOnExample\n@Slf4j public class p182_FluxSimpleSubscribeOnExample { @SneakyThrows public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems() .map(i -\u0026gt; { log.info(\u0026#34;map {}\u0026#34;, i); return i; }) // main 쓰레드가 아닌 다른 쓰레드에서 수행 .subscribeOn(Schedulers.single()) .subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); // 바로 호출 Thread.sleep(1000); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.fromIterable(List.of(1, 2, 3, 4, 5)); } } 실행결과\nsingle-1 쓰레드에서 수행 13:22:13.042 [main] INFO com.example06.reactor.p182_FluxSimpleSubscribeOnExample - start main 13:22:13.094 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 13:22:13.120 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 13:22:13.120 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 13:22:13.122 [main] INFO com.example06.reactor.p182_FluxSimpleSubscribeOnExample - end main 13:22:13.124 [single-1] INFO com.example06.reactor.p182_FluxSimpleSubscribeOnExample - map 1 13:22:13.124 [single-1] INFO com.example06.reactor.p181_SimpleSubscriber - item: 1 13:22:13.264 [single-1] INFO com.example06.reactor.p182_FluxSimpleSubscribeOnExample - map 2 13:22:13.264 [single-1] INFO com.example06.reactor.p181_SimpleSubscriber - item: 2 13:22:13.440 [single-1] INFO com.example06.reactor.p182_FluxSimpleSubscribeOnExample - map 3 13:22:13.441 [single-1] INFO com.example06.reactor.p181_SimpleSubscriber - item: 3 13:22:13.613 [single-1] INFO com.example06.reactor.p182_FluxSimpleSubscribeOnExample - map 4 13:22:13.614 [single-1] INFO com.example06.reactor.p181_SimpleSubscriber - item: 4 13:22:13.789 [single-1] INFO com.example06.reactor.p182_FluxSimpleSubscribeOnExample - map 5 13:22:13.789 [single-1] INFO com.example06.reactor.p181_SimpleSubscriber - item: 5 13:22:13.969 [single-1] INFO com.example06.reactor.p181_SimpleSubscriber - complete Flux - subscribe # FluxNoSubscribeExample\nsubscribe하지 않으면, 아무 일도 일어나지 않는다. @Slf4j public class p183_FluxNoSubscribeExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems(); // subscribe 하지않으면 아무일도 일어나지 않는다. log.info(\u0026#34;end main\u0026#34;); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.create(fluxSink -\u0026gt; { log.info(\u0026#34;start getItems\u0026#34;); for (int i = 0; i \u0026lt; 5; i++) { fluxSink.next(i); } fluxSink.complete(); log.info(\u0026#34;end getItems\u0026#34;); }); } } Flux - backPressure # 1번째 예제 @Slf4j public class p184_FluxSimpleRequestThreeExample { public static void main(String[] args) { // 3개 요청 (1, 2, 3 이후 종료) , 추가적인 요청 없음 getItems().subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(3)); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.fromIterable(List.of(1, 2, 3, 4, 5)); } } SimpleSubscriber\n@Slf4j @RequiredArgsConstructor public class p181_SimpleSubscriber\u0026lt;T\u0026gt; implements Subscriber\u0026lt;T\u0026gt; { private final Integer count; /** * 지속적으로 요청을 하는게 아니라, 딱 한번 N개의 요청을 받고 그 이후로 값을 계속 받음 * @param s the {@link Subscription} that allows requesting data via {@link Subscription#request(long)} */ @Override public void onSubscribe(Subscription s) { log.info(\u0026#34;subscribe\u0026#34;); s.request(count); // count만큼 request log.info(\u0026#34;request: {}\u0026#34;, count); } ... } 실행결과\n09:24:32.953 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:24:32.957 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:24:32.957 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 3 09:24:32.958 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 1 09:24:33.091 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 2 09:24:33.232 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 3 2번째 예제 @Slf4j public class p185_FluxContinuousRequestSubscriberExample { public static void main(String[] args) { getItems().subscribe(new p185_ContinuousRequestSubscriber\u0026lt;\u0026gt;()); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.fromIterable(List.of(1, 2, 3, 4, 5)); } } ContinuousRequestSubscriber\n@Slf4j public class p185_ContinuousRequestSubscriber\u0026lt;T\u0026gt; implements Subscriber\u0026lt;T\u0026gt; { private final Integer count = 1; private Subscription subscription; @Override public void onSubscribe(Subscription s) { this.subscription = s; log.info(\u0026#34;subscribe\u0026#34;); s.request(count); // 개수만큼 요청 log.info(\u0026#34;request: {}\u0026#34;, count); } @SneakyThrows @Override public void onNext(T t) { log.info(\u0026#34;item: {}\u0026#34;, t); Thread.sleep(1000); // 1개를 또 호출 subscription.request(1); log.info(\u0026#34;request: {}\u0026#34;, count); } @Override public void onError(Throwable t) { log.error(\u0026#34;error: {}\u0026#34;, t.getMessage()); } @Override public void onComplete() { log.info(\u0026#34;complete\u0026#34;); } } 아래 로직으로 계속 반복 수행한다. // 1개를 또 호출 subscription.request(1); 실행결과\n09:33:34.419 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:33:34.424 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - subscribe 09:33:34.424 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:33:34.425 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 1 09:33:35.445 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:33:35.445 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 2 09:33:36.518 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:33:36.518 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 3 09:33:37.589 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:33:37.589 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 4 09:33:38.655 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:33:38.655 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 5 09:33:39.718 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:33:39.727 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - complete Flux - error # @Slf4j public class p186_FluxErrorExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems().subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.create(fluxSink -\u0026gt; { fluxSink.next(0); fluxSink.next(1); var error = new RuntimeException(\u0026#34;error in flux\u0026#34;); fluxSink.error(error); // 에러 전달 }); } } 실행결과\n09:36:46.692 [main] INFO com.example06.reactor.p186_FluxErrorExample - start main 09:36:46.756 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:36:46.762 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:36:46.762 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 09:36:46.764 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 0 09:36:46.885 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 1 09:36:47.028 [main] ERROR com.example06.reactor.p181_SimpleSubscriber - error: error in flux 09:36:47.028 [main] INFO com.example06.reactor.p186_FluxErrorExample - end main Flux - complete # @Slf4j public class p187_FluxCompleteExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems().subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.create(fluxSink -\u0026gt; { fluxSink.complete(); // complete 전달 }); } } 실행결과\n09:37:31.038 [main] INFO com.example06.reactor.p187_FluxCompleteExample - start main 09:37:31.100 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:37:31.106 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:37:31.106 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 09:37:31.109 [main] INFO com.example06.reactor.p181_SimpleSubscriber - complete 09:37:31.109 [main] INFO com.example06.reactor.p187_FluxCompleteExample - end main Project reactor - Mono # 0..1개의 item을 전달 에러가 발생하면 error signal 전달하고 종료 모든 item을 전달했다면 complete signal 전달 하고 종료 Mono 예제 # 1개의 item만 전달하기 때문에 next 하나만 실행하면 complete가 보장 혹은 전달하지 않고 complete를 하면 값이 없다는 것을 의미 - 하나의 값이 있거나 없다 @Slf4j public class p190_MonoSimpleExample { @SneakyThrows public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems() .subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); Thread.sleep(1000); } private static Mono\u0026lt;Integer\u0026gt; getItems() { return Mono.create(monoSink -\u0026gt; { monoSink.success(1); }); } } 실행결과\n09:39:02.445 [main] INFO com.example06.reactor.p190_MonoSimpleExample - start main 09:39:02.481 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:39:02.484 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:39:02.484 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 09:39:02.484 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 1 09:39:02.658 [main] INFO com.example06.reactor.p181_SimpleSubscriber - complete 09:39:02.658 [main] INFO com.example06.reactor.p190_MonoSimpleExample - end main Mono와 Flux # Mono : Optional\n없거나 혹은 하나의 값 Mono로 특정 사건이 완료되는 시점을 가리킬 수도 있다 Flux: List\n무한하거나 유한한 여러 개의 값 Flux를 Mono로 변환 # Mono.from으로 Flux를 Mono로 변환 첫 번째 값만 전달 @Slf4j public class p192_FluxToMonoExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); // 1,2,3,4,5 중 첫번째값 1이 onNext로 전달되고 complete // 뒤에 있는 값들은 모두 무시 Mono.from(getItems()) .subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.fromIterable(List.of(1, 2, 3, 4, 5)); } } 실행결과\n09:40:37.275 [main] INFO com.example06.reactor.p192_FluxToMonoExample - start main 09:40:37.340 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:40:37.363 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:40:37.363 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 09:40:37.365 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 1 09:40:37.473 [main] INFO com.example06.reactor.p181_SimpleSubscriber - complete 09:40:37.473 [main] INFO com.example06.reactor.p192_FluxToMonoExample - end main Flux를 Mono로 변환 (Mono\u0026lt;List\u0026gt;) # @Slf4j public class p193_FluxToListMonoExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems() // collect 하고 complete 이벤트 발생 시점에 모은 값들을 모두 전달 // 1, 2, 3, 4, 5를 내부 배열에 저장하고, 가지고있던 값들을 모두 onNext() 한다. // 하나로 합쳐져서 Mono로 한번 요청됨 ([1,2,3,4,5]) .collectList() .subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); } private static Flux\u0026lt;Integer\u0026gt; getItems() { return Flux.fromIterable(List.of(1, 2, 3, 4, 5)); } } 실행결과\n09:41:24.680 [main] INFO com.example06.reactor.p193_FluxToListMonoExample - start main 09:41:24.743 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:41:24.766 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:41:24.766 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 09:41:24.767 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: [1, 2, 3, 4, 5] 09:41:24.940 [main] INFO com.example06.reactor.p181_SimpleSubscriber - complete 09:41:24.940 [main] INFO com.example06.reactor.p193_FluxToListMonoExample - end main Mono를 Flux로 변환 # flux() Mono를 next 한 번 호출하고 onComplete를 호출하는 Flux로 변환 @Slf4j public class p194_MonoToFluxExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); // flux() - Mono를 next 한번 호출하고 onComplete를 호출하는 Flux로 변환 // [1,2,3,4,5] getItems().flux() .subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); } private static Mono\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; getItems() { return Mono.just(List.of(1, 2, 3, 4, 5)); } } 실행결과\n09:42:16.606 [main] INFO com.example06.reactor.p194_MonoToFluxExample - start main 09:42:16.650 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:42:16.694 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:42:16.695 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 09:42:16.695 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: [1, 2, 3, 4, 5] 09:42:16.802 [main] INFO com.example06.reactor.p181_SimpleSubscriber - complete 09:42:16.802 [main] INFO com.example06.reactor.p194_MonoToFluxExample - end main Mono를 Flux로 변환 (Mono\u0026lt;List\u0026gt; -\u0026gt; Flux) # @Slf4j public class p195_ListMonoToFluxExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems() // Mono의 결과를 Flux 형태로 바꾸고, flux를 받아서 처리 // 1, 2, 3, 4, 5 하나씩 처리 .flatMapMany(value -\u0026gt; Flux.fromIterable(value)) .subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); } private static Mono\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; getItems() { return Mono.just(List.of(1, 2, 3, 4, 5)); } } 실행결과\n09:43:07.895 [main] INFO com.example06.reactor.p195_ListMonoToFluxExample - start main 09:43:07.931 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework 09:43:07.972 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:43:07.972 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 09:43:07.972 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 1 09:43:08.082 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 2 09:43:08.239 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 3 09:43:08.414 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 4 09:43:08.588 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 5 09:43:08.724 [main] INFO com.example06.reactor.p181_SimpleSubscriber - complete 09:43:08.724 [main] INFO com.example06.reactor.p195_ListMonoToFluxExample - end main References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지\n2) github 예제코드 : https://github.com/seohaebada/webflux "},{"id":52,"href":"/docs/reactive-streams/003_impl2_rxjava/","title":"003 Impl2 Rxjava","section":"Reactive Streams","content":" Reactive Streams 구현 라이브러리 (2) RxJava # RxJava # Netflix 사에서 개발 닷넷 프레임워크를 지원하는 Reactive Extensions를 포팅 Flowable, Observable, Single, Maybe, Completable, publisher 제공 RxJava - Flowable # 0..n개의 item을 전달 에러가 발생하면 error signal 전달 하고 종료 모든 item을 전달했다면 complete signal 전달하고 종료 backPressure 지원 Reactor의 Flux와 유사 Flowable 예제 # @Slf4j public class p199_FlowableExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems() .subscribe(new p181_SimpleSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); log.info(\u0026#34;end main\u0026#34;); } private static Flowable\u0026lt;Integer\u0026gt; getItems() { return Flowable.fromIterable(List.of(1, 2, 3, 4, 5)); } } 실행결과\n09:53:02.296 [main] INFO com.example06.rxjava.p199_FlowableExample - start main 09:53:02.339 [main] INFO com.example06.reactor.p181_SimpleSubscriber - subscribe 09:53:02.339 [main] INFO com.example06.reactor.p181_SimpleSubscriber - request: 2147483647 09:53:02.340 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 1 09:53:02.450 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 2 09:53:02.622 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 3 09:53:02.762 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 4 09:53:02.933 [main] INFO com.example06.reactor.p181_SimpleSubscriber - item: 5 09:53:03.112 [main] INFO com.example06.reactor.p181_SimpleSubscriber - complete 09:53:03.114 [main] INFO com.example06.rxjava.p199_FlowableExample - end main Flowable - backPressure 예제 # @Slf4j public class p200_FlowableContinuousRequestSubscriberExample { public static void main(String[] args) { log.info(\u0026#34;start main\u0026#34;); getItems() // 1개씩 처리 (backPressure) .subscribe(new p185_ContinuousRequestSubscriber\u0026lt;\u0026gt;()); log.info(\u0026#34;end main\u0026#34;); } private static Flowable\u0026lt;Integer\u0026gt; getItems() { return Flowable.fromIterable(List.of(1, 2, 3, 4, 5)); } } ContinuousRequestSubscriber\n@Slf4j public class p185_ContinuousRequestSubscriber\u0026lt;T\u0026gt; implements Subscriber\u0026lt;T\u0026gt; { private final Integer count = 1; private Subscription subscription; @Override public void onSubscribe(Subscription s) { this.subscription = s; log.info(\u0026#34;subscribe\u0026#34;); s.request(count); // 개수만큼 요청 log.info(\u0026#34;request: {}\u0026#34;, count); } @SneakyThrows @Override public void onNext(T t) { log.info(\u0026#34;item: {}\u0026#34;, t); Thread.sleep(1000); // 1개를 또 호출 subscription.request(1); log.info(\u0026#34;request: {}\u0026#34;, count); } @Override public void onError(Throwable t) { log.error(\u0026#34;error: {}\u0026#34;, t.getMessage()); } @Override public void onComplete() { log.info(\u0026#34;complete\u0026#34;); } } 실행결과\n09:54:17.223 [main] INFO com.example06.rxjava.p200_FlowableContinuousRequestSubscriberExample - start main 09:54:17.258 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - subscribe 09:54:17.259 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:54:17.260 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 1 09:54:18.335 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:54:18.335 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 2 09:54:19.408 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:54:19.409 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 3 09:54:20.483 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:54:20.484 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 4 09:54:21.544 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:54:21.545 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - item: 5 09:54:22.618 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - request: 1 09:54:22.623 [main] INFO com.example06.reactor.p185_ContinuousRequestSubscriber - complete 09:54:22.623 [main] INFO com.example06.rxjava.p200_FlowableContinuousRequestSubscriberExample - end main RxJava - Observable # 0..n개의 item을 전달 에러가 발생하면 error signal 전달 하고 종료 모든 item을 전달했다면 complete signal 전달하고 종료 backPressure 지원 X Observable vs Flowable # Observable Flowable Push 기반 Pull 기반 Subscriber가 처리할 수 없더라도 item을 전달 Subscriber가 request의 수를 조절 Reactive manifesto의 message driven을 일부만 준수 Reactive manifesto의 message driven을 모두 준수 onSubscribe로 Disposable 전달 onSubscribe시 Subscription 전 달\nObservable 예제 # @Slf4j public class p203_ObservableExample { public static void main(String[] args) { // 배압 조절 불가능 getItems() .subscribe(new p203_SimpleObserver()); } private static Observable\u0026lt;Integer\u0026gt; getItems() { return Observable.fromIterable(List.of(1, 2, 3, 4, 5)); } } SimpleObserver\n@Slf4j public class p203_SimpleObserver implements Observer { private Disposable disposable; @Override public void onSubscribe(@NonNull Disposable d) { log.info(\u0026#34;subscribe\u0026#34;); this.disposable = d; } @Override public void onNext(@NonNull Object o) { log.info(\u0026#34;item: {}\u0026#34;, o); } @Override public void onError(@NonNull Throwable e) { log.error(\u0026#34;error: {}\u0026#34;, e.getMessage()); } @Override public void onComplete() { log.info(\u0026#34;complete\u0026#34;); } } 실행결과\n09:57:21.403 [main] INFO com.example06.rxjava.p203_SimpleObserver - subscribe 09:57:21.404 [main] INFO com.example06.rxjava.p203_SimpleObserver - item: 1 09:57:21.404 [main] INFO com.example06.rxjava.p203_SimpleObserver - item: 2 09:57:21.404 [main] INFO com.example06.rxjava.p203_SimpleObserver - item: 3 09:57:21.404 [main] INFO com.example06.rxjava.p203_SimpleObserver - item: 4 09:57:21.405 [main] INFO com.example06.rxjava.p203_SimpleObserver - item: 5 09:57:21.405 [main] INFO com.example06.rxjava.p203_SimpleObserver - complete RxJava - Single # 1개의 item을 전달 후 바로 onComplete signal 전달 1개의 item이 없다면 onError signal 전달 에러가 발생했다면 onError signal 전달 Single - success 예제 # public class p205_SingleExample { public static void main(String[] args) { getItem() .subscribe(new p205_SimpleSingleObserver\u0026lt;\u0026gt;()); } private static Single\u0026lt;Integer\u0026gt; getItem() { return Single.create(singleEmitter -\u0026gt; { singleEmitter.onSuccess(1); }); } } SimpleSingleObserver\n@Slf4j public class p205_SimpleSingleObserver\u0026lt;T\u0026gt; implements SingleObserver\u0026lt;T\u0026gt; { private Disposable disposable; @Override public void onSubscribe(@NonNull Disposable d) { this.disposable = d; log.info(\u0026#34;subscribe\u0026#34;); } @Override public void onSuccess(@NonNull Object o) { log.info(\u0026#34;item: {}\u0026#34;, o); } @Override public void onError(@NonNull Throwable e) { log.error(\u0026#34;error: {}\u0026#34;, e.getMessage()); } } 실행결과\n09:58:59.778 [main] INFO com.example06.rxjava.p205_SimpleSingleObserver - subscribe 09:58:59.780 [main] INFO com.example06.rxjava.p205_SimpleSingleObserver - item: 1 Single - error (빈 값) # @Slf4j public class p206_SingleNullExample { public static void main(String[] args) { getItem() .subscribe(new p205_SimpleSingleObserver\u0026lt;\u0026gt;()); } private static Single\u0026lt;Integer\u0026gt; getItem() { return Single.create(singleEmitter -\u0026gt; { singleEmitter.onSuccess(null); // 에러 발생시킴 }); } } 실행결과\n09:59:53.191 [main] INFO com.example06.rxjava.p205_SimpleSingleObserver - subscribe 09:59:53.193 [main] ERROR com.example06.rxjava.p205_SimpleSingleObserver - error: onSuccess called with a null value. Null values are generally not allowed in 3.x operators and sources. RxJava - Maybe # 1개의 item을 전달 후 바로 onComplete signal 전달 1개의 item이 없어도 onComplete signal 전달 가능 에러가 발생했다면 onError signal 전달 Reactor의 Mono와 유사 예제 # SimpleMaybeObserver\n@Slf4j public class SimpleMaybeObserver\u0026lt;T\u0026gt; implements MaybeObserver\u0026lt;T\u0026gt; { private Disposable disposable; @Override public void onSubscribe(@NonNull Disposable d) { this.disposable = d; log.info(\u0026#34;subscribe\u0026#34;); } @Override public void onSuccess(@NonNull T t) { log.info(\u0026#34;item: {}\u0026#34;, t); } @Override public void onError(@NonNull Throwable e) { log.error(\u0026#34;error: {}\u0026#34;, e.getMessage()); } @Override public void onComplete() { log.info(\u0026#34;complete\u0026#34;); } } Maybe - success 예제 # @Slf4j public class p208_MaybeExample { public static void main(String[] args) { maybeGetItem() .subscribe(new SimpleMaybeObserver\u0026lt;\u0026gt;()); } private static Maybe\u0026lt;Integer\u0026gt; maybeGetItem() { return Maybe.create(maybeEmitter -\u0026gt; { maybeEmitter.onSuccess(1); }); } } 실행결과\n10:42:03.579 [main] INFO com.example06.rxjava.SimpleMaybeObserver - subscribe 10:42:03.581 [main] INFO com.example06.rxjava.SimpleMaybeObserver - item: 1 Maybe - success (빈 값) 예제 # @Slf4j public class p209_MaybeEmptyValueExample { public static void main(String[] args) { maybeGetItem() .subscribe(new SimpleMaybeObserver\u0026lt;\u0026gt;()); } private static Maybe\u0026lt;Integer\u0026gt; maybeGetItem() { return Maybe.create(maybeEmitter -\u0026gt; { maybeEmitter.onComplete(); // complete()만 호출 }); } } 실행결과\n10:42:24.592 [main] INFO com.example06.rxjava.SimpleMaybeObserver - subscribe 10:42:24.593 [main] INFO com.example06.rxjava.SimpleMaybeObserver - complete Maybe - error 예제 # @Slf4j public class p209_MaybeNullValueExample { public static void main(String[] args) { maybeGetItem() .subscribe(new SimpleMaybeObserver\u0026lt;\u0026gt;()); } private static Maybe\u0026lt;Integer\u0026gt; maybeGetItem() { return Maybe.create(maybeEmitter -\u0026gt; { maybeEmitter.onSuccess(null); }); } } 실행결과\n10:42:48.454 [main] INFO com.example06.rxjava.SimpleMaybeObserver - subscribe 10:42:48.456 [main] ERROR com.example06.rxjava.SimpleMaybeObserver - error: onSuccess called with a null value. Null values are generally not allowed in 3.x operators and sources. RxJava - Completable # onComplete 혹은 onError signal만 전달 값이 아닌 사건을 전달 예제 # SimpleCompletableObserver\n@Slf4j public class SimpleCompletableObserver implements CompletableObserver { private Disposable disposable; @Override public void onSubscribe(@NonNull Disposable d) { log.info(\u0026#34;subscribe\u0026#34;); this.disposable = d; } @Override public void onComplete() { log.info(\u0026#34;complete\u0026#34;); } @Override public void onError(@NonNull Throwable e) { log.error(\u0026#34;error: {}\u0026#34;, e.getMessage()); } } Completable - success 예제 # @Slf4j public class p212_CompletableExample { public static void main(String[] args) { getCompletion() .subscribe(new SimpleCompletableObserver()); } private static Completable getCompletion() { return Completable.create(completableEmitter -\u0026gt; { Thread.sleep(1000); completableEmitter.onComplete(); // 값이 아닌 사건을 전달 }); } } 실행결과\n10:43:45.900 [main] INFO com.example06.rxjava.SimpleCompletableObserver - subscribe 10:43:46.924 [main] INFO com.example06.rxjava.SimpleCompletableObserver - complete Completable - error 예제 # @Slf4j public class p213_CompletableErrorExample { public static void main(String[] args) { getCompletion() .subscribe(new SimpleCompletableObserver()); } private static Completable getCompletion() { return Completable.create(completableEmitter -\u0026gt; { Thread.sleep(1000); completableEmitter.onError( new RuntimeException(\u0026#34;error in completable\u0026#34;) ); }); } } 실행결과\n10:44:07.096 [main] INFO com.example06.rxjava.SimpleCompletableObserver - subscribe 10:44:08.124 [main] ERROR com.example06.rxjava.SimpleCompletableObserver - error: error in completable References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지\n2) github 예제코드 : https://github.com/seohaebada/webflux "},{"id":53,"href":"/docs/reactive-streams/004_impl3_munity/","title":"004 Impl3 Munity","section":"Reactive Streams","content":" Reactive Streams 구현 라이브러리 (3) Munity # Mutiny # Hibernate reactive에서 비동기 라이브러리로 제공 Multi, Uni publisher 제공 Mutiny - Multi # 0..n개의 item을 전달 에러가 발생하면 error signal 전달 하고 종료 모든 item을 전달했다면 complete signal 전달하고 종료 backPressure 지원 Reactor의 flux와 유사 Multi 예제 # @Slf4j public class p218_MultiExample { public static void main(String[] args) { getItems() .subscribe() // subscribe 동시에 넘길 수 없음, subscribe() 호출 후 아래 호출 필요 .withSubscriber( new p218_SimpleMultiSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE) ); } private static Multi\u0026lt;Integer\u0026gt; getItems() { return Multi.createFrom().items(1, 2, 3, 4, 5); } } SimpleMultiSubscriber\n@Slf4j @RequiredArgsConstructor public class p218_SimpleMultiSubscriber\u0026lt;T\u0026gt; implements MultiSubscriber\u0026lt;T\u0026gt; { private final Integer count; @Override public void onSubscribe(Flow.Subscription s) { s.request(count); log.info(\u0026#34;subscribe\u0026#34;); } @Override public void onItem(T item) { log.info(\u0026#34;item: {}\u0026#34;, item); } @Override public void onFailure(Throwable failure) { log.error(\u0026#34;fail: {}\u0026#34;, failure.getMessage()); } @Override public void onCompletion() { log.info(\u0026#34;completion\u0026#34;); } } 실행결과\n10:46:36.701 [main] INFO com.example06.mutiny.p218_SimpleMultiSubscriber - item: 1 10:46:36.702 [main] INFO com.example06.mutiny.p218_SimpleMultiSubscriber - item: 2 10:46:36.702 [main] INFO com.example06.mutiny.p218_SimpleMultiSubscriber - item: 3 10:46:36.702 [main] INFO com.example06.mutiny.p218_SimpleMultiSubscriber - item: 4 10:46:36.702 [main] INFO com.example06.mutiny.p218_SimpleMultiSubscriber - item: 5 10:46:36.702 [main] INFO com.example06.mutiny.p218_SimpleMultiSubscriber - completion 10:46:36.702 [main] INFO com.example06.mutiny.p218_SimpleMultiSubscriber - subscribe Mutiny - Uni # 0..1개의 item을 전달 에러가 발생하면 error signal 전달 하고 종료 모든 item을 전달했다면 complete signal 전달하고 종료 Reactor의 Mono와 유사 Uni 예제 # @Slf4j public class p220_UniExample { public static void main(String[] args) { getItem() .subscribe() .withSubscriber(new p220_SimpleUniSubscriber\u0026lt;\u0026gt;(Integer.MAX_VALUE)); } private static Uni\u0026lt;Integer\u0026gt; getItem() { return Uni.createFrom().item(1); } } SimpleUniSubscriber\n@Slf4j @RequiredArgsConstructor public class p220_SimpleUniSubscriber\u0026lt;T\u0026gt; implements UniSubscriber\u0026lt;T\u0026gt; { private final Integer count; private UniSubscription subscription; @Override public void onSubscribe(UniSubscription s) { this.subscription = s; s.request(1); log.info(\u0026#34;subscribe\u0026#34;); } @Override public void onItem(T item) { log.info(\u0026#34;item: {}\u0026#34;, item); } @Override public void onFailure(Throwable failure) { log.error(\u0026#34;error: {}\u0026#34;, failure.getMessage()); } } 실행결과\n10:47:27.202 [main] INFO com.example06.mutiny.p220_SimpleUniSubscriber - subscribe 10:47:27.208 [main] INFO com.example06.mutiny.p220_SimpleUniSubscriber - item: 1 References 1) 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지\n2) github 예제코드 : https://github.com/seohaebada/webflux "},{"id":54,"href":"/docs/redis/001_redis_datastructure/","title":"001 Redis Datastructure","section":"Redis","content":" 레디스 자료구조 활용사례 # 리더보드 # 경쟁자들의 순위와 현재 점수를 보여주는 순위표를 의미한다. 스코어로 정렬되어 상위 경쟁자의 순위를 보여준다.\n절대적 리더보드 서비스의 모든 유저를 정렬시켜 상위권의 목록만을 표시\n상대적 리더보드 사용자의 스코어를 기반으로 그들을 다른 사용자와 비교해 순위를 결정 ex) 유저와 인접해있는 경쟁자들의 스코어를 보여주는 리더보드, 특정 그룹 내에서의 순위를 보여주는 리더보드, 주간 리더보드\n리더보드는 기본적으로 사용자의 스코어를 기반으로 데이터를 정렬하는 서비스이기 때문에 사용자의 증가에 따라 가공해야할 데이터가 몇 배로 증가한다. 또한 리더보드는 실시간으로 반영돼야하는 데이터다. 데이터가 실시간으로 계산되어, 자신의 순위 변동이 바로 확인되어야한다.\nsorted set을 이용한 리더보드 레디스의 sorted set 은 데이터가 저장될 때부터 정렬된다. 유저의 스코어를 가중치로 설정하여 스코어 순으로 유저를 정렬할 수 있다.\n▶ daily-score:\u0026lt;날짜\u0026gt; 를 이용해 sorted set 키를 만들고, 사용자의 스코어를 가중치로 사용해서 데이터를 입력해보자.\nZADD daily-score:228017 28 player:286 ZADD daily-score:228017 400 player:234 ZADD daily-score:228017 45 player:101 ZADD daily-score:228017 357 player:24 ZADD daily-score:228017 199 player:143 위와 같이 데이터를 저장했다. 데이터는 스코어 순으로 정렬되어 있을 것이다.\nZRANGE daily-score:228017 0 -1 withscores ▶ 상위 유저 3명만 출력 ZREVRANGE는 sorted set에 저장된 데이터를 내림차순으로 반환한다. 0번 인덱스 ~ 2번 인덱스(세번째 데이터)까지 출력한다.\nZREVRANGE daily-score:228017 0 2 withscores ▶ 데이터 업데이트 sorted set은 데이터가 중복으로 저장되지 않으므로, 같은 아이템을 저장하고자 할때 스코어가 다르면 기존 데이터의 스코어만 업데이트한다. 이와 동시에 재정렬된다.\nZADD daily-score:228017 200 player:286 ▶ ZINCRBY 커맨드 스코어를 증감시킬 수 있다.\nZINCRBY daily-score:228017 100 player:24 랭킹 합산 # 주간 리더보드가 매주 월요일마다 초기화된다고 가정하자. 레디스에서 주간 누적 랭킹은 ZUNIONSTORE 커맨드로 간단하게 구현할 수 있다.\n▶ ZUNIONSTORE 커맨드 지정한 키에 연결된 각 아이템의 스코어를 합산하는 커맨드다. 해당하는 일자의 키를 지정하기만 한다면 손쉽게 주간 리더보드 데이터를 얻을 수 있다.\n22년 8월 15일 ~ 17일까지의 데이터 합산 // \u0026lt;생성할 키 이름\u0026gt;\u0026lt;합산할 키 개수\u0026gt;\u0026lt;합산할 키\u0026gt;... ZUNIONSTORE weekly-score:2208-3 3 daily-score:228015 daily-score:228016 daily-score:228017 합산한 결과 조회 ZRANGE weekly-score:2208-3 0 -1 withscores ZREVRANGE weekly-score:2208-3 0 -1 withscores // 역순정렬 스코어에 가중치 주기 8월 16일에 스코어 두배 이벤트가 있었다면, 두배로 늘려 계산해야한다. // 순서대로 15일, 16일, 17일에 x1, x1, x2의 결과값으로 합산된 랭킹을 구할 수 있다. ZUNIONSTORE weekly-score:2208-03 3 daily-score:228015 daily-score:228016 daily-score:228017 weights 1 1 2 sorted set을 이용한 최근 검색 내역\n유저 별로 다른 키워드 노출 검색 내역은 중복 제거 가장 최근 검색한 5개의 키워드만 사용자에게 노출 sorted set은 중복을 허용하지 않으며, 스코어를 시간으로 사용한다면 최근 검색 기록을 정렬할 수 있다. 데이터를 저장할때 유저가 검색한 시간을 스코어로 저장한다면 검색 시간 순으로 정렬된 데이터가 저장된다.\n▶ user id가 123인 유저의 검색 기록 저장\nZADD search-keyword:123 20221106143501 코듀로이 ZADD search-keyword:123 20221105220913 실버 ZADD search-keyword:123 20221105221002 반지갑 ZADD search-keyword:123 20221105220954 에나멜 ZADD search-keyword:123 20221106152734 기모후드 ▶ 최근 데이터 조회\nZREVRANGE search-keyword:123 0 4 withscores ▶ 반지갑이라는 키워드 재검색\nZADD search-keyword:123 20221106160104 반지갑 ▶ 오래된 데이터 삭제 sorted set의 음수 인덱스를 사용해서 데이터를 삭제한다면, 아이템의 개수(6개가 되었는지)를 확인해야하는 번거로운 작업을 줄일 수 있다. 음수 인덱스는 아이템의 제일 마지막 값을 -1로 시작해서 역순으로 증가하는 값이다. ex) 데이터가 6개라면, 인덱스 0 또는 음수인덱스 -6이 제일 오래된 아이템이다.\n6번째 데이터를 삽입한다. ZADD search-keyword:123 20221106165302 버킷햇 전체 데이터를 조회한다. ZREVRANGE search-keyword:123 0 -1 withscores 0번째 인덱스 또는 -6 인덱스인 \u0026lsquo;실버\u0026rsquo;를 삭제한다. ZREMRANGEBYRANK search-keyword:123 -6 -6 // -6부터 -6까지 만약 아이템의 개수가 5개보다 많지 않을때에는 -6번째 인덱스는 존재하지 않기 때문에 삭제된 데이터가 없으므로 영향을 주지 않는다. 이로써 굳이 아이템의 개수를 체크할 필요없이 최근 데이터 5개만 유지할 수 있다.\nsorted set을 이용한 태그 기능 ▶ 각 포스트가 사용하는 태그를 레디스의 set을 이용해 저장해보자. 태그는 IT, REDIS, DataStore 이라고 하자.\nSADD post:47:tags IT REDIS DataStore SADD post:22:tags IT python 태그 기능을 사용하는 이유는 특정 게시물이 어떤 태그와 연관돼 있는지 확인하기 위함과, 특정한 태그를 포함한 게시물들만 확인하기 위해서다.\n▶ 태그를 기준으로 하는 set에 각각 데이터를 넣어보자.\nSADD tag:DataStore:posts 53 SADD tag:IT:posts 53 SADD tag:MySQL:posts 53 ▶ SMEMBERS 커맨드 특정 태그를 갖고있는 포스트를 쉽게 확인할 수 있다.\nSMEMBERS tag:IT:posts ▶ SINTER 커맨드 IT, DataStore 태그를 모두 포함하는 게시물을 확인하고 싶은 경우 set의 교집합을 구하면된다.\nSINTER tag:IT:posts tag:DataStore:posts 좋아요 처리하기 # 댓글 id를 기준으로 set을 생성한뒤, 좋아요를 누른 유저의 id를 저장하면 중복 없이 데이터를 저장할 수 있다.\n좋아요를 누른 유저 967 저장 SADD comment-like:12554 967 건수 조회 SCARD comment-like:12554 hash를 이용한 읽지 않은 메시지 수 카운팅하기 # 채널에 새로 추가된 메시지의 개수를 확인하면 된다. 사용자의 ID를 키로 사용하고, 채널의 ID를 아이템의 키로 활용해 숫자 형태의 메시지 카운트를 관리한다.\nID가 234인 사용자 -\u0026gt; 4234 채널에서 새로운 메시지를 수신 HINCRBY user:234 channel:4234 1 전송한 메시지를 삭제했다면 데이터 감소 HINCRBY user:234 channel:4234 -1 DAU 구하기 # DAU(Daily Active User)는 하루 동안 서비스에 방문한 사용자의 수를 의미한다. 하루에 여러번 방문했다 하더라도 한번으로 카운팅되는 값으로, 실제 서비스를 이용한 사용자의 유니크한 수를 파악할 수 있는 지표다.\n레디스의 비트맵을 이용하면 메모리를 효율적으로 줄이면서도 실시간으로 서비스의 DAU를 확인할 수 있다. 사용자 ID는 string 자료구조에서 하나의 비트로 표현될 수 있다.\n2022년 11월 6일에 방문한 유저 id를 구한다. uv:20221106 데이터를 만든 뒤, 접속한 유저 id의 bit를 1로 설정한다. id가 14인 유저가 접근했을때 오프셋 14를 1로 설정해준다. SETBIT uv:20221106 14 1 유저 수 확인 BITCOUNT uv:20221106 ▶ BITOP AND 커맨드 출석 이벤트를 진행하기 위해 특정 기간 11월 1일부터 11월 3일까지 매일 방문한 사용자를 구해보자.\n// 11월 1일 ~ 11월 3일 BITOP AND event:202211 uv:20221101 uv:20221102 uv:20221103 ▶ 위 이벤트 결과 확인\nGET event:202211 "},{"id":55,"href":"/docs/redis/002_redis_cache/","title":"002 Redis Cache","section":"Redis","content":" 레디스를 캐시로 사용하기 # [캐시란?] # 데이터의 원본보다 더 빠르고 효율적으로 액세스할 수 있는 임시 데이터 저장소를 의미한다.\n[캐시로서의 레디스] # 레디스는 자체적으로 고가용성 기능을 가지고있다. 일부 캐싱 전략에서는 캐시에 접근할 수 없게 되면 이는 곧바로 서비스 장애로 이어질 수 있따. 캐시 저장소도 일반적인 데이터 저장소와 같이 안정적으로 운영될 수 있는 조건을 갖추는 것이 좋다. 레디스의 센티널, 클러스터 기능을 사용하면 마스터 노드의 장애를 자동으로 감지해 페일오버(Failover; 장애대비)를 발생시키기 때문에, 운영자의 개입 없이 캐시는 정상으로 유지될 수 있어 가용성이 높아진다. 레디스의 클러스터를 사용하면 캐시의 스케일 아웃 또한 쉽게 처리 가능하다. 서비스 규모에 따라 캐시 자체의 규모도 늘어나야할 상황이 발생할 수 있는데, 자체 샤딩 솔루션인 클러스터를 사용하면 수평 확장이 간단해진다. 레디스는 캐시 저장소 용도로 이상적이다.\n[캐싱 전략] # 캐싱 전략은 캐싱되는 데이터의 유형과 데이터에 대한 엑세스 패턴에 따라 다르기 때문에 적절한 캐싱 전략을 선택해야한다.\n[읽기 전략 - look aside] # 애플리케이션에서 데이터를 읽어갈때 주로 사용한다. 레디스를 사용할때 가장 일반적으로 배치하는 방법이다.\n데이터가 먼저 캐시에 있는지 확인한다. 캐시에 있으면 캐시에서 데이터를 읽어온다. (=캐시 히트) 찾고자하는 데이터가 없을때에는 캐시 미스가 발생하며, 직접 데이터베이스에 접근해 찾고자하는 데이터를 가져온다. 찾고하자는 데이터가 레디스에 없을때에만 레디스에 저장하므로 lazy loading 이라고도 부른다. 장점\n레디스에 문제가 생겨 접근을 할 수 없는 상황이 발생하더라도 장애 발생이 아닌, 직접 데이터베이스에 다시 데이터를 가지고온다. 모든 커넥션이 한꺼번에 원본 데이터베이스로 몰려 많으 부하를 발생시킬 수 있다. 미리 데이터베이스에서 캐시로 데이터를 밀어넣어주는 작업을 하기도하는데, 이를 캐시 워밍(cache warming)이라고도 한다.\n[쓰기 전략과 데이터의 일관성] # 캐시 불일치 : 데이터가 변경될때 원본 데이터베이스에만 업데이트돼 캐시에는 변경된 값이 반영되지 않을때 발생하는 데이터 불일치\n[쓰기 전략 - writh throwgh] # 데이터베이스에 업데이트할때마다 매번 캐시에도 데이터를 함께 업데이트시키는 방식이다. 캐시는 항상 최신 데이터를 가지고있을 수 있다. 데이터는 매번 2개의 저장소에 저장돼야 하기 때문에 데이터를 쓸 때마다 시간이 많이 소요될 수 있다.\n다시 사용될만한 데이터가 아닌 경우에는? 무조건 캐시에도 저장되는건 리소스 낭비일 수도 있다. 따라서 위 방시을 사용할 경우 데이터를 저장할때 만료 시간을 사용할 것을 권장한다.\n[cache invalidation] # 데이터베이스에 값을 업데이트 할때마다 캐시에는 데이터를 삭제한다. 신규 데이터 저장보다, 데이터 삭제가 리소스를 훨씬 적게 사용하기 때문이다.\n[write behind(write back)] # 쓰기가 빈번하게 발생하는 시스템이라면 이 방식을 고려하자. 데이터베이스에 대량의 쓰기 작업이 발생하면 이는 많은 디스크I/O를 유말해, 성능 저하가 발생할 수 있다. 먼저 데이터를 빠르게 접근할 수 있는 캐시에 업데이트 한뒤, 이후에는 건수나 특정 시간 간격 등에 따라 비동기적으로 데이터베이스에 업데이트하는 것이다. 저장되는 데이터가 실시간으로 정확한 데이터가 아니어도 되는 경우 유용하다.\n[캐시에서의 데이터 흐름] # 캐시는 메모리이기 때문에 기본적인 스토리지 보다 데이터를 적게 저장할 수 밖에 없다. 캐시는 가득차지 않게 일정 양의 데이터를 유지해야하며 관리되야한다. 캐시로 레디스를 사용할때에는 데이터를 저장함과 동시에 적절한 시간의 TTL 값을 저장하는 것이 좋다.\n[만료시간] # TTL (Time To Live)은 데이터가 얼마나 오래 저장될 것인지를 나타내는 시간 설정이다. 만료시간이 설정되면 해당 키와 관련된 데이터는 지정된 시간이 지난 후에 레디스에서 자동으로 삭제된다.\n커맨드 : TTL, EXPIRE(초 단위), PTTL, PEXPIRE (밀리세컨드 단위)\n// 키에 만료시간 지정 SET a 100 EXPIRE a 60 TTL a INCR 커맨드로 데이터를 조작하거나, RENAME을 이용해 키의 이름을 바꾸더라도 만료시간은 그대로 유지된다. 그러나, 기존 키에 새로운 값을 저장해 키를 덮어쓸 때에는 이전에 설정한 마료시간은 유지되지 않고 사라진다.\nSET b 100 EXPIRE b 60 TTL b // 57 SET b banana TTL b // -1 (만료시간이 지정되지 않음) [메모리 관리와 maxmemory-policy 설정] # 레디스의 메모리는 제한적이기 때문에 모든 키에 만료시간을 설정하더라도 너무 많은 키가 저장되면 메모리가 가득 차는 상황이 발생한다. 메모리의 용량을 초과하는 양의 데이터가 저장되면 레디스는 내부 정책을 사용해 어떤 키를 삭제할지 결정한다.\nmaxmemory 설정: 데이터의 최대 저장 용량 설정 maxmemory-policy 설정값 : 이 용량을 초과할 때의 처리 방식을 결정하는 설정값\n[Noeviction] # 기본값이다. 레디스에 데이터가 가득 차더라도 임의로 데이터를 삭제하지 않고 더이상 레디스에 데이터를 저장할 수 없다는 에러를 반환한다.\n[LRU eviction] # LRU(Least-Recently-Used) evicition이란, 레디스에 데이터가 가득 찼을때 가장 최근에 사용되지 않은 데이터부터 삭제하는 정책이다.\nvolatile-lru : 만료 시간이 설정돼있는 키에 한해서 LRU 방식으로 키를 삭제한다. 만약 모든 키에 만료시간이 지정돼있지 않다면, noeviction 상황과 동일하다. allkeys-LRU : 모든 키에 대해 LRU 알고리즘을 사용해서 데이터를 삭제한다. [LFU eviction] # LFU(Least-Frequently-Used) eviction이란, 레디스에 데이터가 가득 찼을때 가장 자주 사용되지 않은 데이터부터 삭제하는 정책이다. 사용 우선순위는 유동적으로 바뀌므로 특정 케이스에서는 LRU보다 더 효울적일 수 있다.\nvolatile-lru : 만료 시간이 설정돼있는 키에 한해서 LFU 방식으로 키를 삭제한다. 만약 모든 키에 만료시간이 지정돼있지 않다면, noeviction 상황과 동일하다. allkeys-LRU : 모든 키에 대해 LFU 알고리즘을 이용해 데이터를 삭제한다. [LANDOM eviction] # 레디스에 저장된 키 중 하나를 임의로 골라내 삭제한다. 랜덤으로 데이터를 삭제하기 때문에 나중에 사용할 수도 있는 데이터를 삭제할 가능성이 높아진다.\nvolatile-random : 만료 시간이 설정돼있는 키에 한해 랜덤하게 키를 삭제한다. allkeys-random : 모든 키에 대해 랜덤하게 키를 삭제한다. [voldatile-ttl] # 만료시간이 가장 작은 키를 삭제한다. 삭제 예정 시간이 얼마 남지 않은 키를 추출해 해당 키를 미리 삭제하는 옵션이다.\n[캐시 스탬피드 현상] # 대규모 트래픽 환경에서 만료 시간을 어떻게 설정하느냐에 따라 캐시 스탬피드(cache-stampede)와 같은 예상치 못한 문제 상황이 발생할 수 있다. look aside 방식으로 레디스를 사용하고 있을때, 특정 키가 만료되는 시점에 키가 삭제된다면? 여러개의 어플리케이션에서 바라보던 키가 레디스에서 만료돼 삭제된다면 이 서버들은 한꺼번에 데이터베이스에 가서 데이터를 읽어오는 과정을 거친다. 이를 중복 읽기(duplicate read)라고 한다. 이후 각 애플리케이션에서는 읽어온 데이터를 레디스에 쓰게 되는데, 이 또한 여러번 반복되기 때문에 중복 쓰기(duplicate write)가 발생한다.\n[적절한 만료시간 설정] # 캐시 스탬피드를 줄이기 위한 가장 간단한 방법은 만료 시간을 너무 짧지않게 설정하는 것이다. 여러 애플리케이션에서 한꺼번에 접근해야하는 데이터이며, 반복적으로 사용돼야하는 데이터라면 만료시간을 충분히 길게 설정한다.\n[선 계산] # look aside 방식으로 캐시를 사용할때 애플리케이션은 다음 코드와 비슷하게 동작할 것이다. 키가 실제로 만료되기 전에 이 값을 미리 갱신해준다면 여러 애플리케이션에서 한꺼번에 데이터베이스에 접근해 데이터를 읽어오는 과정을 줄여 불필요한 프로세스를 줄일 수 있다.\n[PER 알고리즘] # PER(Probabilistic Early Recomputation) 알고리즘 캐시 값이 만료되기 전에 언제 데이터베이스에 접근해서 값을 읽어오면 되는지 최적으로 계산할 수 있다.\ncurrentTime - ( timeToCompute * beta * log(rand()) ) \u0026gt; expiry currentTime : 현재 남은 만료시간 timeToCompute : 캐시된 값을 다시 계산하는데 걸리는 시간 beta : 기본적으로 1.0 보다 큰 값으로 설정 가능 rand() : 0과 1 사이의 랜덤 값을 반환하는 함수 expiry : 키를 재설정할때 새로 넣어줄 만료 시간 위 알고리즘은 만료시간에 가까워질수록 true를 반환할 확률이 증가하므로, 이는 불필요한 재계산을 효과적으로 방지하는 가장 효율적인 방법일 수 있다.\n[세션 스토어로서의 레디스] # 세션이란? 서비스를 사용하는 클라이언트의 상태 정보를 의미한다. 애플리케이션은 현재 서비스에 로그인돼 있는 클라이언트가 누구인지, 그 클라이언트가 어떤 활동을 하고 있는지 저장하고 있으며, 유저가 서비스를 떠나면 세션스토어에서 유저의 정보를 삭제한다. 많은 서비스에서 레디스를 세션 스토어로 사용하고 있다.\n웹 서버가 여러대로 늘어나는 상황에서, 각 웹 서버별로 세션 스토어를 따로 관리한다면 유저는 유저의 세션 정보를 갖고있는 웹 서버에 종속되야한다. 따라서 레디스를 세션 스토어로 사용해 서버, 데이터베이스와 분리 해놓은 뒤 여러 서버에서 세션 스토어 (1개)를 바라보도록 구성해야한다. 유저는 세션 스토어에 구애받지 않고 어떤 웹 서버에 연결되더라도 동일한 세션 데이터를 조회할 수 있어 트래픽을 효율적으로 분산시킬 수 있으며, 데이터의 일관성도 고려할 필요가 없다. 또한 관계형 데이터베이스보다 훨씬 빠르고 접근하기도 간편하므로 데이터를 가볍게 저장할 수 있다.\n레디스의 hash 자료구조는 세션 데이터를 저장하기에 알맞은 형태다.\nHMSET usersession:1 Name Garimoo IP 10:20:104:30 Hits 1 HINCRBY userssession:2 Hits 1 [캐시와 세션의 차이] # 레디스를 캐시로 사용할때에의 가장 일반적인 look aside 전략을 이용할때 데이터는 데이터베이스의 서브셋으로 동작한다. 세션 스토어에 저장된 데이터는 여러 사용자간 공유되지 않으며, 특정 사용자 ID에 한해 유효하다. 일반적인 세션 스토어에서는 유저가 로그인하면 세션 데이터는 세션 스토어에 저장된다. 유저가 로그인해 있는 동안, 즉 세션이 활성화돼 있는 동안에는 애플리케이션은 유저의 데이터를 데이터베이스가 아닌 세션 스토어에만 저장한다.\n"},{"id":56,"href":"/docs/kotlin/002_Functional_Programming_Example/","title":"002 Functional Programming Example","section":"Kotlin","content":" 코틀린으로 함수형 프로그래밍 시작하기 # [고차함수 : 함수를 함수에 넘기기] # 함수형 프로그램을 작성할때 기본이 되는 몇가지 주제\n함수도 값이다. 함수를 변수에 대입하거나 데이터 구조에 저장하거나 함수의 인자로 넘길 수 있다. 고차함수란? 다른 함수를 인자로 받는 함수\n고차함수 예제 어떤 수의 절댓값과 다른 수의 계승(팩토리얼; factorial)을 출력하는 프로그램\n루프를 함수적으로 작성하는 방법 n의 계승을 계산하는 함수를 추가한다. 재귀(recursion)를 통해 순수 함수로 루프를 작성할 수 있다. fun factorial(i: Int): Int { fun go(n: Int, acc: Int): Int = // \u0026lt;1\u0026gt; if (n \u0026lt;= 0) acc // 루프를 종료시키려면 재귀 호출을 하지 않고, 값을 반환한다. else go(n - 1, n * acc) // 재귀 호출 return go(i, 1) // \u0026lt;2\u0026gt; } i=1 go(0, 1x1) i=2 go(1, 2x1) i=3 go(2, 3x2) i=4 go(3, 4x6) i=5 go(4, 5x24)\n코틀린은 이런 식의(루프로 표현할 수 있는) 재귀를 수동으로 감지하지는 않지만 함수 앞에 tailrec 변경자를 붙이도록 요구한다. tailrec이 붙은 경우 컴파일러는 재귀 호출이 꼬리 위치(tail position)인 경우에 한해 while 루프로 작성했을 때와 같은 종류의 바이트 코드를 토해낸다. =\u0026gt; \u0026ldquo;꼬리 위치에 있는 재귀 호출을 최적화해 while 루프 형태로 변환한다.\u0026rdquo;\n코틀린의 꼬리 호출 fun factorial(i: Int): Int { tailrec fun go(n: Int, acc: Int): Int = // \u0026lt;1\u0026gt; if (n \u0026lt;= 0) acc else go(n - 1, n * acc) // \u0026lt;2\u0026gt; return go(i, 1) } 재귀적인 함수 호출을 하는 호출자가 재귀 함수 호출이 반환값을 즉시 호출하기만 하고 다른 아무일도 하지 않을때, 재귀 호출이 꼬리 위치에 있다고 말한다.\n꼬리 위치에 있다 : go(n-1, n*acc) 꼬리 위치에 있지 않다 : 1 + go(n-1, n*acc) 어떤 함수의 모든 재귀 호출이 꼬리 위치에 있고 함수 앞에 tailrec 변경자가 붙은 경우 코틀린 컴파일러는 재귀를 이터레이션시 호출 스택을 소비하지 않는 반복적인 루프로 컴파일한다. =\u0026gt; 이는 스택 오버플로우를 방지하고 메모리를 효율적으로 사용하는 데 도움이 된다.\n첫번째 고차함수 작성하기\nobject Example { private fun abs(n: Int): Int = if (n \u0026lt; 0) -n else n private fun factorial(i: Int): Int { //\u0026lt;1\u0026gt; 계층함수(formatFactorial())를 추가했으므로 private로 변경 fun go(n: Int, acc: Int): Int = if (n \u0026lt;= 0) acc else go(n - 1, n * acc) return go(i, 1) } fun formatAbs(x: Int): String { val msg = \u0026#34;The absolute value of %d is %d\u0026#34; return msg.format(x, abs(x)) } fun formatFactorial(x: Int): String { //\u0026lt;2\u0026gt; 새로 추가한 함수 (결과 출력) val msg = \u0026#34;The factorial of %d is %d\u0026#34; return msg.format(x, factorial(x)) } } fun main() { println(Example.formatAbs(-42)) println(Example.formatFactorial(7)) //\u0026lt;3\u0026gt; } 두 함수 formatAbs, formatFactorial은 거의 같다. 이 두 함수를 일반화해서 formatResult() 함수를 만들자.\nfun formatResult(name: String, n: Int, f: (Int) -\u0026gt; Int): String { val msg = \u0026#34;The %s of %d is %d.\u0026#34; return msg.format(name, n, f(n)) } fun main() { println(formatResult(\u0026#34;factorial\u0026#34;, 7, ::factorial)) println(formatResult(\u0026#34;absolute value\u0026#34;, -42, ::abs)) } 고차함수\nfun formatResult(name: String, n: Int, f: (Int) -\u0026gt; Int): String { ... } f에 대해서도 타입을 지정한다. f가 정수를 인자로 받고 정수를 반환하는 함수라는 뜻이다.\nabs()나 factorial()을 formatResult의 f 인자로 넘길 수 있다.\nprintln(formatResult(\u0026#34;factorial\u0026#34;, 7, ::factorial)) println(formatResult(\u0026#34;absolute value\u0026#34;, -42, ::abs)) [다형적 함수 : 타입에 대해 추상화하기] # 다형적(polymorphic) 함수 : 고차 함수를 작성할때 어떤 타입이 주어지든 관계없이 동작하는 코드\n예제\n배열에서 어떤 문자열을 찾는 단형적 함수 fun findFirst(ss: Array\u0026lt;String\u0026gt;, key: String): Int { tailrec fun loop(n: Int): Int = when { n \u0026gt;= ss.size -\u0026gt; -1 // \u0026lt;1\u0026gt; ss[n] == key -\u0026gt; n // \u0026lt;2\u0026gt; else -\u0026gt; loop(n + 1) // \u0026lt;3\u0026gt; } return loop(0) // \u0026lt;4\u0026gt; } 위 1)번의 단형적 함수를 다형적 함수로 변환 술어 함수(predicate function)는 어떤 조건을 평가하여 참(true) 또는 거짓(false) 중 하나를 반환하는 함수 fun \u0026lt;A\u0026gt; findFirst(xs: Array\u0026lt;A\u0026gt;, p: (A) -\u0026gt; Boolean): Int { // \u0026lt;1\u0026gt; 원소 타입이 A인 배열에 작용, 배열의 각 원소에 작용하는 술어 함수를 파라미터로 받음 tailrec fun loop(n: Int): Int = when { n \u0026gt;= xs.size -\u0026gt; -1 p(xs[n]) -\u0026gt; n // \u0026lt;2\u0026gt; 술어 함수를 배열 원소에 적용하기 else -\u0026gt; loop(n + 1) } return loop(0) } 타입 변수 A를 사용하는 위치\n배열의 원소는 모두 A 타입이어야 한다. xs: Array\u0026lt;A\u0026gt; p 함수는 A 타입의 값을 인자로 받는다. p: (A) -\u0026gt; Boolean 두 위치에서 같은 타입 변수를 참조한다는 사실은 findFirst()의 두 인자에서 해당 타입이 같은 타입이어야만 한다는 사실을 암시한다. 컴파일러는 findFirst()를 호출하는 코드가 이 두 부분에서 같은 타입을 사용하도록 강제한다.\n[익명 함수를 사용해 고차함수 호출하기] # \u0026gt;\u0026gt;\u0026gt; findFirst(arrayOf(7, 9, 13), {i: Int -\u0026gt; i == 9} {i: Int -\u0026gt; i == 9} 라는 구문을 함수 리터럴이나 익명 함수라고 한다.\n[타입에 맞춰 구현하기] # 함수 시그니처에 의해 구현이 하나로 정해지는 예제를 살펴보자.\nfun \u0026lt;A, B, C\u0026gt; partial1(a: A, f: (A, B) -\u0026gt; C): (B) -\u0026gt; C = TODO() 부분 적용(partial application)을 수행하는 고차함수다. partial1() 함수는 어떤 값과 함수(인자를 둘 받아서, 다른 결과를 내놓음)를 인자로 받는다. 인자를 하나만 받아서 결과를 내놓는 함수를 반환한다. 고차함수 f: (A, B) -\u0026gt; C 반환타입 우리가 반환해야하는 대상의 타입이다. (B) -\u0026gt; C 인자 타입이 B인 함수 리터럴을 작성한다. partial1()의 본문 안에서 a값을 자유롭게 사용할 수 있다. 마찬가지로 b도 익명함수의 인자이므로 함수 본문에서 자유롭게 사용할 수 있다. fun \u0026lt;A, B, C\u0026gt; partial1(a: A, f: (A, B) -\u0026gt; C): (B) -\u0026gt; C = { b: B -\u0026gt; TODO() } 내부 함수가 C 타입의 값을 반환해야한다. C타입의 값을 어떻게 얻을까? C 타입 값은 f 고차함수의 결괏값이다. 따라서 C 타입 값을 얻는 유일한 방법은 f 함수에 A, B 타입 값을 넘기는 것뿐이다. fun \u0026lt;A, B, C\u0026gt; partial1(a: A, f: (A, B) -\u0026gt; C): (B) -\u0026gt; C = { b: B -\u0026gt; f(a, b) } 결과적으로 인자 2개를 받아서 부분적으로 적용해 돌려주는 고차함수가 생긴 것이다. =\u0026gt; \u0026ldquo;A 그리고 A, B를 인자로 받아서 C를 생성해주는 함수가 있다면, A는 이미 인자에 있기 때문에 B만 제공한다면 C를 돌려주는 새로운 함수를 만들 수 있다.\u0026rdquo; 코틀린의 타입 추론 특성으로, 타입 애너테이션 생략이 가능하다. fun \u0026lt;A, B, C\u0026gt; partial1(a: A, f: (A, B) -\u0026gt; C): (B) -\u0026gt; C = { b -\u0026gt; f(a, b) } // 여기서 타입 생략 "},{"id":57,"href":"/docs/kotlin/001_Functional_Programming/","title":"001 Functional Programming","section":"Kotlin","content":" 함수형 프로그래밍이란? # 명령어 스타일 (imperative style) # 컴퓨터에게 정해진 명령 또는 지시를 하나하나 내림으로써 각 명령 단계마다 시스템의 상태를 바꾼다. 처음에는 단순화하려는 의도나, 시스템이 커질수록 복잡해지며, 그 결과 코드를 더이상 유지보수할 수 없게 되고, 테스트 하기 어려워지며 코드를 추론하는데에 어려워진다. 함수형 프로그래밍 (FP, Functional Programming) # 위 명령어 스타일의 대안으로, \u0026lsquo;부수 효과\u0026rsquo;를 완전히 없애는 개념이다. 함수형 프로그래밍의 전제는, 순수 함수를 통해 프로그램을 구성한다는 것이다. 순수 함수 : 아무 부수 효과가 없는 함수 부수 효과란? 결과를 반환하는 것 외에 무언가 다른 일을 하는 함수는 부수 효과가 있는 함수다. 변경이 일어나는 블록 외부 영역에 있는 변수를 변경한다. 데이터 구조를 인플레이스로 변경한다. (즉, 메모리의 내용을 직접 변경한다.) 객체의 필드를 설정한다. 예외를 던지거나 예외를 발생시키면서 프로그램을 중단시킨다. 콘솔에 출력을 하거나 사용자 입력을 읽는다. 파일을 읽거나 쓴다. 화면에 무언가를 그린다. 함수형 프로그래밍(FP)의 장점 : 예제로 알아보기 # 부수 효과가 있는 프로그램 순수하지 않은 프로그램 val listing1 = { class CreditCard { fun charge(price: Float): Unit = TODO() } data class Coffee(val price: Float = 2.50F) //tag::init1[] class Cafe { fun buyCoffee(cc: CreditCard): Coffee { val cup = Coffee() // \u0026lt;1\u0026gt; cc.charge(cup.price) // \u0026lt;2\u0026gt; return cup // \u0026lt;3\u0026gt; } } CreditCard 객체의 charge() 메서드를 호출한다. 이로써 부수 효과가 생긴다. 신용카드를 청구하려면, 신용 카드사에 요청해야하므로 외부에서 부수적으로 벌어지는 일이다. 반환하는 객체는 단지 Coffee 객체다. 이 부수효과로 인해서, 테스트가 어려워진다. 실제 신용 카드사에 접속해서 요청하는 것은 원하지 않는다. CreditCard는 신용카드사에 접속해 비용을 청구하는 방법을 알아서는 안된다. CreditCard가 이런 관심사를 알지 못하게 하고, buyCoffee에 Payments 객체를 넘김으로써 이 코드를 좀더 모듈화하고 테스트성을 향상시킬 수 있다. val listing2 = { data class Coffee(val price: Float = 2.95F) class CreditCard class Payments { fun charge(cc: CreditCard, price: Float): Unit = TODO() } //tag::init2[] class Cafe { fun buyCoffee(cc: CreditCard, p: Payments): Coffee { val cup = Coffee() p.charge(cc, cup.price) return cup } } //end::init2[] } Payments를 인터페이스로 선언할 수 있고, 이 인터페이스에에 대해 테스트에 적합한 mock 객체를 구현할 수 있다. 불필요하게 Payments를 인터페이스로 선언해야한다. buyCoffee()를 재사용하기가 어렵다. 한 고객이 커피를 12잔 주문할 경우, for문으로 buyCoffee()를 호출할 것이다. 이런 식으로 호출하면 charge() 메서드가 12번 수행되어 신용카드사에 12번 연결해서 청구라는 행위를 수행하게 된다. 위 문제의 처리 방안으로, buyCoffess()라는 새로운 함수를 작성해서 한꺼번에 청구하는 로직을 넣을 수 있다. 함수형 해법 # 부수 효과를 제거하고 buyCoffee가 Coffee와 함께 청구할 금액을 반환하게하자. val listing3 = { class CreditCard data class Coffee(val price: Float = 2.50F) data class Charge(val cc: CreditCard, val amount: Float) //tag::init3[] class Cafe { fun buyCoffee(cc: CreditCard): Pair\u0026lt;Coffee, Charge\u0026gt; { val cup = Coffee() return Pair(cup, Charge(cc, cup.price)) // 어떤 금액 청구를 만드는 관심사(Coffee), 청구를 처리하거나 해석하는 관심사(Charge) } } } 두 관심사로 분리했다. 어떤 금액 청구를 만드는 관심사 = Coffee 청구를 처리하거나 해석하는 관심사 = Charge Charge CreditCard와 amount를 포함한다. 같은 CreditCard에 대한 청구를 하나로 묶어줄때 편리하게 쓸 수 있는 combine 함수를 제공한다. val listing4 = { class CreditCard //tag::init4[] data class Charge(val cc: CreditCard, val amount: Float) { // \u0026lt;1\u0026gt; 생성자와 불변 필드가 있는 데이터 클래스 선언 fun combine(other: Charge): Charge = // \u0026lt;2\u0026gt;같은 신용카드에 대한 청구를 하나로 묶음 if (cc == other.cc) // \u0026lt;3\u0026gt; 같은 카드인지 검사. 그 외의 경우 에러 발생 Charge(cc, amount + other.amount) // \u0026lt;4\u0026gt; 이 Charge와 다른 Charge의 금액을 합산한 새로운 Charge를 반환 else throw Exception( \u0026#34;Cannot combine charges to different cards\u0026#34; ) } } buyCoffees 생성 # 이제는 우리 바람대로 buyCoffee를 바탕으로 이 함수를 구현할 수 있다. val listing5 = { class CreditCard data class Coffee(val price: Float = 2.50F) data class Charge(val cc: CreditCard, val amount: Float) { fun combine(other: Charge): Charge = TODO() } //tag::init5[] class Cafe { fun buyCoffee(cc: CreditCard): Pair\u0026lt;Coffee, Charge\u0026gt; = TODO() fun buyCoffees( cc: CreditCard, n: Int // 구매할 커피잔 수 ): Pair\u0026lt;List\u0026lt;Coffee\u0026gt;, Charge\u0026gt; { val purchases: List\u0026lt;Pair\u0026lt;Coffee, Charge\u0026gt;\u0026gt; = List(n) { buyCoffee(cc) } // \u0026lt;1\u0026gt; 자체적으로 초기화되는 리스트를 생성한다. val (coffees, charges) = purchases.unzip() // \u0026lt;2\u0026gt; Pair의 리스트를 두 리스트로 분리한다. List\u0026lt;Coffee\u0026gt;, List\u0026lt;Charge\u0026gt; return Pair( coffees, charges.reduce { c1, c2 -\u0026gt; c1.combine(c2) } ) // \u0026lt;3\u0026gt; coffees를 한 Charge로 합친 출력을 생성한다. } } } 이제는 buyCoffees 함수를 정의할때 직접 buyCoffee를 재사용할 수 있다. Payments 인터페이스에 대한 복잡한 mock 구현을 정의하지 않아도 이 두 함수를 아주 쉽게 테스트할 수 있다. Cafe 객체는 이제 Charge 값이 어떻게 처리되는지와는 무관하다. 같은 카드에 청구하는 금액을 모두 합치기 # val listing6 = { class CreditCard data class Charge(val cc: CreditCard, val amount: Float) { fun combine(other: Charge): Charge = TODO() } //tag::init6[] fun List\u0026lt;Charge\u0026gt;.coalesce(): List\u0026lt;Charge\u0026gt; = this.groupBy { it.cc }.values .map { it.reduce { a, b -\u0026gt; a.combine(b) } } } 청구 금액의 리스트를 취해서 사용한 신용카드에 따라 그룹으로 나누고, 각 그룹의 청구 금액을 하나로 합쳐서 카드마다 하나씩 청구로 만들어낸다. 순수 함수란? # 어떤 함수가 주어진 입력으로부터 결과를 계산하는 것 외에 다른 어떤 관찰 가능한 효과가 없다 -\u0026gt; \u0026ldquo;부수효과가 없다\u0026rdquo; \u0026ldquo;부수 효과가 없는 함수\u0026rdquo; -\u0026gt; \u0026ldquo;순수 함수\u0026rdquo; ex) String의 length 함수 : 주어진 문자열에 대해 항상 같은 길이가 반환되며, 다른 일은 발생하지 않는다. 참조 투명성(RT, Referential Transparency)이라는 개념을 사용해 형식화할 수 있다. 예시로 이해하자. 2 + 3은 순수함수 plus(2, 3)에 적용하는 식이다. 이 식에는 아무 부수효과가 없다. 결과는 언제나 5다. 실제로 프로그램에서 2 + 3을 볼때마다 이 식을 5로 치환할 수 있다. 이렇게 해도 프로그램의 의미가 전혀 바뀌지 않는다. 이는 어떤 식이 참조 투명하다는 말이 지닌 뜻의 전부다. 어떤 프로그램에서 프로그램의 의미를 변경하지 않으면서 식을 그 결괏값으로 치환할 수 있다면, 이 식은 참조 투명하다. 어떤 함수를 참조 투명한 인자를 사용해 호출한 결과가 참조 투명하다면 이 함수도 참조 투명하다. 참조 투명성 예제 # class CreditCard { fun charge(price: Float): Unit = TODO() } data class Coffee(val price: Float = 2.50F) //tag::init[] fun buyCoffee(cc: CreditCard): Coffee { val cup = Coffee() cc.charge(cup.price) return cup } buyCoffee()는 cc.charge(cup.price)의 반환 타입과 관계없이 이 함수 호출의 반환값을 무시한다. 따라서 buyCoffee()를 평과한 결과는 그냥 cup이고, 이 값은 Coffee()와 동일하다. 순수 함수가 되기 위해서는 p에 관계없이 p(buyCoffee(aliceCreditCard)), p(Coffee())가 똑같이 작동해야한다. 성립되지 않는다. p(buyCoffee(aliceCreditCard)) : 카드사를 통해 커피 값을 청구한다. p(Coffee()) : 아무일도 하지 않는다. 참조 투명성 예제(2) # \u0026gt;\u0026gt;\u0026gt; val x = \u0026#34;Hello, World\u0026#34; \u0026gt;\u0026gt;\u0026gt; val r1 = x.reversed() \u0026gt;\u0026gt;\u0026gt; val r2 = x.reversed() x가 등장하는 부분을 x가 가리키는 식으로 바꿔치기 하면 다음과 같다. \u0026gt;\u0026gt;\u0026gt; val r1 = \u0026#34;Hello, World\u0026#34;.reversed() \u0026gt;\u0026gt;\u0026gt; val r2 = \u0026#34;Hello, World\u0026#34;.reversed() 위 r1, r2가 같은 값으로 평가된다. x가 참조 투명하기 때문에 r1, r2 값은 예전과 같다. -\u0026gt; r1, r2도 참조 투명하다. 참조 투명성을 위배하는 예제 # \u0026gt;\u0026gt;\u0026gt; val x = StringBuilder(\u0026#34;Hello\u0026#34;) \u0026gt;\u0026gt;\u0026gt; val y = x.append(\u0026#34;, World\u0026#34;) \u0026gt;\u0026gt;\u0026gt; val r1 = y.toString() \u0026gt;\u0026gt;\u0026gt; val r2 = y.toString() append() 함수 : StringBuilder에 작용하며 객체 내부를 변화시킨다. append()가 호출될 때마다 StringBuilder의 이전 상태가 파괴된다. StringBuilder에 대해 toString()을 여러번 호출해도 항상 똑같은 결과를 얻는다. \u0026gt;\u0026gt;\u0026gt; val x = StringBuilder(\u0026#34;Hello\u0026#34;) \u0026gt;\u0026gt;\u0026gt; val r1 = x.append(\u0026#34;, World\u0026#34;).toString() \u0026gt;\u0026gt;\u0026gt; val r2 = x.append(\u0026#34;, World\u0026#34;).toString() y를 모두 append() 호출로 치환했다. -\u0026gt; 순수 함수가 아니라고 결론을 내릴 수 있다. StringBuilder에 대해 toString()을 여러번 호출해도 결코 같은 결과가 생기지 않는다. r1, r2는 같은 식처럼 보이지만, 실제로는 같은 StringBuilder 객체의 다른 두 값을 가르킨다. "},{"id":58,"href":"/docs/reactive-streams/001_reactive_streams_component/","title":"001 Reactive Streams Component","section":"Reactive Streams","content":" 리액티브 스트림즈란? # 리액티브한 코드 작성을 위한 구성을 도와주는 리액티브 라이브러리가 있다. 이 리액티브 라이브러리를 어떻게 구현해야할지 정의해놓은 별도의 표준 사양을 리액티브 스트림즈(Reactive Streams)라고 한다.\n리액티브 스트림즈는 \u0026lsquo;데이터 스트림을 Non-Blocking이면서 비동기적인 방식으로 처리하기 위한 리액티브 라이브러리 표준 사양\u0026rsquo;이라고 표현할 수 있다. 이를 구현한 구현체로는 RxJava, Reactor, Akka Streams, Java 9 Flow API 등이 있고, 그 중에 Spring framework와 가장 궁합이 잘 맞는 구현체는 Reactor이다.\n리액티브 구성요소 # 리액티브 스트림즈를 통해 구현해야 되는 API 컴포넌트에는 Publisher, Subscriber, Subscription, Processor 가 있다. 이 4개의 컴포넌트를 반드시 기억해야한다. 아무래도 이 4개의 역할이 헷갈리면 전체적인 동작과정까지도 헷갈리게되기 때문에 확실히 짚고 넘어가자.\n컴포넌트 설명 Publisher 데이터를 생성하고 통지(발행, 게시, 방출)하는 역할을 한다. Subsriber 구독한 Publisher로부터 통지된 데이터를 전달받아서 처리한다. Subscription Publisher에 요청할 데이터의 개수를 지정하고, 데이터의 구독을 취소하는 역할을 한다. Processor Publisher와 Subscriber의 기능을 모두 가지고 있다. 즉, Subscriber로서 다른 Publisher를 구독할 수 있고, Publisher로서 다른 Subscriber가 구독할 수 있다. Publisher와 Subscriber의 동작과정을 나타내는 그림 # 1. 데이터를 구독한다. (subscribe)\n먼저 Subscriber는 전달받을 데이터를 구독한다.\n2. 데이터를 통지할 준비가 되었음을 알린다. (onSubscribe)\nPublisher는 데이터를 통지할 준비가 되었음을 Subscriber에 알린다.\n3. 전달 받을 통지 데이터 개수를 요청한다. (Subscription.request)\nPublisher가 데이터를 통지할 준비가 되었다는 알림을 받은 Subscriber는 전달받기를 원하는 데이터의 개수를 Publisher에게 요청한다.\n▶ 데이터의 요청 개수를 지정하는 이유가 뭘까?\nSubscriber가 Subscription.reuqest를 통해 데이터의 요청 개수를 지정한다. 이는 실제로 Publisher와 Subscriber는 각각 다른 스레드에서 비동기적으로 상호작용하는 경우가 대부분이기 때문이다.\n이럴 경우 Publisher가 통지하는 속도가 Publisher로부터 통지된 데이터를 처리하는 Subscriber가 처리하는 속도보다 더 빠르면 처리를 기다리는 데이터가 쌓이게되어 시스템 부하가 커질 수 있다. 이러한 결과를 방지하기 위한 행위다.\nPublisher의 데이터 통지 속도 \u0026gt; 통지된 데이터를 처리하는 Subscriber 속도 간단하게 생각해보면 데이터가 전송되는 속도가 데이터가 처리되는 속도보다 빠르면 계속해서 처리해야하는 데이터가 밀리기 때문인 것이다.\n4. 데이터를 생성한다.\n5. 요청 받은 개수만큼 데이터를 통지한다. (onNext)\nPublisher는 Subscriber로부터 요청받은 만큼의 데이터를 통지한다.\n6. 데이터 처리를 완료할때까지 위 3~5번의 과정을 반복한다.\n이렇게 Publisehr와 Subscriber 간에 데이터 통지, 데이터 수신, 데이터 요청의 과정을 반복한다.\n7. 완료 또는 에러가(onError) 발생할때까지 데이터 생성, 통지, 요청을 계속한다.\n8. 데이터 통지가 완료되었음을 알린다. (onComplete)\n반복하다가 Publisher가 모든 데이터를 통지하게 되면 마지막으로 데이터 전송이 완료되었음을 Subscriber에게 알린다. 만약에 Publisher가 데이터를 처리하는 과정에서 에러가 발생하면 에러가 발생했음을 Subscriber에게 알린다.\n위 글의 내용으로 이해가 되지 않아도 계속해서 포스팅을 읽자. 추후에 예제코드를 보고나서 다시 위 글을 읽으면 이해가 될것이다.\n코드로 보는 리액티브 스트림즈 컴포넌트 # 리액티브 스트림즈 컴포넌트의 동작과정을 이미지와 순서 설명으로 알아보았다. 처리 과정은 이해가 되지만 역시나 Publisher, Subscriber, Subscription, Processor의 코드 흐름이 머릿속으로 그려지지는 않는다. 이제 실제 코드를 보면서 조금씩 머릿속으로 그림을 그려보자.\nPublisher.java # public interface Publisher\u0026lt;T\u0026gt; { public void subscribe(Subscriber \u0026lt;? super T\u0026gt; subscriber); } subscribe() 메서드 1개만 존재한다. subscribe() 메서드는 파라미터로 전달받은 Subscriber를 등록하는 역할을 한다.\n\u0026lsquo;Publisher는 데이터를 생성하고 통지하는 역할을 하고, Subscriber는 Publisher가 통지하는 데이터를 전달받기 위해 구독을 한다.\u0026rsquo; 라는 내용으로 봤을때 우리는 구독을 처리하는 subscribe() 메서드가 당연히 Subscriber에 있을거라고 오해할 수 있다. ▶ 왜 Subscriber가 아닌 Publisher에 subscribe() 메서드가 정의되어 있을까?\n리액티브 스트림즈에서의 Publisher/Subscriber는 개념상으로는 Subscriber가 구독을 하는게 맞다. 하지만 실제 코드상으로는 Publisher가 subscribe() 메서드의 파라미터인 Subscriber를 등록하는 형태로 구독이 이뤄진다. 우선 아래의 호출로직으로 Publisher 객체의 subscribe() 메서드를 호출할때 Subscriber 객체를 파라미터로 넘긴다고 이해하자.\n// 구독 pub.subscribe(sub); Subscriber.java # public interface Subscriber\u0026lt;T\u0026gt; { //구독 시작 처리 public void onSubscribe(Subscription subscription); // 아래 Subscription을 인자로 전달 //데이터 통지시 처리 public void onNext(T item); //에러 통지시 처리 public void onError(Throwable error); //완료 통지시 처리 public void onComplete(); } 메서드 설명 onSubscribe 구독 시작 시점에 어떤 처리를 하는 역할을 한다. 여기서의 처리는 Publisher에게 요청할 데이터의 개수를 지정하거나 구독을 해지하는 것을 의미한다. 이것은 onSubscribe 메서드의 파라미터로 전달되는 Subscription 객체를 통해서 이뤄진다. onNext Publisher가 통지한 데이터를 처리하는 역할을 한다. onError Publisher가 데이터를 통지를 위한 처리 과정에서 에러가 발생했을때 해당 에러를 처리하는 역할을 한다. onComplete Publisher가 데이터 통지를 완료했음을 알릴 때 호출되는 메서드다. 데이터 통지가 정상적으로 완료될 경우에 어떤 후처리를 해야한다면 omComplete 메서드에서 처리 코드를 작성하면 된다. Subscripton.java # public interface Subscription { // 통지받을 데이터 개수를 지정해 데이터 통지를 요청하거나 통지받지 않게 구독을 해지할때 사용하는 인터페이스 //통지받을 데이터 개수 요청 public void request(long num); //구독 해지 public void cancel(); // Subscriber에서 호출함 (Subscription을 받은 Subscriber에서 구독 해지를 위해 호출) } 메서드 설명 request Subscriber가 구독한 데이터의 개수를 요청한다. Publisher에게 데이터의 개수를 요청할 수 있다. cancel 구독을 해지한다. 실제 구독하는 구현코드! 위의 설명을 돕기위한 예제 코드다.\n// Publisher Publisher\u0026lt;Integer\u0026gt; pub = new Publisher\u0026lt;Integer\u0026gt;() { @Override public void subscribe(Subscriber\u0026lt;? super Integer\u0026gt; sub) { sub.onSubscribe(new Subscription() { @Override public void request(long n) { ... } @Override public void cancel() { ... } }); } }; // Subscriber Subscriber\u0026lt;Integer\u0026gt; sub = new Subscriber\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Subscription s) { log.debug(\u0026#34;onSubscribe\u0026#34;); s.request(Long.MAX_VALUE); } @Override public void onNext(Integer i) { log.debug(\u0026#34;onNext:{}\u0026#34;, i); } @Override public void onError(Throwable t) { log.debug(\u0026#34;onError:{}\u0026#34;, t); } @Override public void onComplete() { log.debug(\u0026#34;onComplete\u0026#34;); } }; // 구독 pub.subscribe(sub); 결국 Publisher의 subscribe() 메서드를 호출하여 구독하는데, 이때 파라미터 Subscriber 객체를 넘기면 된다.\n위 코드의 흐름\nPublisher와 Subscriber의 동작과정을 리액티브 스트림즈의 컴포넌트 코드 관점에서 다시 이해해보자.\n순서 과정 1 Publisher가 Subscriber 인터페이스 구현 객체를 subscribe 메서드의 파라미터로 전달한다. 2 Publisher 냅에서는 전달받은 Subscriber 인터페이스 구현 객체의 onSubscribe 메서드를 호출하면서 Subscriber의 구독을 의미하는 Subscription 인터페이스 구현 객체를 Subscriber에게 전달한다. 3 호출된 Subscriber 인터페이스 구현 객체의 onSubscribe() 메서드에서 전달받은 Subscription 객체를 통해 전달받을 데이터의 개수를 Publisher 에게 요청한다. 4 Publisher는 Subscriber로부터 전달받은 요청 개수만큼의 데이터를 onNext() 메서드를 호출해서 Subsriber에게 전달한다. 5 Publisher는 통지할 데이터가 더이상 없을 경우 onComplete 메서드를 호출해서 Subscriber에게 데이터 처리 종료를 알린다. Processor.java # public abstract interface Processor\u0026lt;T, R\u0026gt; extends Subscriber\u0026lt;T\u0026gt;, Publichser\u0026lt;R\u0026gt; {} Processor 인터페이스는 별도로 구현해야할 메서드가 없다. 대신 Subscriber, Publisher 인터페이스를 상속하고있다. 리액티브 스트림즈 컴포넌트에서 설명한대로 Processor가 Publisher과 Subscriber 기능을 모두 가지고있기 때문이다.\n구현 예제코드 # @Slf4j public class E05_PubSub_2 { public static void main(String[] args) { Publisher\u0026lt;Integer\u0026gt; pub = iterPub(Stream.iterate(1, a -\u0026gt; a + 1).limit(10).collect(Collectors.toList())); // 구독자 Subscriber\u0026lt;Integer\u0026gt; sub = logSub(); // 구독 시작 pub.subscribe(sub); } private static Subscriber\u0026lt;Integer\u0026gt; logSub() { Subscriber\u0026lt;Integer\u0026gt; sub = new Subscriber\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Subscription s) { // Subscription 의 request 를 요청해야한다. log.debug(\u0026#34;onSubscribe\u0026#34;); s.request(Long.MAX_VALUE); } @Override public void onNext(Integer i) { log.debug(\u0026#34;onNext:{}\u0026#34;, i); } @Override public void onError(Throwable t) { log.debug(\u0026#34;onError:{}\u0026#34;, t); } @Override public void onComplete() { log.debug(\u0026#34;onComplete\u0026#34;); } }; return sub; } private static Publisher\u0026lt;Integer\u0026gt; iterPub(List\u0026lt;Integer\u0026gt; iter) { Publisher\u0026lt;Integer\u0026gt; pub = new Publisher\u0026lt;Integer\u0026gt;() { // Publisher 의 구현해야하는 메서드 @Override public void subscribe(Subscriber\u0026lt;? super Integer\u0026gt; sub) { // 호출하면 그때부터 데이터를 통지 // Subscription : Publisher, Subscriber 둘 사이의 구독이 한번 일어난다는 의미 sub.onSubscribe(new Subscription() { @Override public void request(long n) { try { // iterable 의 원소를 통지한다. iter.forEach(s -\u0026gt; sub.onNext(s)); // 여기서 멈추면 안되고, publisher 가 데이터 통지가 완료했으면 완료됨을 호출해야한다. sub.onComplete(); } catch (Throwable t) { // 에러 처리 sub.onError(t); } } /** * Subscriber 에서 Subscription 객체의 cancel()을 호출할 수 있다. * 더이상 데이터를 통지받지 않겠다고 알림 */ @Override public void cancel() { } }); } }; return pub; } } Publisher 객체 생성 Publisher\u0026lt;Integer\u0026gt; pub = iterPub(Stream.iterate(1, a -\u0026gt; a + 1).limit(10).collect(Collectors.toList())); Subscriber 객체 생성 Subscriber\u0026lt;Integer\u0026gt; sub = logSub(); 구독 실행! pub.subscribe(sub); 여기서부터 실행 흐름을 들여다보자. # Subscriber 객체의 onSubscribe() 호출 메서드 설명 onSubscribe 구독 시작 시점에 어떤 처리를 하는 역할을 한다. 여기서의 처리는 Publisher에게 요청할 데이터의 개수를 지정하거나 구독을 해지하는 것을 의미한다. 이것은 onSubscribe 메서드의 파라미터로 전달되는 Subscription 객체를 통해서 이뤄진다. Subscriber 객체의 onNext() 호출 메서드 설명 onNext Publisher가 통지한 데이터를 처리하는 역할을 한다. !\n위 1)~2)번 반복\n1, 2, 3 ~ 9까지 반복 완료 후 마지막 데이터인 10의 onNext()가 호출된 시점이 왔다.\n모든 데이터 통지가 완료되었으므로 onComplete() 메서드 호출 메서드 설명 onComplete Publisher가 데이터 통지를 완료했음을 알릴 때 호출되는 메서드다. 데이터 통지가 정상적으로 완료될 경우에 어떤 후처리를 해야한다면 omComplete 메서드에서 처리 코드를 작성하면 된다. ▶ Subscriber 객체의 onComplete() 호출된 모습\n실행결과\n[main] DEBUG com.reactive.step02.E05_PubSub_2 - onSubscribe [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:1 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:2 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:3 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:4 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:5 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:6 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:7 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:8 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:9 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onNext:10 [main] DEBUG com.reactive.step02.E05_PubSub_2 - onComplete "},{"id":59,"href":"/docs/algorithm/000_sample/","title":"000 Sample","section":"Algorithm","content":"sample\n"},{"id":60,"href":"/docs/data-structure/000_sample/","title":"000 Sample","section":"Data Structure","content":"sample\n"},{"id":61,"href":"/docs/ddd/000_sample/","title":"000 Sample","section":"Ddd","content":"sample\n"},{"id":62,"href":"/docs/docker/000_sample/","title":"000 Sample","section":"Docker","content":"sample\n"},{"id":63,"href":"/docs/etc/000_sample/","title":"000 Sample","section":"Etc","content":"sample\n"},{"id":64,"href":"/docs/jenkins/000_sample/","title":"000 Sample","section":"Jenkins","content":"sample\n"},{"id":65,"href":"/docs/jpa/000_sample/","title":"000 Sample","section":"Jpa","content":"sample\n"},{"id":66,"href":"/docs/linux/000_sample/","title":"000 Sample","section":"Linux","content":"sample\n"},{"id":67,"href":"/docs/msa/000_sample/","title":"000 Sample","section":"Msa","content":"sample\n"},{"id":68,"href":"/docs/mvc/000_sample/","title":"000 Sample","section":"Mvc","content":"sample\n"},{"id":69,"href":"/docs/mysql/000_sample/","title":"000 Sample","section":"Mysql","content":"sample\n"},{"id":70,"href":"/docs/network/000_sample/","title":"000 Sample","section":"Network","content":"sample\n"},{"id":71,"href":"/docs/operating-system/000_sample/","title":"000 Sample","section":"Operating System","content":"sample\n"},{"id":72,"href":"/docs/oracle/000_sample/","title":"000 Sample","section":"Oracle","content":"sample\n"},{"id":73,"href":"/docs/security/000_sample/","title":"000 Sample","section":"Security","content":"sample\n"},{"id":74,"href":"/docs/servlet/000_sample/","title":"000 Sample","section":"Servlet","content":"sample\n"},{"id":75,"href":"/docs/spring/000_sample/","title":"000 Sample","section":"Spring","content":"sample\n"},{"id":76,"href":"/docs/webflux/000_sample/","title":"000 Sample","section":"Webflux","content":"sample\n"}]