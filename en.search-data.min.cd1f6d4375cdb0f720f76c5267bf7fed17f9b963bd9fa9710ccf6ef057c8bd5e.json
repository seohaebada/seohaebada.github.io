[{"id":0,"href":"/docs/algorithm/","title":"Algorithm","section":"Docs","content":" 000 Sample "},{"id":1,"href":"/docs/batch/","title":"Batch","section":"Docs","content":" 000 Sample "},{"id":2,"href":"/docs/data-structure/","title":"Data Structure","section":"Docs","content":" 000 Sample "},{"id":3,"href":"/docs/ddd/","title":"Ddd","section":"Docs","content":" 000 Sample "},{"id":4,"href":"/docs/docker/","title":"Docker","section":"Docs","content":" 000 Sample "},{"id":5,"href":"/docs/etc/","title":"Etc","section":"Docs","content":" 000 Sample "},{"id":6,"href":"/docs/java/","title":"Java","section":"Docs","content":" 000 Sample "},{"id":7,"href":"/docs/jenkins/","title":"Jenkins","section":"Docs","content":" 000 Sample "},{"id":8,"href":"/docs/jpa/","title":"Jpa","section":"Docs","content":" 000 Sample "},{"id":9,"href":"/docs/kafka/","title":"Kafka","section":"Docs","content":" 000 Sample "},{"id":10,"href":"/docs/kotlin/","title":"Kotlin","section":"Docs","content":" 000 Sample "},{"id":11,"href":"/docs/linux/","title":"Linux","section":"Docs","content":" 000 Sample "},{"id":12,"href":"/docs/mongodb/","title":"Mongodb","section":"Docs","content":" 000 Sample "},{"id":13,"href":"/docs/msa/","title":"Msa","section":"Docs","content":" 000 Sample "},{"id":14,"href":"/docs/mvc/","title":"Mvc","section":"Docs","content":" 000 Sample "},{"id":15,"href":"/docs/mysql/","title":"Mysql","section":"Docs","content":" 000 Sample "},{"id":16,"href":"/docs/network/","title":"Network","section":"Docs","content":" 000 Sample "},{"id":17,"href":"/docs/operating-system/","title":"Operating System","section":"Docs","content":" 000 Sample "},{"id":18,"href":"/docs/oracle/","title":"Oracle","section":"Docs","content":" 000 Sample "},{"id":19,"href":"/docs/reactive-streams/","title":"Reactive Streams","section":"Docs","content":" 000 Sample "},{"id":20,"href":"/docs/redis/","title":"Redis","section":"Docs","content":" 001 Redis Datastructure 002 Redis Cache "},{"id":21,"href":"/docs/security/","title":"Security","section":"Docs","content":" 000 Sample "},{"id":22,"href":"/docs/servlet/","title":"Servlet","section":"Docs","content":" 000 Sample "},{"id":23,"href":"/docs/spring/","title":"Spring","section":"Docs","content":" 000 Sample "},{"id":24,"href":"/docs/test/","title":"Test","section":"Docs","content":" 000 Sample "},{"id":25,"href":"/docs/webflux/","title":"Webflux","section":"Docs","content":" 000 Sample "},{"id":26,"href":"/docs/redis/001_redis_datastructure/","title":"001 Redis Datastructure","section":"Redis","content":" 레디스 자료구조 활용사례 # 리더보드 # 경쟁자들의 순위와 현재 점수를 보여주는 순위표를 의미한다. 스코어로 정렬되어 상위 경쟁자의 순위를 보여준다.\n절대적 리더보드 서비스의 모든 유저를 정렬시켜 상위권의 목록만을 표시\n상대적 리더보드 사용자의 스코어를 기반으로 그들을 다른 사용자와 비교해 순위를 결정 ex) 유저와 인접해있는 경쟁자들의 스코어를 보여주는 리더보드, 특정 그룹 내에서의 순위를 보여주는 리더보드, 주간 리더보드\n리더보드는 기본적으로 사용자의 스코어를 기반으로 데이터를 정렬하는 서비스이기 때문에 사용자의 증가에 따라 가공해야할 데이터가 몇 배로 증가한다. 또한 리더보드는 실시간으로 반영돼야하는 데이터다. 데이터가 실시간으로 계산되어, 자신의 순위 변동이 바로 확인되어야한다.\nsorted set을 이용한 리더보드 레디스의 sorted set 은 데이터가 저장될 때부터 정렬된다. 유저의 스코어를 가중치로 설정하여 스코어 순으로 유저를 정렬할 수 있다.\n▶ daily-score:\u0026lt;날짜\u0026gt; 를 이용해 sorted set 키를 만들고, 사용자의 스코어를 가중치로 사용해서 데이터를 입력해보자.\nZADD daily-score:228017 28 player:286 ZADD daily-score:228017 400 player:234 ZADD daily-score:228017 45 player:101 ZADD daily-score:228017 357 player:24 ZADD daily-score:228017 199 player:143 위와 같이 데이터를 저장했다. 데이터는 스코어 순으로 정렬되어 있을 것이다.\nZRANGE daily-score:228017 0 -1 withscores ▶ 상위 유저 3명만 출력 ZREVRANGE는 sorted set에 저장된 데이터를 내림차순으로 반환한다. 0번 인덱스 ~ 2번 인덱스(세번째 데이터)까지 출력한다.\nZREVRANGE daily-score:228017 0 2 withscores ▶ 데이터 업데이트 sorted set은 데이터가 중복으로 저장되지 않으므로, 같은 아이템을 저장하고자 할때 스코어가 다르면 기존 데이터의 스코어만 업데이트한다. 이와 동시에 재정렬된다.\nZADD daily-score:228017 200 player:286 ▶ ZINCRBY 커맨드 스코어를 증감시킬 수 있다.\nZINCRBY daily-score:228017 100 player:24 랭킹 합산 # 주간 리더보드가 매주 월요일마다 초기화된다고 가정하자. 레디스에서 주간 누적 랭킹은 ZUNIONSTORE 커맨드로 간단하게 구현할 수 있다.\n▶ ZUNIONSTORE 커맨드 지정한 키에 연결된 각 아이템의 스코어를 합산하는 커맨드다. 해당하는 일자의 키를 지정하기만 한다면 손쉽게 주간 리더보드 데이터를 얻을 수 있다.\n22년 8월 15일 ~ 17일까지의 데이터 합산 // \u0026lt;생성할 키 이름\u0026gt;\u0026lt;합산할 키 개수\u0026gt;\u0026lt;합산할 키\u0026gt;... ZUNIONSTORE weekly-score:2208-3 3 daily-score:228015 daily-score:228016 daily-score:228017 합산한 결과 조회 ZRANGE weekly-score:2208-3 0 -1 withscores ZREVRANGE weekly-score:2208-3 0 -1 withscores // 역순정렬 스코어에 가중치 주기 8월 16일에 스코어 두배 이벤트가 있었다면, 두배로 늘려 계산해야한다. // 순서대로 15일, 16일, 17일에 x1, x1, x2의 결과값으로 합산된 랭킹을 구할 수 있다. ZUNIONSTORE weekly-score:2208-03 3 daily-score:228015 daily-score:228016 daily-score:228017 weights 1 1 2 sorted set을 이용한 최근 검색 내역\n유저 별로 다른 키워드 노출 검색 내역은 중복 제거 가장 최근 검색한 5개의 키워드만 사용자에게 노출 sorted set은 중복을 허용하지 않으며, 스코어를 시간으로 사용한다면 최근 검색 기록을 정렬할 수 있다. 데이터를 저장할때 유저가 검색한 시간을 스코어로 저장한다면 검색 시간 순으로 정렬된 데이터가 저장된다.\n▶ user id가 123인 유저의 검색 기록 저장\nZADD search-keyword:123 20221106143501 코듀로이 ZADD search-keyword:123 20221105220913 실버 ZADD search-keyword:123 20221105221002 반지갑 ZADD search-keyword:123 20221105220954 에나멜 ZADD search-keyword:123 20221106152734 기모후드 ▶ 최근 데이터 조회\nZREVRANGE search-keyword:123 0 4 withscores ▶ 반지갑이라는 키워드 재검색\nZADD search-keyword:123 20221106160104 반지갑 ▶ 오래된 데이터 삭제 sorted set의 음수 인덱스를 사용해서 데이터를 삭제한다면, 아이템의 개수(6개가 되었는지)를 확인해야하는 번거로운 작업을 줄일 수 있다. 음수 인덱스는 아이템의 제일 마지막 값을 -1로 시작해서 역순으로 증가하는 값이다. ex) 데이터가 6개라면, 인덱스 0 또는 음수인덱스 -6이 제일 오래된 아이템이다.\n6번째 데이터를 삽입한다. ZADD search-keyword:123 20221106165302 버킷햇 전체 데이터를 조회한다. ZREVRANGE search-keyword:123 0 -1 withscores 0번째 인덱스 또는 -6 인덱스인 \u0026lsquo;실버\u0026rsquo;를 삭제한다. ZREMRANGEBYRANK search-keyword:123 -6 -6 // -6부터 -6까지 만약 아이템의 개수가 5개보다 많지 않을때에는 -6번째 인덱스는 존재하지 않기 때문에 삭제된 데이터가 없으므로 영향을 주지 않는다. 이로써 굳이 아이템의 개수를 체크할 필요없이 최근 데이터 5개만 유지할 수 있다.\nsorted set을 이용한 태그 기능 ▶ 각 포스트가 사용하는 태그를 레디스의 set을 이용해 저장해보자. 태그는 IT, REDIS, DataStore 이라고 하자.\nSADD post:47:tags IT REDIS DataStore SADD post:22:tags IT python 태그 기능을 사용하는 이유는 특정 게시물이 어떤 태그와 연관돼 있는지 확인하기 위함과, 특정한 태그를 포함한 게시물들만 확인하기 위해서다.\n▶ 태그를 기준으로 하는 set에 각각 데이터를 넣어보자.\nSADD tag:DataStore:posts 53 SADD tag:IT:posts 53 SADD tag:MySQL:posts 53 ▶ SMEMBERS 커맨드 특정 태그를 갖고있는 포스트를 쉽게 확인할 수 있다.\nSMEMBERS tag:IT:posts ▶ SINTER 커맨드 IT, DataStore 태그를 모두 포함하는 게시물을 확인하고 싶은 경우 set의 교집합을 구하면된다.\nSINTER tag:IT:posts tag:DataStore:posts 좋아요 처리하기 # 댓글 id를 기준으로 set을 생성한뒤, 좋아요를 누른 유저의 id를 저장하면 중복 없이 데이터를 저장할 수 있다.\n좋아요를 누른 유저 967 저장 SADD comment-like:12554 967 건수 조회 SCARD comment-like:12554 hash를 이용한 읽지 않은 메시지 수 카운팅하기 # 채널에 새로 추가된 메시지의 개수를 확인하면 된다. 사용자의 ID를 키로 사용하고, 채널의 ID를 아이템의 키로 활용해 숫자 형태의 메시지 카운트를 관리한다.\nID가 234인 사용자 -\u0026gt; 4234 채널에서 새로운 메시지를 수신 HINCRBY user:234 channel:4234 1 전송한 메시지를 삭제했다면 데이터 감소 HINCRBY user:234 channel:4234 -1 DAU 구하기 # DAU(Daily Active User)는 하루 동안 서비스에 방문한 사용자의 수를 의미한다. 하루에 여러번 방문했다 하더라도 한번으로 카운팅되는 값으로, 실제 서비스를 이용한 사용자의 유니크한 수를 파악할 수 있는 지표다.\n레디스의 비트맵을 이용하면 메모리를 효율적으로 줄이면서도 실시간으로 서비스의 DAU를 확인할 수 있다. 사용자 ID는 string 자료구조에서 하나의 비트로 표현될 수 있다.\n2022년 11월 6일에 방문한 유저 id를 구한다. uv:20221106 데이터를 만든 뒤, 접속한 유저 id의 bit를 1로 설정한다. id가 14인 유저가 접근했을때 오프셋 14를 1로 설정해준다. SETBIT uv:20221106 14 1 유저 수 확인 BITCOUNT uv:20221106 ▶ BITOP AND 커맨드 출석 이벤트를 진행하기 위해 특정 기간 11월 1일부터 11월 3일까지 매일 방문한 사용자를 구해보자.\n// 11월 1일 ~ 11월 3일 BITOP AND event:202211 uv:20221101 uv:20221102 uv:20221103 ▶ 위 이벤트 결과 확인\nGET event:202211 "},{"id":27,"href":"/docs/redis/002_redis_cache/","title":"002 Redis Cache","section":"Redis","content":" 레디스를 캐시로 사용하기 # [캐시란?] # 데이터의 원본보다 더 빠르고 효율적으로 액세스할 수 있는 임시 데이터 저장소를 의미한다.\n[캐시로서의 레디스] # 레디스는 자체적으로 고가용성 기능을 가지고있다. 일부 캐싱 전략에서는 캐시에 접근할 수 없게 되면 이는 곧바로 서비스 장애로 이어질 수 있따. 캐시 저장소도 일반적인 데이터 저장소와 같이 안정적으로 운영될 수 있는 조건을 갖추는 것이 좋다. 레디스의 센티널, 클러스터 기능을 사용하면 마스터 노드의 장애를 자동으로 감지해 페일오버(Failover; 장애대비)를 발생시키기 때문에, 운영자의 개입 없이 캐시는 정상으로 유지될 수 있어 가용성이 높아진다. 레디스의 클러스터를 사용하면 캐시의 스케일 아웃 또한 쉽게 처리 가능하다. 서비스 규모에 따라 캐시 자체의 규모도 늘어나야할 상황이 발생할 수 있는데, 자체 샤딩 솔루션인 클러스터를 사용하면 수평 확장이 간단해진다. 레디스는 캐시 저장소 용도로 이상적이다.\n[캐싱 전략] # 캐싱 전략은 캐싱되는 데이터의 유형과 데이터에 대한 엑세스 패턴에 따라 다르기 때문에 적절한 캐싱 전략을 선택해야한다.\n[읽기 전략 - look aside] # 애플리케이션에서 데이터를 읽어갈때 주로 사용한다. 레디스를 사용할때 가장 일반적으로 배치하는 방법이다.\n데이터가 먼저 캐시에 있는지 확인한다. 캐시에 있으면 캐시에서 데이터를 읽어온다. (=캐시 히트) 찾고자하는 데이터가 없을때에는 캐시 미스가 발생하며, 직접 데이터베이스에 접근해 찾고자하는 데이터를 가져온다. 찾고하자는 데이터가 레디스에 없을때에만 레디스에 저장하므로 lazy loading 이라고도 부른다. 장점\n레디스에 문제가 생겨 접근을 할 수 없는 상황이 발생하더라도 장애 발생이 아닌, 직접 데이터베이스에 다시 데이터를 가지고온다. 모든 커넥션이 한꺼번에 원본 데이터베이스로 몰려 많으 부하를 발생시킬 수 있다. 미리 데이터베이스에서 캐시로 데이터를 밀어넣어주는 작업을 하기도하는데, 이를 캐시 워밍(cache warming)이라고도 한다.\n[쓰기 전략과 데이터의 일관성] # 캐시 불일치 : 데이터가 변경될때 원본 데이터베이스에만 업데이트돼 캐시에는 변경된 값이 반영되지 않을때 발생하는 데이터 불일치\n[쓰기 전략 - writh throwgh] # 데이터베이스에 업데이트할때마다 매번 캐시에도 데이터를 함께 업데이트시키는 방식이다. 캐시는 항상 최신 데이터를 가지고있을 수 있다. 데이터는 매번 2개의 저장소에 저장돼야 하기 때문에 데이터를 쓸 때마다 시간이 많이 소요될 수 있다.\n다시 사용될만한 데이터가 아닌 경우에는? 무조건 캐시에도 저장되는건 리소스 낭비일 수도 있다. 따라서 위 방시을 사용할 경우 데이터를 저장할때 만료 시간을 사용할 것을 권장한다.\n[cache invalidation] # 데이터베이스에 값을 업데이트 할때마다 캐시에는 데이터를 삭제한다. 신규 데이터 저장보다, 데이터 삭제가 리소스를 훨씬 적게 사용하기 때문이다.\n[write behind(write back)] # 쓰기가 빈번하게 발생하는 시스템이라면 이 방식을 고려하자. 데이터베이스에 대량의 쓰기 작업이 발생하면 이는 많은 디스크I/O를 유말해, 성능 저하가 발생할 수 있다. 먼저 데이터를 빠르게 접근할 수 있는 캐시에 업데이트 한뒤, 이후에는 건수나 특정 시간 간격 등에 따라 비동기적으로 데이터베이스에 업데이트하는 것이다. 저장되는 데이터가 실시간으로 정확한 데이터가 아니어도 되는 경우 유용하다.\n[캐시에서의 데이터 흐름] # 캐시는 메모리이기 때문에 기본적인 스토리지 보다 데이터를 적게 저장할 수 밖에 없다. 캐시는 가득차지 않게 일정 양의 데이터를 유지해야하며 관리되야한다. 캐시로 레디스를 사용할때에는 데이터를 저장함과 동시에 적절한 시간의 TTL 값을 저장하는 것이 좋다.\n[만료시간] # TTL (Time To Live)은 데이터가 얼마나 오래 저장될 것인지를 나타내는 시간 설정이다. 만료시간이 설정되면 해당 키와 관련된 데이터는 지정된 시간이 지난 후에 레디스에서 자동으로 삭제된다.\n커맨드 : TTL, EXPIRE(초 단위), PTTL, PEXPIRE (밀리세컨드 단위)\n// 키에 만료시간 지정 SET a 100 EXPIRE a 60 TTL a INCR 커맨드로 데이터를 조작하거나, RENAME을 이용해 키의 이름을 바꾸더라도 만료시간은 그대로 유지된다. 그러나, 기존 키에 새로운 값을 저장해 키를 덮어쓸 때에는 이전에 설정한 마료시간은 유지되지 않고 사라진다.\nSET b 100 EXPIRE b 60 TTL b // 57 SET b banana TTL b // -1 (만료시간이 지정되지 않음) [메모리 관리와 maxmemory-policy 설정] # 레디스의 메모리는 제한적이기 때문에 모든 키에 만료시간을 설정하더라도 너무 많은 키가 저장되면 메모리가 가득 차는 상황이 발생한다. 메모리의 용량을 초과하는 양의 데이터가 저장되면 레디스는 내부 정책을 사용해 어떤 키를 삭제할지 결정한다.\nmaxmemory 설정: 데이터의 최대 저장 용량 설정 maxmemory-policy 설정값 : 이 용량을 초과할 때의 처리 방식을 결정하는 설정값\n[Noeviction] # 기본값이다. 레디스에 데이터가 가득 차더라도 임의로 데이터를 삭제하지 않고 더이상 레디스에 데이터를 저장할 수 없다는 에러를 반환한다.\n[LRU eviction] # LRU(Least-Recently-Used) evicition이란, 레디스에 데이터가 가득 찼을때 가장 최근에 사용되지 않은 데이터부터 삭제하는 정책이다.\nvolatile-lru : 만료 시간이 설정돼있는 키에 한해서 LRU 방식으로 키를 삭제한다. 만약 모든 키에 만료시간이 지정돼있지 않다면, noeviction 상황과 동일하다. allkeys-LRU : 모든 키에 대해 LRU 알고리즘을 사용해서 데이터를 삭제한다. [LFU eviction] # LFU(Least-Frequently-Used) eviction이란, 레디스에 데이터가 가득 찼을때 가장 자주 사용되지 않은 데이터부터 삭제하는 정책이다. 사용 우선순위는 유동적으로 바뀌므로 특정 케이스에서는 LRU보다 더 효울적일 수 있다.\nvolatile-lru : 만료 시간이 설정돼있는 키에 한해서 LFU 방식으로 키를 삭제한다. 만약 모든 키에 만료시간이 지정돼있지 않다면, noeviction 상황과 동일하다. allkeys-LRU : 모든 키에 대해 LFU 알고리즘을 이용해 데이터를 삭제한다. [LANDOM eviction] # 레디스에 저장된 키 중 하나를 임의로 골라내 삭제한다. 랜덤으로 데이터를 삭제하기 때문에 나중에 사용할 수도 있는 데이터를 삭제할 가능성이 높아진다.\nvolatile-random : 만료 시간이 설정돼있는 키에 한해 랜덤하게 키를 삭제한다. allkeys-random : 모든 키에 대해 랜덤하게 키를 삭제한다. [voldatile-ttl] # 만료시간이 가장 작은 키를 삭제한다. 삭제 예정 시간이 얼마 남지 않은 키를 추출해 해당 키를 미리 삭제하는 옵션이다.\n[캐시 스탬피드 현상] # 대규모 트래픽 환경에서 만료 시간을 어떻게 설정하느냐에 따라 캐시 스탬피드(cache-stampede)와 같은 예상치 못한 문제 상황이 발생할 수 있다. look aside 방식으로 레디스를 사용하고 있을때, 특정 키가 만료되는 시점에 키가 삭제된다면? 여러개의 어플리케이션에서 바라보던 키가 레디스에서 만료돼 삭제된다면 이 서버들은 한꺼번에 데이터베이스에 가서 데이터를 읽어오는 과정을 거친다. 이를 중복 읽기(duplicate read)라고 한다. 이후 각 애플리케이션에서는 읽어온 데이터를 레디스에 쓰게 되는데, 이 또한 여러번 반복되기 때문에 중복 쓰기(duplicate write)가 발생한다.\n[적절한 만료시간 설정] # 캐시 스탬피드를 줄이기 위한 가장 간단한 방법은 만료 시간을 너무 짧지않게 설정하는 것이다. 여러 애플리케이션에서 한꺼번에 접근해야하는 데이터이며, 반복적으로 사용돼야하는 데이터라면 만료시간을 충분히 길게 설정한다.\n[선 계산] # look aside 방식으로 캐시를 사용할때 애플리케이션은 다음 코드와 비슷하게 동작할 것이다. 키가 실제로 만료되기 전에 이 값을 미리 갱신해준다면 여러 애플리케이션에서 한꺼번에 데이터베이스에 접근해 데이터를 읽어오는 과정을 줄여 불필요한 프로세스를 줄일 수 있다.\n[PER 알고리즘] # PER(Probabilistic Early Recomputation) 알고리즘 캐시 값이 만료되기 전에 언제 데이터베이스에 접근해서 값을 읽어오면 되는지 최적으로 계산할 수 있다.\ncurrentTime - ( timeToCompute * beta * log(rand()) ) \u0026gt; expiry currentTime : 현재 남은 만료시간 timeToCompute : 캐시된 값을 다시 계산하는데 걸리는 시간 beta : 기본적으로 1.0 보다 큰 값으로 설정 가능 rand() : 0과 1 사이의 랜덤 값을 반환하는 함수 expiry : 키를 재설정할때 새로 넣어줄 만료 시간 위 알고리즘은 만료시간에 가까워질수록 true를 반환할 확률이 증가하므로, 이는 불필요한 재계산을 효과적으로 방지하는 가장 효율적인 방법일 수 있다.\n[세션 스토어로서의 레디스] # 세션이란? 서비스를 사용하는 클라이언트의 상태 정보를 의미한다. 애플리케이션은 현재 서비스에 로그인돼 있는 클라이언트가 누구인지, 그 클라이언트가 어떤 활동을 하고 있는지 저장하고 있으며, 유저가 서비스를 떠나면 세션스토어에서 유저의 정보를 삭제한다. 많은 서비스에서 레디스를 세션 스토어로 사용하고 있다.\n웹 서버가 여러대로 늘어나는 상황에서, 각 웹 서버별로 세션 스토어를 따로 관리한다면 유저는 유저의 세션 정보를 갖고있는 웹 서버에 종속되야한다. 따라서 레디스를 세션 스토어로 사용해 서버, 데이터베이스와 분리 해놓은 뒤 여러 서버에서 세션 스토어 (1개)를 바라보도록 구성해야한다. 유저는 세션 스토어에 구애받지 않고 어떤 웹 서버에 연결되더라도 동일한 세션 데이터를 조회할 수 있어 트래픽을 효율적으로 분산시킬 수 있으며, 데이터의 일관성도 고려할 필요가 없다. 또한 관계형 데이터베이스보다 훨씬 빠르고 접근하기도 간편하므로 데이터를 가볍게 저장할 수 있다.\n레디스의 hash 자료구조는 세션 데이터를 저장하기에 알맞은 형태다.\nHMSET usersession:1 Name Garimoo IP 10:20:104:30 Hits 1 HINCRBY userssession:2 Hits 1 [캐시와 세션의 차이] # 레디스를 캐시로 사용할때에의 가장 일반적인 look aside 전략을 이용할때 데이터는 데이터베이스의 서브셋으로 동작한다. 세션 스토어에 저장된 데이터는 여러 사용자간 공유되지 않으며, 특정 사용자 ID에 한해 유효하다. 일반적인 세션 스토어에서는 유저가 로그인하면 세션 데이터는 세션 스토어에 저장된다. 유저가 로그인해 있는 동안, 즉 세션이 활성화돼 있는 동안에는 애플리케이션은 유저의 데이터를 데이터베이스가 아닌 세션 스토어에만 저장한다.\n"},{"id":28,"href":"/docs/algorithm/000_sample/","title":"000 Sample","section":"Algorithm","content":"sample\n"},{"id":29,"href":"/docs/batch/000_sample/","title":"000 Sample","section":"Batch","content":"sample\n"},{"id":30,"href":"/docs/data-structure/000_sample/","title":"000 Sample","section":"Data Structure","content":"sample\n"},{"id":31,"href":"/docs/ddd/000_sample/","title":"000 Sample","section":"Ddd","content":"sample\n"},{"id":32,"href":"/docs/docker/000_sample/","title":"000 Sample","section":"Docker","content":"sample\n"},{"id":33,"href":"/docs/etc/000_sample/","title":"000 Sample","section":"Etc","content":"sample\n"},{"id":34,"href":"/docs/java/000_sample/","title":"000 Sample","section":"Java","content":"sample\n"},{"id":35,"href":"/docs/jenkins/000_sample/","title":"000 Sample","section":"Jenkins","content":"sample\n"},{"id":36,"href":"/docs/jpa/000_sample/","title":"000 Sample","section":"Jpa","content":"sample\n"},{"id":37,"href":"/docs/kafka/000_sample/","title":"000 Sample","section":"Kafka","content":"sample\n"},{"id":38,"href":"/docs/kotlin/000_sample/","title":"000 Sample","section":"Kotlin","content":"sample\n"},{"id":39,"href":"/docs/linux/000_sample/","title":"000 Sample","section":"Linux","content":"sample\n"},{"id":40,"href":"/docs/mongodb/000_sample/","title":"000 Sample","section":"Mongodb","content":"sample\n"},{"id":41,"href":"/docs/msa/000_sample/","title":"000 Sample","section":"Msa","content":"sample\n"},{"id":42,"href":"/docs/mvc/000_sample/","title":"000 Sample","section":"Mvc","content":"sample\n"},{"id":43,"href":"/docs/mysql/000_sample/","title":"000 Sample","section":"Mysql","content":"sample\n"},{"id":44,"href":"/docs/network/000_sample/","title":"000 Sample","section":"Network","content":"sample\n"},{"id":45,"href":"/docs/operating-system/000_sample/","title":"000 Sample","section":"Operating System","content":"sample\n"},{"id":46,"href":"/docs/oracle/000_sample/","title":"000 Sample","section":"Oracle","content":"sample\n"},{"id":47,"href":"/docs/reactive-streams/000_sample/","title":"000 Sample","section":"Reactive Streams","content":"sample\n"},{"id":48,"href":"/docs/security/000_sample/","title":"000 Sample","section":"Security","content":"sample\n"},{"id":49,"href":"/docs/servlet/000_sample/","title":"000 Sample","section":"Servlet","content":"sample\n"},{"id":50,"href":"/docs/spring/000_sample/","title":"000 Sample","section":"Spring","content":"sample\n"},{"id":51,"href":"/docs/test/000_sample/","title":"000 Sample","section":"Test","content":"sample\n"},{"id":52,"href":"/docs/webflux/000_sample/","title":"000 Sample","section":"Webflux","content":"sample\n"}]